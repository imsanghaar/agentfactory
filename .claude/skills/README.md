# Skill Coordination Guide

## Overview

This guide resolves collisions between related skills and provides clear decision trees for skill selection.

**14 Active Skills** organized by domain with clear triggers and interactions.

---

## CRITICAL COLLISION RESOLUTION

### 1. Content Quality Assessment: TWO TOOLS, DIFFERENT PURPOSES

**Skills**: `chapter-evaluator` + `content-evaluation-framework`

| Aspect | chapter-evaluator | content-evaluation-framework |
|--------|------------------|------------------------------|
| **Purpose** | Diagnose specific problems | Gate decision (pass/fail) |
| **When** | During development (find issues) | Before publication (go/no-go) |
| **Output** | Detailed findings + improvement recommendations | Weighted score (75%+ = pass) |
| **User** | Authors (improving content) | Reviewers (publication gate) |

**CORRECT WORKFLOW**:
```
Author develops lesson
  â†“
Author runs chapter-evaluator â†’ "What's wrong with this?"
  â†“
Author identifies issues + uses remediation skills:
  - Low Clarity? â†’ Use technical-clarity
  - Low Engagement? â†’ Use code-example-generator
  - Low Scaffolding? â†’ Use concept-scaffolding
  â†“
Author revises content
  â†“
Reviewer runs content-evaluation-framework â†’ "Is this 75%+?"
  â†“
PASS â†’ Publish | FAIL â†’ Return to author with chapter-evaluator
```

**DO NOT**:
- Use chapter-evaluator as final gate (it's diagnostic, not pass/fail)
- Use content-evaluation-framework during development (doesn't identify what's wrong)
- Ask "which one?" â€” use BOTH in sequence

---

### 2. Teaching AI Collaboration: DESIGN FIRST, THEN CODE

**Skills**: `ai-collaborate-teaching` + `code-example-generator`

| Aspect | ai-collaborate-teaching | code-example-generator |
|--------|------------------------|------------------------|
| **Purpose** | Design lesson balance | Generate specific examples |
| **Scope** | Whole lesson structure | Individual code examples |
| **Question** | "How should this lesson mix foundation/AI/verification?" | "What code example demonstrates this concept?" |
| **Output** | 40/40/20 balance plan | Runnable code with validation |

**CORRECT WORKFLOW**:
```
Lesson concept defined
  â†“
Use ai-collaborate-teaching â†’ "Design the lesson balance"
  â†“
Lesson should be 40% foundation + 40% AI + 20% verification
  â†“
For EACH section needing code:
  Use code-example-generator â†’ Generate specific examples
  (Examples must follow Specâ†’Promptâ†’Codeâ†’Validation)
  â†“
Assemble lesson with code examples fitting the 40/40/20 structure
```

**DO NOT**:
- Skip ai-collaborate-teaching and jump to code examples (no balance)
- Use code-example-generator randomly (examples must fit lesson design)

---

### 3. Learning Design: OBJECTIVES â†’ SCAFFOLDING â†’ CLARITY

**Skills**: `learning-objectives` + `concept-scaffolding` + `technical-clarity`

| Skill | Question | Output | When |
|-------|----------|--------|------|
| learning-objectives | "What will students DO?" | SMART outcomes + Bloom's levels + assessments | PLAN (first) |
| concept-scaffolding | "How will students LEARN it?" | 3-7 step progression + cognitive load limits | DESIGN (second) |
| technical-clarity | "Is this clear to read?" | Prose refinement + jargon checks | POLISH (third) |

**CORRECT WORKFLOW**:
```
Step 1: Define learning objectives
  â†’ What outcomes? (Bloom's Create level)
  â†’ What proficiency? (CEFR B1)
  â†’ How to assess? (Concrete evals)
  â†’ Output: learning_objectives.md

Step 2: Design progression to reach objectives
  â†’ How many steps? (3-7)
  â†’ Concepts per step? (B1 = 3-5)
  â†’ Validation checkpoints?
  â†’ Output: scaffolding_plan.md

Step 3: Write lesson content following scaffolding
  â†’ Use code-example-generator for worked examples
  â†’ Use ai-collaborate-teaching for 40/40/20 balance
  â†’ Output: lesson.md (draft)

Step 4: Polish clarity
  â†’ Run technical-clarity skill
  â†’ Fix: gatekeeping language, jargon, accessibility
  â†’ Output: lesson.md (final)

Step 5: Verify against outcomes
  â†’ Use chapter-evaluator
  â†’ All objectives measurable? Learning outcomes clear?
  â†’ Output: evaluation report
```

**DO NOT**:
- Write lesson first, define objectives after (backwards)
- Skip scaffolding design (jump straight to writing)
- Polish prose before content is solid (wrong priority)

---

## SKILL SELECTION MATRIX

### By Task: "I need to..."

#### âœï¸ PLAN & DESIGN

**"Define what students will learn"**
â†’ Use `learning-objectives`

**"Design the progression to teach a concept"**
â†’ Use `concept-scaffolding`

**"Balance a lesson between foundation/AI/verification"**
â†’ Use `ai-collaborate-teaching`

#### ğŸ› ï¸ IMPLEMENT & CREATE

**"Generate a working code example"**
â†’ Use `code-example-generator`

**"Generate a full PhD-level exam from notes"**
â†’ Use `mit-exam-generator`

**"Generate a lesson summary for quick review"**
â†’ Use `summary-generator`

**"Create a production skill from scratch"**
â†’ Use `skill-creator-pro`

**"Create platform skills/agents/specs correctly"**
â†’ Use `canonical-format-checker`

#### ğŸ” REVIEW & EVALUATE

**"Diagnose problems in a chapter (detailed analysis)"**
â†’ Use `chapter-evaluator`

**"Gate a chapter for publication (yes/no)"**
â†’ Use `content-evaluation-framework`

**"Check technical prose for accessibility"**
â†’ Use `technical-clarity`

**"Validate a skill meets production standards"**
â†’ Use `skill-validator`

#### ğŸ”§ FIX & IMPROVE

**"Fix Gate 4 failures (word count/continuity)"**
â†’ Use `content-refiner`

**"Map skill proficiency to CEFR levels"**
â†’ Use `skills-proficiency-mapper`

---

## DOMAIN ORGANIZATION

### 1. PEDAGOGICAL DESIGN (Objectives + Progression)

**Core**: `learning-objectives` â†’ `concept-scaffolding`
- **learning-objectives**: WHAT will students achieve
- **concept-scaffolding**: HOW they'll learn it
- **Support**: `technical-clarity` (polish), `ai-collaborate-teaching` (balance)

### 2. CONTENT CREATION (Write + Generate)

**Core**: `code-example-generator` + `ai-collaborate-teaching`
- **code-example-generator**: Create specific examples
- **ai-collaborate-teaching**: Design lesson structure
- **Support**: `mit-exam-generator` (assessments), `summary-generator` (review)

### 3. QUALITY GATES (Diagnose + Gate + Validate)

**Diagnostic**: `chapter-evaluator` (find issues)
**Gate**: `content-evaluation-framework` (publish decision)
**Support**: `technical-clarity` (fix prose), `content-refiner` (fix structure)

### 4. PLATFORM STANDARDS (Skills + Specs + Patterns)

**Creation**: `skill-creator-pro`
**Validation**: `skill-validator`, `canonical-format-checker`
**Support**: `skills-proficiency-mapper`

---

## COMMON WORKFLOWS

### Workflow 1: Create a New Lesson

```
1. Define objectives â†’ learning-objectives
2. Design progression â†’ concept-scaffolding
3. Generate examples â†’ code-example-generator
4. Design lesson balance â†’ ai-collaborate-teaching
5. Write content following scaffolding
6. Polish prose â†’ technical-clarity
7. Diagnose problems â†’ chapter-evaluator
8. Fix issues using remediation skills
9. Gate for publication â†’ content-evaluation-framework
10. PUBLISH
```

**Time**: ~8-12 hours (depends on complexity)

---

### Workflow 2: Review Existing Chapter

```
1. Run chapter-evaluator â†’ Get detailed analysis
2. For each low-scoring dimension:
   - Low Clarity? â†’ Fix with technical-clarity
   - Low Engagement? â†’ Use code-example-generator for better examples
   - Low Scaffolding? â†’ Redesign with concept-scaffolding
   - Low Objectives? â†’ Clarify with learning-objectives
3. Re-run chapter-evaluator
4. Submit to content-evaluation-framework
5. If PASS â†’ Publish | If FAIL â†’ Repeat steps 2-3
```

**Time**: ~4-6 hours (revision depends on issues found)

---

### Workflow 3: Create a Production Skill

```
1. Determine skill type (Builder/Guide/Automation/Analyzer/Validator)
2. Run skill-creator-pro â†’ Get domain expertise + structure
3. Implement skill + bundled resources
4. Run skill-validator â†’ Check quality (9-category scoring)
5. Fix any failures identified
6. Re-validate
7. Deploy to production
```

**Time**: ~6-10 hours (depends on domain complexity)

---

### Workflow 4: Fix Gate 4 Failure

```
1. Understand what Gate 4 failure means (word count? continuity? both?)
2. Run content-refiner â†’ Diagnose + fix in phases
3. Phase 1: Fix continuity (if needed)
4. Phase 2: Fix word count (layer-aware)
5. Phase 3: Validate (run checks)
6. Re-submit to Gate 4
7. If still failing â†’ Understand why and address root cause
```

**Time**: ~1-2 hours

---

## NO-COLLISION SKILLS

These skills have clear, non-overlapping purposes:

- **summary-generator**: Extract key concepts from lessons (unique)
- **mit-exam-generator**: Generate rigorous exams (specialized, no overlap)
- **skill-creator-pro**: Create production skills (unique domain)
- **skill-validator**: Validate skills (complements skill-creator-pro)
- **canonical-format-checker**: Prevent format drift (specialized niche)
- **skills-proficiency-mapper**: Map proficiency levels (unique function)

---

## QUICK DECISION TREE

```
User asks: "Help me with [task]"

Is it about lesson content?
  â”œâ”€ YES
  â”‚   â”œâ”€ Define learning outcomes? â†’ learning-objectives
  â”‚   â”œâ”€ Design progression? â†’ concept-scaffolding
  â”‚   â”œâ”€ Generate code example? â†’ code-example-generator
  â”‚   â”œâ”€ Balance lesson structure? â†’ ai-collaborate-teaching
  â”‚   â”œâ”€ Fix prose clarity? â†’ technical-clarity
  â”‚   â”œâ”€ Diagnose problems? â†’ chapter-evaluator
  â”‚   â”œâ”€ Gate for publication? â†’ content-evaluation-framework
  â”‚   â”œâ”€ Fix Gate 4 failure? â†’ content-refiner
  â”‚   â””â”€ Create lesson summary? â†’ summary-generator
  â”‚
  â””â”€ NO, it's about something else
    â”œâ”€ Exams/assessments? â†’ mit-exam-generator
    â”œâ”€ Creating a skill? â†’ skill-creator-pro
    â”œâ”€ Validating a skill? â†’ skill-validator
    â”œâ”€ Teaching platform patterns? â†’ canonical-format-checker
    â”œâ”€ Mapping skill proficiency? â†’ skills-proficiency-mapper
    â”œâ”€ Teaching AI collaboration patterns? â†’ ai-collaborate-teaching
    â””â”€ Teaching foundational concepts in general? â†’ concept-scaffolding
```

---

## VERSION NOTES

- **Report Date**: January 16, 2026
- **Skills Evaluated**: 14 (removed: creating-skills, operational-excellence)
- **Critical Fixes Applied**:
  1. âœ… content-refiner: Added failure diagnosis logic + phase-based approach
  2. âœ… chapter-evaluator: Added weighting + publication gate decision logic
  3. âœ… concept-scaffolding: Added YAML frontmatter + comparison to learning-objectives
- **Collision Resolutions**: 3 major (addressed above)
- **Status**: **PRODUCTION-READY** (all skills vetted)

---

## FEEDBACK & UPDATES

If skills change or new collisions emerge:
1. Update the relevant workflow section above
2. Update the decision tree
3. Test the workflow with a real task
4. Document the change in VERSION NOTES

**Last Updated**: January 16, 2026
