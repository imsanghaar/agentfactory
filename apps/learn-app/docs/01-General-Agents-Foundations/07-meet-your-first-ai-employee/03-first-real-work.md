---
sidebar_position: 3
title: "Your First Real Work"
description: "Build artifacts you'll keep, iterate on agent output, and configure a daily workflow that runs while you sleep"
keywords:
  [
    ai employee tasks,
    agent loop,
    task delegation,
    daily workflow,
    morning briefing,
    openclaw tasks,
    output iteration,
  ]
chapter: 7
lesson: 3
duration_minutes: 30

# HIDDEN SKILLS METADATA
skills:
  - name: "Agent Task Delegation"
    proficiency_level: "A2"
    category: "Applied"
    bloom_level: "Apply"
    digcomp_area: "Computational Thinking"
    measurable_at_this_level: "Student can delegate research and file creation tasks, then iterate on agent output by requesting explanations and making accept/reject decisions"

  - name: "Output Quality Assessment"
    proficiency_level: "A2"
    category: "Conceptual"
    bloom_level: "Evaluate"
    digcomp_area: "Critical Thinking"
    measurable_at_this_level: "Student can assess agent output, request reasoning behind suggestions, and apply their own judgment to accept or modify recommendations"

  - name: "Daily Workflow Design"
    proficiency_level: "A2"
    category: "Applied"
    bloom_level: "Apply"
    digcomp_area: "Computational Thinking"
    measurable_at_this_level: "Student can configure a personalized daily briefing that runs on schedule, review its output, and modify the configuration based on usefulness"

learning_objectives:
  - objective: "Delegate tasks and iterate on agent output by requesting explanations and making accept/reject decisions"
    proficiency_level: "A2"
    bloom_level: "Apply"
    assessment_method: "Student completes Tasks 1-2 and has edited at least one agent output based on their own judgment"

  - objective: "Identify the 4 phases of the agent loop (parse, plan, execute, report) from real observations"
    proficiency_level: "A2"
    bloom_level: "Understand"
    assessment_method: "Student can describe which phase the agent was in during each task"

  - objective: "Configure a personalized daily briefing and test it"
    proficiency_level: "A2"
    bloom_level: "Apply"
    assessment_method: "Student has a working morning briefing configured for their role that runs on schedule"

  - objective: "Distinguish between reactive tasks (you ask) and autonomous tasks (agent acts on schedule)"
    proficiency_level: "A2"
    bloom_level: "Understand"
    assessment_method: "Student can explain the difference between Tasks 1-3 (reactive) and Task 4 (autonomous) and why it matters"

cognitive_load:
  new_concepts: 5
  concepts_list:
    - "Task delegation with iteration (ask, review, modify)"
    - "Agent loop phases (parse, plan, execute, report)"
    - "Output judgment (accept vs reject agent suggestions)"
    - "Autonomous invocation (scheduled tasks without prompting)"
    - "Daily workflow design (personalized briefing)"
  assessment: "5 concepts grounded in hands-on practice at A2 -- within budget"

differentiation:
  extension_for_advanced: "Design a 3-task workflow chain where each task builds on the previous task's output. Configure it to run on a weekly schedule."
  remedial_for_struggling: "Focus on Tasks 1 and 4 only. For Task 1, just do the research. For Task 4, configure the simplest possible briefing (check files modified yesterday). Skip iteration steps."

teaching_guide:
  lesson_type: "hands-on"
  session_group: 1
  session_title: "Doing Real Work with Your AI Employee"
  key_points:
    - "The agent loop (parse, plan, execute, report) is the conceptual backbone — students will see it formalized in Lesson 4's architecture deep-dive"
    - "The shift from reactive (Tasks 1-3) to autonomous (Task 4) is THE pivotal moment in this chapter — it is what separates an AI Employee from a chatbot"
    - "Iteration skill matters more than first-draft quality — the lesson teaches students to give specific feedback ('add X, remove Y') rather than vague ('make it better')"
    - "Students leave with real artifacts (competitors.md, weekly-goals.md, morning briefing) — this is intentional: tangible output builds confidence"
  misconceptions:
    - "Students think the agent's first output should be perfect — emphasize that first drafts are cheap and their judgment is the expensive part"
    - "Students treat the morning briefing as a demo exercise — stress that it actually runs tomorrow at 8 AM if configured correctly, making it the first real autonomous AI they have deployed"
    - "Students confuse 'the agent planned the steps' with 'I told it each step' — in Task 3 the agent autonomously sequences research-write-analyze from a single instruction"
    - "Students think disagreeing with agent output means the agent failed — the goals iteration task explicitly teaches that override is a feature, not a bug"
  discussion_prompts:
    - "When the agent ranked your weekly goals differently than you would, was its reasoning valid even if you disagreed? What does that tell you about when to trust vs override AI judgment?"
    - "What is the difference between automating a task and delegating it? Which did you do in Task 4?"
    - "If your morning briefing ran for a week, what would you change about it? How would you know if it was actually saving you time?"
  teaching_tips:
    - "Have students share their Task 1 competitor tables — different industries reveal how the agent adapts research to domain context"
    - "Task 2's 'explain your reasoning' prompt is the most teachable moment: model this interaction live, showing that requesting explanations is a professional delegation skill"
    - "Time pressure matters — enforce the 6-minute limits per task so students experience that iteration has diminishing returns"
    - "For Task 4, walk the room and check that students configure their actual role, not a generic placeholder — personal relevance drives retention"
  assessment_quick_check:
    - "Ask students to name the four phases of the agent loop in order"
    - "Ask: What is the difference between Tasks 1-3 and Task 4? (reactive vs autonomous)"
    - "Have students open one of their artifact files and describe one edit they made to agent output and why"
---

# Your First Real Work

In Lesson 2, you installed OpenClaw, connected Telegram, and confirmed your AI Employee responds. That proved the wiring works. Now make it earn its keep.

Over the next 30 minutes, you will build artifacts you keep, iterate on output you disagree with, and configure a daily workflow that runs while you sleep. Four tasks. You walk away with real files on your machine and a working morning briefing on your phone.

:::tip Using a Different Channel?
If you set up Discord, Slack, or WhatsApp instead of Telegram, use that channel for these tasks. You can also use the Control UI at `http://127.0.0.1:18789/` or `openclaw tui` in your terminal. The tasks work identically across all channels.
:::

---

## Part A: Reactive Tasks (12 minutes)

### Task 1: Research and Edit (6 minutes)

Type this into your AI Employee:

```
Research the top 3 competitors in [your industry]. Create a comparison
table with pricing, features, and target market for each.
```

Replace `[your industry]` with your actual field. Healthcare software, online education, local restaurants -- use something real.

The agent researches, structures, and delivers a comparison table. Read the output carefully. Something will be wrong or incomplete -- a missing column, an outdated price, a competitor you know they missed.

Now iterate. Type a follow-up:

```
Add a column for [something you noticed was missing] and correct
[something that was wrong]. Save the updated table to competitors.md.
```

Open the file. You now have an artifact on your machine -- not a chat message that scrolls away, but a file you can edit, share, and reference tomorrow.

**Takeaway:** The value is not what the agent produces. It is what YOU produce by editing agent output. First drafts are cheap. Your judgment is the expensive part.

---

### Task 2: Weekly Goals and Iteration (6 minutes)

```
Create a file called weekly-goals.md with 5 professional goals
for this week, formatted as a markdown checklist. Make the goals
realistic for someone in [your role].
```

The agent creates the file. Open it and read the goals. You will probably disagree with the ranking. Good. Type:

```
Explain why you ranked goal #1 highest. I think [goal #3 or whichever
you disagree with] is more urgent because [your reason].
```

The agent explains its reasoning. It might convince you -- or you might override it. Either outcome is correct. Accept the suggestions that make sense. Reject the ones that do not. Update the file with your final version.

**Takeaway:** An employee who never pushes back is useless. An employee who explains their reasoning and lets you override is valuable. You just experienced the second kind.

---

## Part B: Multi-Step Foundation (5 minutes)

### Task 3: Research Pipeline (5 minutes)

```
Research the latest trends in [your field] for 2026, summarize the
key findings in a file called trends-report.md, then suggest 3
action items I could implement this quarter.
```

One instruction. Four operations: research, synthesize, write to file, analyze for recommendations. The agent sequences them without you managing the steps.

Check the file. The agent chained research into writing into analysis -- each step feeding the next. This capability is what makes the next task possible.

**Takeaway:** You did not manage the steps. The agent planned and sequenced them. One instruction, four operations. This is the agent loop at full stretch.

---

## Part C: Your Daily Employee (13 minutes)

This is the task that turns a demo into a daily tool.

### Task 4: Configure Your Morning Briefing

**Step 1 -- Describe your needs (3 minutes):**

```
I work as [YOUR ROLE] and my priorities this quarter are [2-3 PRIORITIES].
Design a daily morning briefing that runs at 8 AM. It should check
my recent files, summarize what I worked on yesterday, and suggest
priorities for today. Send it to me on [Telegram/your channel].
```

**Step 2 -- Review the proposal (3 minutes):**

The agent suggests a briefing structure. Read it. Is this what you would actually want to see at 8 AM? Type feedback:

```
Add [something useful it missed]. Remove [something you don't need].
Make the priorities section shorter -- just bullet points, no explanations.
```

The agent adjusts.

**Step 3 -- Test it now (4 minutes):**

```
Run the morning briefing now so I can see what it looks like.
```

The agent produces a sample briefing. Evaluate it honestly: Would you read this at 8 AM? Would it change how you start your day? If not, iterate again until it would.

**Step 4 -- Set the schedule (3 minutes):**

Confirm the schedule. The agent configures the cron job or heartbeat. If your setup does not support scheduling, run `openclaw tui` each morning and type "run my morning briefing" -- you will automate it properly later.

**Takeaway:** Tasks 1-3 were reactive -- you asked, the agent responded. Task 4 is autonomous -- the agent works on YOUR schedule. Tomorrow at 8 AM, check your phone. Your employee already clocked in.

---

## The Agent Loop

Every task you ran followed the same four phases:

**Parse** -- The agent read your natural language and understood your intent. When you said "research competitors," it inferred what "competitors" means for your industry without you spelling it out.

**Plan** -- Before producing output, it decided what to do and in what order. The research pipeline (Task 3) required sequencing research before writing before analysis. You never specified the order.

**Execute** -- It called tools as needed: web search, file creation, file reading. When the pipeline task required reading a file it had just written, it did so automatically.

**Report** -- It formatted results for you: tables for comparisons, checklists for goals, prose for reports. Format matched context, not a rigid template.

Task 4 added **autonomous invocation** on top of the same loop. The agent does not wait for your message. It fires on a schedule, runs the same parse-plan-execute-report cycle, and delivers the result to your phone. That single addition -- acting without being prompted -- is what separates an AI Employee from an AI tool.

---

## What Works Well vs What Doesn't

### Tasks Where AI Employees Excel

| Task Type                      | Why It Works Well                                                    | Example                                                    |
| ------------------------------ | -------------------------------------------------------------------- | ---------------------------------------------------------- |
| **Research and summarization** | Processes large volumes of information faster than manual reading    | Competitor analysis, trend reports, literature reviews     |
| **Professional writing**       | Adapts tone, format, and structure to natural language constraints   | Emails, proposals, reports, documentation                  |
| **File management**            | Creates, reads, modifies, and organizes files without manual effort  | Goal lists, meeting notes, project templates               |
| **Structured analysis**        | Applies consistent criteria across items without fatigue             | Priority ranking, pros/cons tables, comparison matrices    |
| **Multi-step workflows**       | Chains operations that would require context-switching between tools | Research-to-report pipelines, data-to-recommendation flows |

### Tasks Where AI Employees Struggle

| Task Type                               | Why It Struggles                                                                 | What to Do Instead                                            |
| --------------------------------------- | -------------------------------------------------------------------------------- | ------------------------------------------------------------- |
| **Tasks requiring real-time data**      | Training data has a cutoff; web access varies by provider                        | Verify recency of time-sensitive claims; provide current data |
| **Highly subjective decisions**         | No access to your personal values, relationships, or organizational politics     | Use the agent for analysis; make the final judgment yourself  |
| **Tasks requiring external services**   | Unless you configured specific integrations, the agent cannot access them        | Connect services as needed in later lessons                   |
| **Very long, complex workflows**        | Context windows have limits; earlier instructions may lose fidelity              | Break long workflows into smaller steps                       |
| **Creative work requiring originality** | Produces competent, pattern-based output; genuine novelty requires human insight | Use for first drafts; inject your own creative direction      |

AI Employees are strongest at tasks that are **information-heavy, structure-dependent, and repeatable**. They are weakest at tasks requiring **real-time awareness, subjective judgment, or genuine creativity**. Most professional work falls between, which is exactly why the employee model works -- delegate the mechanical parts, apply your judgment to the parts that matter.

On free tiers (Gemini Flash, Kimi K2.5), this lesson costs nothing. On paid models, expect $0.01-0.10 per task -- less than a dollar for the entire lesson.

---

You now have two artifacts (a competitor research table and a weekly goals file) and a configured morning briefing. Tomorrow at 8 AM, your agent delivers its first autonomous report. In Lesson 4, you will open the hood and see exactly how the agent loop and scheduling system work under the surface.

---

## Try With AI

### Prompt 1 -- Refine Your Briefing

```
My morning briefing was [useful/not useful enough]. Here's what
I'd change: [YOUR FEEDBACK]. Update the briefing configuration
and run it again so I can compare.
```

**What you're learning:** Iteration is the skill. The first version is never the final version. Learning to give specific feedback ("add X, remove Y") instead of vague feedback ("make it better") is what makes AI delegation effective.

### Prompt 2 -- Capability Boundaries

```
What tasks are AI Employees currently good at vs bad at? Create
a 2-column table with 8 entries each. For each weakness, note
whether it's temporary (will improve) or fundamental (needs human judgment).
```

**What you're learning:** Calibrating expectations prevents frustration. Knowing the boundaries shapes how you invest your time -- you focus on tasks where AI saves hours and handle the rest yourself.

### Prompt 3 -- Design Your Work Routine

```
Design a full daily AI Employee routine for my role ([YOUR ROLE]).
What should it do in the morning, during work hours, and at end of day?
```

**What you're learning:** Thinking in workflows rather than individual tasks. A daily routine combines research, analysis, and scheduling into automated sequences -- the foundation for building an always-on employee.
