### Core Concept
The Two-Way Problem: getting your tacit knowledge INTO the AI (unwritten rules, institutional history, professional judgment) and extracting understanding FROM what the AI generates. Both directions are essential—one without the other creates blind spots.

### Key Mental Models
- **Tacit vs Explicit Knowledge**: Tacit knowledge is what you'd tell a colleague over coffee but never write down—client preferences, historical decisions, unwritten rules. Documentation captures explicit knowledge; tacit knowledge requires deliberate extraction.
- **Memory Scoping**: Global memory persists across all sessions (style preferences, firm standards). Session memory is current context only (today's task state). Over-globalizing creates noise; under-globalizing means re-explaining preferences every session.
- **Examples Over Rules**: "Write clearly" is vague. Showing GOOD vs BAD examples gives AI concrete patterns to match against, not rules to interpret.

### Critical Patterns
- Structure context documents FOR AI: include explicit constraints, the "why" behind decisions, and what NOT to do
- Require explanations before deliverables: "Before drafting, explain your approach and reasoning"
- Use progressive review: break complex work into chunks so understanding builds incrementally
- Apply the Rubber Duck Test: explain AI-generated work back to verify your own understanding

### Common Mistakes
- Writing AI context the way you'd write for humans—assuming shared experience that AI doesn't have
- Accepting deliverables without understanding the reasoning—you can't defend work you don't comprehend
- Storing changing information (current priorities, meeting times) as global memory—creates staleness

### Connections
- **Builds on**: Context architecture and lean CLAUDE.md (Lessons 2-4)
- **Leads to**: Context lifecycle management with /clear and /compact (Lesson 6)
