# Part 8: LLMOps Proprietary Intelligence â€” Lesson Plans (Chapters 67-72)

**Generated by**: chapter-planner v2.0.0 (Reasoning-Activated)
**Source Spec**: specs/001-part8-llmops/spec.md
**Created**: 2026-01-01
**Constitution**: v7.0.0 (Agent Factory Paradigm)

---

## Overview: Chapters 67-72 Structure

These chapters cover Stage 2-4 of Part 8's LLMOps pipeline:

| Stage | Chapters | Focus |
|-------|----------|-------|
| Stage 2: Data & Training | 67 | Model Merging & Optimization |
| Stage 3: Evaluation & Quality | 68, 69 | Alignment & Safety, Evaluation & Quality Gates |
| Stage 4: Deployment & Operations | 70, 71, 72 | Deployment & Serving, Agent Integration, Capstone |

**Proficiency Level**: B2-C1 (Intermediate to Advanced)
**Constraint**: All training workflows must run on Colab Free Tier (T4 GPU, 4-bit quantization)

---

## Chapter 67: Model Merging & Optimization

**Title**: Model Merging & Optimization
**Description**: Combine multiple LoRA adapters and optimize models for production using MergeKit and reasoning distillation techniques.

### Chapter Analysis

**Chapter Type**: Technical (code-focused with production patterns)

**Concept Density Analysis**:
- Core Concepts: 8 concepts
  1. Adapter merging fundamentals
  2. MergeKit installation and setup
  3. TIES merge strategy
  4. SLERP merge strategy
  5. DARE merge strategy
  6. Sharded loading for RAM constraints
  7. Reasoning distillation introduction
  8. Production model export

**Complexity Assessment**: Standard (8 concepts, production-focused)
**Proficiency Tier**: B2
**Justified Lesson Count**: 7 lessons

### Success Evals (from Spec)

- SC-001: Training runs complete on T4 with <5% OOM failure rate
- SC-007: 80%+ students complete Part 8 with deployable model
- Merge operations complete within 12GB RAM constraint

### Lesson Sequence

| # | Title | Layer | Duration | Key Outcome |
|---|-------|-------|----------|-------------|
| 0 | Build Your Model Merging Skill | L1 | 25 min | Skill from official docs |
| 1 | Adapter Merging Fundamentals | L1 | 45 min | Understand why merge vs train |
| 2 | MergeKit Setup and Configuration | L1 | 40 min | Working MergeKit environment |
| 3 | TIES, SLERP, and DARE Strategies | L1 | 50 min | Choose strategy by use case |
| 4 | Sharded Merging for RAM Constraints | L1 | 45 min | Merge on 12GB RAM |
| 5 | Introduction to Reasoning Distillation | L2 | 50 min | Understand when to distill |
| 6 | Capstone: Merge Task API Adapters | L4 | 60 min | Production merged model |

**Total Duration**: 315 minutes (~5.25 hours)

---

### Lesson 0: Build Your Model Merging Skill

**Learning Objective**: Create a model-merging skill using MergeKit documentation

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 1): Skill creation from official docs

**Cognitive Load Validation**: 1 concept <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-008

**Content Elements**:
- Clone skills-lab fresh
- Write LEARNING-SPEC.md for model merging goals
- Fetch MergeKit documentation via Context7
- Create skill with merge strategies, RAM constraints

**Prerequisites**: Part 8 Chapters 61-66 completed

**Estimated Time**: 25 minutes

---

### Lesson 1: Adapter Merging Fundamentals

**Learning Objective**: Explain when and why to merge adapters vs train combined

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. Adapter composition problem
2. Merge vs retrain tradeoffs
3. Weight interpolation basics
4. Task interference
5. Merge use cases (persona + function calling)

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-007

**Content Elements**:
- Manual exploration of why separate adapters exist
- Diagram: Multiple LoRAs trained on different datasets
- Tradeoff analysis: merge (fast, approximate) vs retrain (slow, optimal)
- No AI assistance yet (Layer 1)

**Prerequisites**: Chapter 64 SFT, Chapter 65 persona tuning, Chapter 66 agentic tuning

**Estimated Time**: 45 minutes

---

### Lesson 2: MergeKit Setup and Configuration

**Learning Objective**: Install and configure MergeKit in Colab environment

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 4):
1. MergeKit installation
2. YAML configuration format
3. Model resolution (HuggingFace IDs)
4. Memory profiling setup

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-001, SC-002

**Content Elements**:
- Step-by-step Colab setup
- MergeKit config.yaml structure walkthrough
- Model paths and resolution
- Memory monitoring commands

**Running Example**: Setup for merging Task API persona + function-calling adapters

**Prerequisites**: Lesson 1

**Estimated Time**: 40 minutes

---

### Lesson 3: TIES, SLERP, and DARE Strategies

**Learning Objective**: Compare merge strategies and select appropriate strategy for use case

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 6):
1. TIES (TrIm, Elect, Sign & merge)
2. SLERP (Spherical Linear Interpolation)
3. DARE (Drop And REscale)
4. Parameter density impact
5. Strategy selection framework
6. Weight conflict resolution

**Cognitive Load Validation**: 6 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-003

**Content Elements**:
- Deep dive into each strategy with diagrams
- Decision framework: When to use which
- Configuration examples for each strategy
- Comparison table with tradeoffs

**Running Example**: Test TIES vs SLERP on Task API adapters

**Prerequisites**: Lesson 2

**Estimated Time**: 50 minutes

---

### Lesson 4: Sharded Merging for RAM Constraints

**Learning Objective**: Implement layer-by-layer merging to fit 12GB RAM constraint

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. Sharded weight loading
2. Layer-by-layer processing
3. Memory checkpoint patterns
4. Safetensors format
5. Disk-to-memory streaming

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-001, Edge case (MergeKit exceeds RAM)

**Content Elements**:
- Memory profiling during merge
- Sharded loading configuration
- Checkpoint and resume patterns
- OOM prevention strategies

**Running Example**: Merge 7B models on 12GB RAM

**Prerequisites**: Lesson 3

**Estimated Time**: 45 minutes

---

### Lesson 5: Introduction to Reasoning Distillation

**Learning Objective**: Evaluate when reasoning distillation adds value vs direct merging

**Stage**: 2 (AI Collaboration with Three Roles)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. Reasoning distillation concept
2. Teacher-student training
3. Chain-of-thought transfer
4. When distillation adds value
5. Distillation vs fine-tuning

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-003

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI explains distillation patterns student didn't know (intermediate reasoning tokens)
2. **AI as Student**: Student teaches AI their Task API domain constraints for distillation dataset design
3. **AI as Co-Worker**: Iterate on whether distillation is needed for Task API use case (possibly conclude: not yet)

**Content Elements**:
- Conceptual introduction (not hands-on training yet)
- Decision framework: When is distillation worth the effort?
- Comparison with model merging approaches
- AI collaboration on Task API suitability

**Prerequisites**: Lessons 1-4

**Estimated Time**: 50 minutes

---

### Lesson 6: Capstone: Merge Task API Adapters

**Learning Objective**: Produce a merged model combining persona and function-calling adapters

**Stage**: 4 (Spec-Driven Integration)
**CEFR Proficiency**: B2

**Maps to Evals**: SC-007, SC-008

**Content Elements**:
1. **Specification Writing** (PRIMARY):
   - Intent: Merge Task API persona + agentic adapters
   - Constraints: 12GB RAM, T4 GPU compatible
   - Success criteria: Merged model passes both persona and tool-calling tests
2. **Skill Composition**:
   - Use model-merging skill from L00
   - Apply TIES strategy from L03
   - Apply sharded loading from L04
3. **AI Orchestration**:
   - AI implements merge using composed skills
   - Student validates output quality
4. **Validation**:
   - Test persona responses
   - Test function-calling accuracy
   - Compare to individual adapters

**Prerequisites**: Lessons 0-5, Chapter 65-66 adapters

**Estimated Time**: 60 minutes

---

## Chapter 68: Alignment & Safety

**Title**: Alignment & Safety
**Description**: Apply DPO alignment and safety guardrails to ensure fine-tuned models refuse harmful requests and follow instructions reliably.

### Chapter Analysis

**Chapter Type**: Technical (safety-critical with ethical considerations)

**Concept Density Analysis**:
- Core Concepts: 9 concepts
  1. Alignment fundamentals (why models need alignment)
  2. DPO vs RLHF comparison
  3. Preference dataset creation
  4. DPO training implementation
  5. Red-teaming basics
  6. Jailbreak detection
  7. Refusal training
  8. Toxicity filtering
  9. Safety evaluation metrics

**Complexity Assessment**: Complex (9 concepts, safety-critical domain)
**Proficiency Tier**: B2-C1
**Justified Lesson Count**: 8 lessons

### Success Evals (from Spec)

- SC-006: DPO-aligned models reduce harmful output rate by 90%+
- FR-019: DPO covered (not RLHF)
- FR-020: Red-teaming basics included
- FR-021: Safety guardrails covered

### Lesson Sequence

| # | Title | Layer | Duration | Key Outcome |
|---|-------|-------|----------|-------------|
| 0 | Build Your Alignment Skill | L1 | 25 min | Skill from official docs |
| 1 | Why Models Need Alignment | L1 | 35 min | Understand alignment motivation |
| 2 | DPO vs RLHF: Choosing Simplicity | L1 | 40 min | Justify DPO approach |
| 3 | Creating Preference Datasets | L1 | 50 min | Build chosen/rejected pairs |
| 4 | DPO Training Implementation | L1 | 55 min | Run DPO on Colab T4 |
| 5 | Red-Teaming and Jailbreak Detection | L2 | 50 min | Adversarial testing |
| 6 | Refusal Training and Safety Guardrails | L2 | 45 min | Implement refusal behaviors |
| 7 | Capstone: Align Task API Model | L4 | 60 min | 90%+ harmful reduction |

**Total Duration**: 360 minutes (6 hours)

---

### Lesson 0: Build Your Alignment Skill

**Learning Objective**: Create an alignment skill using TRL DPO documentation

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 1): Skill creation for alignment

**Content Elements**:
- Fetch TRL DPOTrainer documentation via Context7
- Create skill with preference dataset patterns
- Include safety evaluation templates

**Estimated Time**: 25 minutes

---

### Lesson 1: Why Models Need Alignment

**Learning Objective**: Explain why fine-tuned models can produce harmful outputs and why alignment matters

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 4):
1. Capability vs alignment distinction
2. Misuse potential after fine-tuning
3. Instruction-following drift
4. Real-world alignment failures (case studies)

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-006

**Content Elements**:
- Case studies of misaligned model outputs
- Why SFT alone is insufficient
- The alignment gap concept
- No AI assistance (Layer 1 foundation)

**Running Example**: Task API model giving incorrect/harmful task advice

**Estimated Time**: 35 minutes

---

### Lesson 2: DPO vs RLHF: Choosing Simplicity

**Learning Objective**: Compare DPO and RLHF and justify DPO for practitioner workflows

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. RLHF workflow (reward model + PPO)
2. DPO direct optimization
3. Preference modeling basics
4. Compute requirements comparison
5. Stability and convergence differences

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: FR-019

**Content Elements**:
- Side-by-side workflow comparison
- Why RLHF is out of scope (reward model training complexity)
- DPO mathematical intuition (without full derivation)
- Decision framework: When each approach applies

**Estimated Time**: 40 minutes

---

### Lesson 3: Creating Preference Datasets

**Learning Objective**: Construct preference datasets with prompt/chosen/rejected format

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 6):
1. Preference dataset structure
2. Prompt/chosen/rejected format
3. Quality criteria for chosen responses
4. Generating rejected responses
5. Domain-specific preference pairs
6. Dataset size requirements

**Cognitive Load Validation**: 6 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-006, FR-021

**Content Elements**:
- JSONL format for preferences
- Manual creation of 50 preference pairs
- Using GPT-4o-mini for synthetic rejected generation
- Quality validation checklist

**Running Example**: Create Task API preference dataset (helpful vs harmful task guidance)

**Estimated Time**: 50 minutes

---

### Lesson 4: DPO Training Implementation

**Learning Objective**: Run DPO training on Colab T4 GPU using TRL DPOTrainer

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 6):
1. TRL DPOTrainer API
2. Beta parameter tuning
3. Reference model handling
4. 4-bit quantization for DPO
5. Training hyperparameters
6. Loss curve interpretation

**Cognitive Load Validation**: 6 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-001, SC-002, SC-006

**Content Elements**:
- Step-by-step Colab notebook
- DPOTrainer configuration
- Memory optimization for T4
- Training monitoring

**Running Example**: DPO train Task API model on preference dataset

**Estimated Time**: 55 minutes

---

### Lesson 5: Red-Teaming and Jailbreak Detection

**Learning Objective**: Design adversarial tests to identify model vulnerabilities

**Stage**: 2 (AI Collaboration with Three Roles)
**CEFR Proficiency**: C1
**New Concepts** (count: 5):
1. Red-teaming methodology
2. Common jailbreak categories
3. Prompt injection attacks
4. Role-playing exploits
5. Adversarial test design

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: FR-020

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI suggests jailbreak patterns student hadn't considered
2. **AI as Student**: Student teaches AI Task API-specific attack vectors
3. **AI as Co-Worker**: Collaboratively build red-team test suite

**Content Elements**:
- Categories of jailbreak attacks
- Red-team prompt templates
- Systematic vulnerability assessment
- AI collaboration on adversarial dataset

**Running Example**: Red-team Task API model for harmful task creation

**Estimated Time**: 50 minutes

---

### Lesson 6: Refusal Training and Safety Guardrails

**Learning Objective**: Implement refusal behaviors and toxicity filtering

**Stage**: 2 (AI Collaboration with Three Roles)
**CEFR Proficiency**: C1
**New Concepts** (count: 5):
1. Refusal response patterns
2. Toxicity detection integration
3. Output filtering pipelines
4. Safety system prompts
5. Graceful degradation

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: FR-021, SC-006

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI suggests refusal patterns from safety research
2. **AI as Student**: Student teaches AI acceptable refusal tone for Task API
3. **AI as Co-Worker**: Iterate on refusal message design

**Content Elements**:
- Training data for refusal responses
- Perspective API integration for toxicity
- System prompt guardrails
- Fallback behavior design

**Running Example**: Add refusal behavior to Task API model

**Estimated Time**: 45 minutes

---

### Lesson 7: Capstone: Align Task API Model

**Learning Objective**: Produce DPO-aligned model with 90%+ reduction in harmful outputs

**Stage**: 4 (Spec-Driven Integration)
**CEFR Proficiency**: C1

**Maps to Evals**: SC-006

**Content Elements**:
1. **Specification Writing**:
   - Intent: Align Task API model to refuse harmful requests
   - Constraints: T4 GPU, 90%+ harm reduction target
   - Success criteria: Pass red-team evaluation, maintain task accuracy
2. **Skill Composition**:
   - Use alignment skill from L00
   - Apply preference dataset from L03
   - Apply DPO training from L04
   - Apply safety evaluation from L05-06
3. **AI Orchestration**:
   - AI implements alignment pipeline
   - Student validates safety metrics
4. **Validation**:
   - Run red-team test suite
   - Measure harm reduction percentage
   - Verify task accuracy retention

**Prerequisites**: Lessons 0-6, Chapter 64-66 fine-tuned model

**Estimated Time**: 60 minutes

---

## Chapter 69: Evaluation & Quality Gates

**Title**: Evaluation & Quality Gates
**Description**: Implement systematic model evaluation using LLM-as-a-Judge, task-specific benchmarks, and regression testing.

### Chapter Analysis

**Chapter Type**: Technical (evaluation infrastructure)

**Concept Density Analysis**:
- Core Concepts: 7 concepts
  1. Evaluation taxonomy (task vs safety vs quality)
  2. LLM-as-a-Judge methodology
  3. Task-specific benchmarks
  4. Regression testing for models
  5. Quality thresholds and gates
  6. Automated evaluation pipelines
  7. Evaluation-driven iteration

**Complexity Assessment**: Standard (7 concepts, critical for production)
**Proficiency Tier**: B2
**Justified Lesson Count**: 7 lessons

### Success Evals (from Spec)

- SC-003: 20%+ improvement on domain benchmarks vs base model
- SC-005: 95%+ JSON syntax accuracy for tool-calling
- SC-006: 90%+ harmful output reduction measurable

### Lesson Sequence

| # | Title | Layer | Duration | Key Outcome |
|---|-------|-------|----------|-------------|
| 0 | Build Your Evaluation Skill | L1 | 25 min | Skill from official docs |
| 1 | Evaluation Taxonomy and Strategy | L1 | 40 min | Understand what to measure |
| 2 | LLM-as-a-Judge Implementation | L1 | 50 min | GPT-4 evaluation setup |
| 3 | Task-Specific Benchmark Design | L1 | 50 min | Custom Task API benchmarks |
| 4 | Regression Testing for Models | L2 | 45 min | Detect quality degradation |
| 5 | Quality Gates and Thresholds | L2 | 40 min | Define pass/fail criteria |
| 6 | Capstone: Evaluation Pipeline | L4 | 60 min | Automated quality system |

**Total Duration**: 310 minutes (~5.2 hours)

---

### Lesson 0: Build Your Evaluation Skill

**Learning Objective**: Create an evaluation skill using TRL and LLM-as-a-Judge patterns

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 1): Skill creation for evaluation

**Content Elements**:
- Fetch evaluation documentation
- Create skill with benchmark templates
- Include LLM-as-a-Judge prompts

**Estimated Time**: 25 minutes

---

### Lesson 1: Evaluation Taxonomy and Strategy

**Learning Objective**: Categorize evaluation types and design evaluation strategy

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. Task accuracy evaluation
2. Safety/alignment evaluation
3. Quality/coherence evaluation
4. Latency/efficiency evaluation
5. Evaluation strategy design

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Content Elements**:
- Evaluation taxonomy diagram
- What to measure at each stage
- Evaluation frequency decisions
- No AI assistance (Layer 1)

**Running Example**: Design evaluation strategy for Task API model

**Estimated Time**: 40 minutes

---

### Lesson 2: LLM-as-a-Judge Implementation

**Learning Objective**: Implement GPT-4-based evaluation for subjective quality metrics

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 6):
1. LLM-as-a-Judge concept
2. Evaluation prompt design
3. Rubric specification
4. Inter-rater reliability
5. Cost optimization for evaluation
6. Batch evaluation patterns

**Cognitive Load Validation**: 6 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-003

**Content Elements**:
- Judge prompt templates
- GPT-4o-mini as evaluator (cost-effective)
- Rubric design patterns
- Output parsing and aggregation

**Running Example**: GPT-4 judges Task API response quality

**Estimated Time**: 50 minutes

---

### Lesson 3: Task-Specific Benchmark Design

**Learning Objective**: Create custom benchmarks measuring domain-specific capabilities

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. Benchmark dataset creation
2. Ground truth labeling
3. Metric selection (accuracy, F1, BLEU)
4. Benchmark versioning
5. Leaderboard tracking

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-003, SC-005

**Content Elements**:
- Create 100-example Task API benchmark
- Ground truth for task creation quality
- Structured output accuracy metrics
- Baseline vs fine-tuned comparison

**Running Example**: Task API task-creation benchmark

**Estimated Time**: 50 minutes

---

### Lesson 4: Regression Testing for Models

**Learning Objective**: Detect quality degradation after model updates

**Stage**: 2 (AI Collaboration with Three Roles)
**CEFR Proficiency**: B2
**New Concepts** (count: 4):
1. Model regression concept
2. Golden test sets
3. Threshold-based alerting
4. CI/CD integration for models

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI suggests regression test categories student missed
2. **AI as Student**: Student teaches AI Task API-specific regression scenarios
3. **AI as Co-Worker**: Collaboratively build regression test suite

**Content Elements**:
- Golden test set maintenance
- Before/after comparison patterns
- Alert thresholds for degradation
- Automated regression in pipelines

**Estimated Time**: 45 minutes

---

### Lesson 5: Quality Gates and Thresholds

**Learning Objective**: Define pass/fail criteria for model deployment

**Stage**: 2 (AI Collaboration with Three Roles)
**CEFR Proficiency**: B2
**New Concepts** (count: 4):
1. Quality gate concept
2. Threshold determination
3. Multi-metric gates
4. Override and exception handling

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI suggests threshold calibration methods
2. **AI as Student**: Student teaches AI acceptable risk levels for Task API
3. **AI as Co-Worker**: Iterate on gate thresholds

**Content Elements**:
- Threshold setting methodology
- Gate composition (all must pass)
- Exception handling for edge cases
- Gate documentation

**Running Example**: Define gates for Task API model deployment

**Estimated Time**: 40 minutes

---

### Lesson 6: Capstone: Evaluation Pipeline

**Learning Objective**: Build automated evaluation pipeline for continuous model quality

**Stage**: 4 (Spec-Driven Integration)
**CEFR Proficiency**: B2

**Maps to Evals**: SC-003, SC-005, SC-006

**Content Elements**:
1. **Specification Writing**:
   - Intent: Automated evaluation on every model update
   - Constraints: <5 min evaluation time, <$0.10 per run
   - Success criteria: Gates catch 95%+ of quality regressions
2. **Skill Composition**:
   - Use evaluation skill from L00
   - Apply LLM-as-Judge from L02
   - Apply benchmarks from L03
   - Apply gates from L05
3. **AI Orchestration**:
   - AI implements pipeline
   - Student validates threshold settings
4. **Validation**:
   - Run on Task API model versions
   - Verify gate behavior
   - Measure cost and latency

**Estimated Time**: 60 minutes

---

## Chapter 70: Deployment & Serving

**Title**: Deployment & Serving
**Description**: Export fine-tuned models to GGUF format and deploy locally via Ollama or at scale via vLLM.

### Chapter Analysis

**Chapter Type**: Technical (production deployment)

**Concept Density Analysis**:
- Core Concepts: 8 concepts
  1. Model export formats (GGUF, safetensors)
  2. Quantization for serving (Q4, Q8)
  3. Ollama installation and setup
  4. Local model serving
  5. vLLM architecture (theory)
  6. Performance optimization
  7. Latency vs quality tradeoffs
  8. Production serving patterns

**Complexity Assessment**: Standard (8 concepts, deployment-focused)
**Proficiency Tier**: B2
**Justified Lesson Count**: 8 lessons

### Success Evals (from Spec)

- SC-004: <500ms latency on consumer hardware via Ollama
- SC-001: Complete workflow in under 4 hours

### Lesson Sequence

| # | Title | Layer | Duration | Key Outcome |
|---|-------|-------|----------|-------------|
| 0 | Build Your Model Serving Skill | L1 | 25 min | Skill from official docs |
| 1 | Model Export Formats | L1 | 40 min | Understand GGUF, safetensors |
| 2 | Quantization for Serving | L1 | 45 min | Choose Q4 vs Q8 tradeoffs |
| 3 | Ollama Installation and Setup | L1 | 35 min | Working Ollama environment |
| 4 | Local Model Serving | L1 | 45 min | Serve custom model locally |
| 5 | vLLM Architecture (Theory) | L1 | 40 min | Understand production serving |
| 6 | Performance Optimization | L2 | 50 min | Optimize latency/throughput |
| 7 | Capstone: Deploy Task API Model | L4 | 60 min | Production-ready local serving |

**Total Duration**: 340 minutes (~5.7 hours)

---

### Lesson 0: Build Your Model Serving Skill

**Learning Objective**: Create a model serving skill using Ollama and GGUF documentation

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 1): Skill creation for serving

**Content Elements**:
- Fetch Ollama documentation via Context7
- Fetch llama.cpp GGUF documentation
- Create skill with export and serving patterns

**Estimated Time**: 25 minutes

---

### Lesson 1: Model Export Formats

**Learning Objective**: Compare model export formats and select appropriate format

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. Safetensors format
2. GGUF format
3. GGML legacy format
4. Format conversion tools
5. Format selection criteria

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Content Elements**:
- Format comparison table
- When to use each format
- Conversion with llama.cpp
- No AI assistance (Layer 1)

**Running Example**: Export Task API model to GGUF

**Estimated Time**: 40 minutes

---

### Lesson 2: Quantization for Serving

**Learning Objective**: Apply serving quantization to reduce memory and improve latency

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 6):
1. Post-training quantization
2. Q4_K_M vs Q8_0 comparison
3. Quality vs size tradeoffs
4. Memory footprint calculation
5. Quantization with llama.cpp
6. Quality validation after quantization

**Cognitive Load Validation**: 6 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-004

**Content Elements**:
- Quantization levels comparison
- Memory calculator for different quants
- Quality benchmark before/after
- Consumer hardware requirements

**Running Example**: Quantize Task API model to Q4_K_M

**Estimated Time**: 45 minutes

---

### Lesson 3: Ollama Installation and Setup

**Learning Objective**: Install Ollama and configure for custom model loading

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 4):
1. Ollama installation (macOS, Linux, Windows)
2. Modelfile format
3. Custom model registration
4. Ollama CLI commands

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Content Elements**:
- Step-by-step installation
- Modelfile creation for custom GGUF
- Model registration with ollama create
- Basic ollama commands

**Running Example**: Register Task API model with Ollama

**Estimated Time**: 35 minutes

---

### Lesson 4: Local Model Serving

**Learning Objective**: Serve custom model via Ollama API

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. Ollama REST API
2. /api/generate endpoint
3. /api/chat endpoint
4. Streaming responses
5. Python client integration

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-004

**Content Elements**:
- Ollama API documentation walkthrough
- curl examples for testing
- Python client code
- Latency measurement

**Running Example**: Serve Task API model and measure latency

**Estimated Time**: 45 minutes

---

### Lesson 5: vLLM Architecture (Theory)

**Learning Objective**: Understand vLLM for production-scale serving

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. vLLM PagedAttention
2. Continuous batching
3. GPU memory management
4. vLLM vs Ollama comparison
5. When vLLM is appropriate

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Content Elements**:
- Theory only (vLLM requires GPU beyond Colab)
- Architecture diagrams
- Decision framework: Ollama vs vLLM
- Demo screenshots/videos

**Note**: Hands-on vLLM deferred due to GPU requirements

**Estimated Time**: 40 minutes

---

### Lesson 6: Performance Optimization

**Learning Objective**: Optimize serving latency and throughput through configuration

**Stage**: 2 (AI Collaboration with Three Roles)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. Context length optimization
2. Batch size tuning
3. Thread configuration
4. Memory mapping options
5. Profiling and monitoring

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-004

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI suggests optimization techniques student missed
2. **AI as Student**: Student teaches AI latency targets for Task API
3. **AI as Co-Worker**: Iterate on configuration optimization

**Content Elements**:
- Configuration parameter tuning
- Benchmarking methodology
- Latency profiling
- AI-assisted configuration

**Estimated Time**: 50 minutes

---

### Lesson 7: Capstone: Deploy Task API Model

**Learning Objective**: Deploy production-ready Task API model via Ollama with <500ms latency

**Stage**: 4 (Spec-Driven Integration)
**CEFR Proficiency**: B2

**Maps to Evals**: SC-001, SC-004

**Content Elements**:
1. **Specification Writing**:
   - Intent: Local deployment of Task API custom model
   - Constraints: <500ms latency, 8GB RAM consumer hardware
   - Success criteria: Functional API with measured latency
2. **Skill Composition**:
   - Use model serving skill from L00
   - Apply GGUF export from L01
   - Apply quantization from L02
   - Apply optimization from L06
3. **AI Orchestration**:
   - AI implements export and deployment
   - Student validates latency
4. **Validation**:
   - Latency benchmarks
   - Quality comparison to hosted model
   - Memory usage verification

**Estimated Time**: 60 minutes

---

## Chapter 71: Agent Framework Integration

**Title**: Agent Framework Integration
**Description**: Connect custom fine-tuned models as backends to OpenAI Agents SDK, Claude SDK, and Google ADK.

### Chapter Analysis

**Chapter Type**: Technical (integration patterns)

**Concept Density Analysis**:
- Core Concepts: 8 concepts
  1. Custom model as agent backend
  2. OpenAI SDK custom base_url
  3. LiteLLM proxy for SDK compatibility
  4. Tool-calling with custom models
  5. MCP server with custom backend
  6. FastAPI edge deployment
  7. Error handling for custom models
  8. Fallback to foundation models

**Complexity Assessment**: Standard (8 concepts, integration-focused)
**Proficiency Tier**: B2-C1
**Justified Lesson Count**: 8 lessons

### Success Evals (from Spec)

- SC-005: 95%+ JSON syntax accuracy for tool-calling
- User Story 2: Custom models in agentic workflows

### Lesson Sequence

| # | Title | Layer | Duration | Key Outcome |
|---|-------|-------|----------|-------------|
| 0 | Build Your Agent Integration Skill | L1 | 25 min | Skill from official docs |
| 1 | Custom Models as Agent Backends | L1 | 40 min | Understand integration patterns |
| 2 | LiteLLM Proxy for SDK Compatibility | L1 | 45 min | Unified API interface |
| 3 | OpenAI SDK with Custom Backend | L1 | 50 min | Working SDK integration |
| 4 | Tool-Calling with Custom Models | L2 | 55 min | 95%+ JSON accuracy |
| 5 | MCP Server with Custom Backend | L2 | 50 min | MCP-compatible endpoint |
| 6 | Error Handling and Fallbacks | L2 | 40 min | Production resilience |
| 7 | Capstone: Task API Agent | L4 | 60 min | Complete agent integration |

**Total Duration**: 365 minutes (~6 hours)

---

### Lesson 0: Build Your Agent Integration Skill

**Learning Objective**: Create an agent integration skill for custom model backends

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 1): Skill creation for integration

**Content Elements**:
- Fetch OpenAI SDK documentation
- Fetch LiteLLM documentation via Context7
- Create skill with integration patterns

**Estimated Time**: 25 minutes

---

### Lesson 1: Custom Models as Agent Backends

**Learning Objective**: Understand patterns for using custom models in agent frameworks

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. Agent backend architecture
2. OpenAI API compatibility
3. Custom base_url pattern
4. Model ID mapping
5. Token counting differences

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Content Elements**:
- Architecture diagram: Agent -> Custom Model
- API compatibility requirements
- Decision framework: When to use custom vs foundation
- No AI assistance (Layer 1)

**Running Example**: Task API agent architecture design

**Estimated Time**: 40 minutes

---

### Lesson 2: LiteLLM Proxy for SDK Compatibility

**Learning Objective**: Deploy LiteLLM proxy to provide unified OpenAI-compatible API

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. LiteLLM proxy concept
2. Ollama provider configuration
3. Model aliasing
4. Proxy deployment patterns
5. Request routing

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Content Elements**:
- LiteLLM installation and configuration
- Ollama as provider
- Model alias setup
- API testing with curl

**Running Example**: LiteLLM proxy for Task API model

**Estimated Time**: 45 minutes

---

### Lesson 3: OpenAI SDK with Custom Backend

**Learning Objective**: Connect OpenAI Agents SDK to custom model via LiteLLM

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. OpenAI SDK base_url override
2. Client configuration
3. Model parameter passing
4. Response parsing
5. SDK compatibility verification

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: User Story 2

**Content Elements**:
- OpenAI SDK client configuration
- base_url pointing to LiteLLM
- Simple agent test
- Comparison to hosted model

**Running Example**: Task API agent with custom backend

**Estimated Time**: 50 minutes

---

### Lesson 4: Tool-Calling with Custom Models

**Learning Objective**: Achieve 95%+ JSON syntax accuracy for structured outputs

**Stage**: 2 (AI Collaboration with Three Roles)
**CEFR Proficiency**: B2
**New Concepts** (count: 5):
1. Tool schema definition
2. Structured output prompting
3. JSON parsing and validation
4. Error recovery for malformed JSON
5. Accuracy measurement

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-005

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI suggests JSON prompting patterns
2. **AI as Student**: Student teaches AI Task API tool schemas
3. **AI as Co-Worker**: Iterate on prompt to reach 95% accuracy

**Content Elements**:
- Tool schema design for Task API
- Prompting for JSON outputs
- Validation and error handling
- Accuracy benchmarking

**Estimated Time**: 55 minutes

---

### Lesson 5: MCP Server with Custom Backend

**Learning Objective**: Create MCP server that uses custom model for reasoning

**Stage**: 2 (AI Collaboration with Three Roles)
**CEFR Proficiency**: C1
**New Concepts** (count: 5):
1. MCP server architecture
2. Tool registration
3. Custom model integration
4. Context injection
5. Response formatting

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI explains MCP patterns from Part 6
2. **AI as Student**: Student teaches AI Task API-specific tools
3. **AI as Co-Worker**: Build MCP server together

**Content Elements**:
- MCP server with FastMCP
- Custom model as reasoning engine
- Tool implementation for Task API
- Integration testing

**Estimated Time**: 50 minutes

---

### Lesson 6: Error Handling and Fallbacks

**Learning Objective**: Implement production resilience with fallback to foundation models

**Stage**: 2 (AI Collaboration with Three Roles)
**CEFR Proficiency**: B2
**New Concepts** (count: 4):
1. Error categorization (timeout, OOM, quality)
2. Fallback decision logic
3. Retry patterns
4. Graceful degradation

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI suggests error handling patterns
2. **AI as Student**: Student teaches AI acceptable degradation for Task API
3. **AI as Co-Worker**: Design fallback logic together

**Content Elements**:
- Error detection and categorization
- Fallback to GPT-4o-mini when custom fails
- Retry with exponential backoff
- Logging and alerting

**Estimated Time**: 40 minutes

---

### Lesson 7: Capstone: Task API Agent

**Learning Objective**: Deploy complete Task API agent with custom model backend

**Stage**: 4 (Spec-Driven Integration)
**CEFR Proficiency**: C1

**Maps to Evals**: SC-005, User Story 2, User Story 3

**Content Elements**:
1. **Specification Writing**:
   - Intent: Task API agent using custom fine-tuned model
   - Constraints: 95%+ tool-calling accuracy, fallback to GPT-4
   - Success criteria: Complete agent workflow with custom backend
2. **Skill Composition**:
   - Use agent integration skill from L00
   - Apply LiteLLM from L02
   - Apply SDK integration from L03
   - Apply tool-calling from L04
   - Apply error handling from L06
3. **AI Orchestration**:
   - AI implements agent
   - Student validates accuracy
4. **Validation**:
   - Tool-calling accuracy benchmark
   - Fallback behavior verification
   - End-to-end workflow test

**Estimated Time**: 60 minutes

---

## Chapter 72: Capstone: End-to-End LLMOps

**Title**: Capstone: End-to-End LLMOps
**Description**: Build complete LLMOps pipeline from data curation to production deployment, producing a Digital FTE outcome.

### Chapter Analysis

**Chapter Type**: Technical + Integration (capstone project)

**Concept Density Analysis**:
- Core Concepts: 10 concepts
  1. Pipeline architecture design
  2. Data curation workflow
  3. Training orchestration
  4. Evaluation integration
  5. Deployment automation
  6. Digital FTE productization
  7. Monitoring and observability
  8. Version control for models
  9. Continuous training patterns
  10. Business value demonstration

**Complexity Assessment**: Complex (10 concepts, full integration)
**Proficiency Tier**: C1
**Justified Lesson Count**: 9 lessons (capstone requires synthesis)

### Success Evals (from Spec)

- SC-001: Complete workflow in under 4 hours
- SC-007: 80%+ students complete with deployable model
- SC-008: Students have llmops-fine-tuner skill
- FR-011: Digital FTE outcome

### Lesson Sequence

| # | Title | Layer | Duration | Key Outcome |
|---|-------|-------|----------|-------------|
| 0 | Finalize Your LLMOps Skill | L3 | 30 min | Complete skill from Part 8 |
| 1 | Pipeline Architecture Design | L1 | 45 min | End-to-end architecture |
| 2 | Data Curation Workflow | L1 | 50 min | Automated data pipeline |
| 3 | Training Orchestration | L2 | 55 min | Reproducible training |
| 4 | Evaluation Integration | L2 | 50 min | Automated quality gates |
| 5 | Deployment Automation | L2 | 50 min | One-click deployment |
| 6 | Digital FTE Productization | L3 | 55 min | Business value packaging |
| 7 | Monitoring and Continuous Training | L2 | 45 min | Production observability |
| 8 | Capstone: Domain Expert Digital FTE | L4 | 75 min | Complete LLMOps product |

**Total Duration**: 455 minutes (~7.6 hours)

---

### Lesson 0: Finalize Your LLMOps Skill

**Learning Objective**: Consolidate all Part 8 learning into production-ready llmops-fine-tuner skill

**Stage**: 3 (Intelligence Design)
**CEFR Proficiency**: C1
**New Concepts** (count: 2): Skill consolidation, pattern synthesis

**Content Elements**:
- Review all skills created in Chapters 61-71
- Consolidate into comprehensive llmops-fine-tuner skill
- Add decision frameworks for when to use each component
- Document skill with official source references

**Maps to Evals**: SC-008

**Prerequisites**: All Part 8 chapters completed

**Estimated Time**: 30 minutes

---

### Lesson 1: Pipeline Architecture Design

**Learning Objective**: Design end-to-end LLMOps pipeline architecture

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: C1
**New Concepts** (count: 5):
1. Pipeline component identification
2. Data flow design
3. Artifact management
4. Stage dependencies
5. Pipeline visualization

**Cognitive Load Validation**: 5 concepts, C1 no limit -> WITHIN LIMIT

**Content Elements**:
- Full pipeline architecture diagram
- Stage identification (data -> train -> eval -> deploy)
- Artifact storage decisions
- Manual walkthrough (no AI yet)

**Running Example**: Task API LLMOps pipeline

**Estimated Time**: 45 minutes

---

### Lesson 2: Data Curation Workflow

**Learning Objective**: Automate data preparation pipeline

**Stage**: 1 (Manual Foundation)
**CEFR Proficiency**: C1
**New Concepts** (count: 5):
1. Data version control
2. Quality filtering automation
3. Schema validation
4. Synthetic data augmentation
5. Dataset registry

**Cognitive Load Validation**: 5 concepts, C1 no limit -> WITHIN LIMIT

**Content Elements**:
- Automated data quality checks
- DVC or simple versioning
- Synthetic data generation integration
- Dataset artifact management

**Running Example**: Task API training data pipeline

**Estimated Time**: 50 minutes

---

### Lesson 3: Training Orchestration

**Learning Objective**: Create reproducible training workflow with checkpointing

**Stage**: 2 (AI Collaboration with Three Roles)
**CEFR Proficiency**: C1
**New Concepts** (count: 5):
1. Training configuration management
2. Experiment tracking
3. Checkpoint management
4. Hyperparameter versioning
5. Training reproducibility

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI suggests experiment tracking patterns
2. **AI as Student**: Student teaches AI Task API-specific training needs
3. **AI as Co-Worker**: Design training workflow together

**Content Elements**:
- Configuration as code
- Weights & Biases or simple logging
- Checkpoint save/restore
- Reproducibility verification

**Estimated Time**: 55 minutes

---

### Lesson 4: Evaluation Integration

**Learning Objective**: Integrate evaluation pipeline with training workflow

**Stage**: 2 (AI Collaboration with Three Roles)
**CEFR Proficiency**: C1
**New Concepts** (count: 4):
1. Post-training evaluation triggers
2. Quality gate enforcement
3. Evaluation result storage
4. Pass/fail decision automation

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI suggests evaluation orchestration patterns
2. **AI as Student**: Student teaches AI Task API quality thresholds
3. **AI as Co-Worker**: Integrate evaluation gates

**Content Elements**:
- Automatic evaluation on training completion
- Quality gate enforcement
- Failure handling and rollback
- Evaluation artifact storage

**Estimated Time**: 50 minutes

---

### Lesson 5: Deployment Automation

**Learning Objective**: Automate model export and deployment

**Stage**: 2 (AI Collaboration with Three Roles)
**CEFR Proficiency**: C1
**New Concepts** (count: 5):
1. Export automation
2. Deployment triggers
3. Blue-green deployment concept
4. Rollback automation
5. Health checks

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI suggests deployment patterns
2. **AI as Student**: Student teaches AI Task API deployment constraints
3. **AI as Co-Worker**: Build deployment automation

**Content Elements**:
- GGUF export automation
- Ollama model update
- Version tracking
- Rollback capability

**Estimated Time**: 50 minutes

---

### Lesson 6: Digital FTE Productization

**Learning Objective**: Package LLMOps pipeline as sellable Digital FTE product

**Stage**: 3 (Intelligence Design)
**CEFR Proficiency**: C1
**New Concepts** (count: 5):
1. Digital FTE value proposition
2. Productization checklist
3. Pricing models for custom models
4. Documentation for customers
5. Support and maintenance patterns

**Content Elements**:
- Agent Factory thesis application
- Value proposition for Task API assistant
- Pricing model design (subscription vs license)
- Customer documentation template
- SLA definition

**Maps to Evals**: FR-011

**Estimated Time**: 55 minutes

---

### Lesson 7: Monitoring and Continuous Training

**Learning Objective**: Implement production monitoring and continuous improvement

**Stage**: 2 (AI Collaboration with Three Roles)
**CEFR Proficiency**: C1
**New Concepts** (count: 5):
1. Production monitoring metrics
2. Drift detection
3. Feedback collection
4. Continuous training triggers
5. Alerting and observability

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI suggests monitoring patterns from MLOps
2. **AI as Student**: Student teaches AI Task API monitoring needs
3. **AI as Co-Worker**: Design monitoring system

**Content Elements**:
- Response quality monitoring
- User feedback collection
- Trigger conditions for retraining
- Alerting configuration

**Estimated Time**: 45 minutes

---

### Lesson 8: Capstone: Domain Expert Digital FTE

**Learning Objective**: Build and deploy complete LLMOps pipeline producing Domain Expert Digital FTE

**Stage**: 4 (Spec-Driven Integration)
**CEFR Proficiency**: C1

**Maps to Evals**: SC-001, SC-007, SC-008, FR-011

**Content Elements**:
1. **Specification Writing** (PRIMARY):
   - Intent: Complete LLMOps pipeline for domain expertise productization
   - Constraints: Colab Free Tier, <$1 total cost, 4-hour completion
   - Success criteria: Deployed Digital FTE with agent integration

2. **Skill Composition**:
   - Use llmops-fine-tuner skill from L00
   - Compose all Part 8 skills:
     - Data engineering (Ch 63)
     - SFT training (Ch 64)
     - Model merging (Ch 67)
     - Alignment (Ch 68)
     - Evaluation (Ch 69)
     - Deployment (Ch 70)
     - Agent integration (Ch 71)

3. **AI Orchestration**:
   - AI implements complete pipeline
   - Student provides domain expertise
   - AI handles mechanical implementation
   - Student validates quality at each stage

4. **Validation**:
   - End-to-end pipeline execution
   - Quality gate passage
   - Deployment verification
   - Agent integration test
   - Business value demonstration

5. **Digital FTE Outcome**:
   - Deployed model serving requests
   - Agent integration working
   - Documentation complete
   - Pricing/packaging defined

**Prerequisites**: All Part 8 chapters (61-71)

**Estimated Time**: 75 minutes

---

## Skill Dependencies

### Skills Created in Chapters 67-72

| Chapter | Skill Name | Purpose |
|---------|------------|---------|
| 67 | model-merging | Adapter combination with MergeKit |
| 68 | model-alignment | DPO training and safety evaluation |
| 69 | model-evaluation | LLM-as-Judge and quality gates |
| 70 | model-serving | GGUF export and Ollama deployment |
| 71 | agent-integration | Custom model as agent backend |
| 72 | llmops-fine-tuner | Consolidated Part 8 skill |

### Cross-Chapter Dependencies

```
Ch 61-62: Concepts & Setup (foundations)
    |
    v
Ch 63: Data Engineering
    |
    v
Ch 64: Supervised Fine-Tuning (SFT)
    |
    v
Ch 65: Persona Tuning ----\
    |                      \
    v                       \
Ch 66: Agentic Tuning ------+----> Ch 67: Model Merging
                                      |
                                      v
                                   Ch 68: Alignment & Safety
                                      |
                                      v
                                   Ch 69: Evaluation & Quality Gates
                                      |
                                      v
                                   Ch 70: Deployment & Serving
                                      |
                                      v
                                   Ch 71: Agent Framework Integration
                                      |
                                      v
                                   Ch 72: Capstone (composes all)
```

---

## Validation Checklist

### Chapter-Level Validation

- [x] All chapters compatible with T4 GPU (15GB VRAM)
- [x] Platform-agnostic (concepts transfer to any provider)
- [x] Running example (Task API) provides coherent thread
- [x] Skill-First pattern applied (L00 lessons)
- [x] Layer 1-4 progression in each chapter
- [x] Digital FTE outcome from capstone (Ch 72)
- [x] Total cost under $1 per student verified

### Stage Progression Validation

For each chapter:
- [x] L00: Skill creation from official docs
- [x] L1-3: Manual foundation, mental model building
- [x] L4-6: AI Collaboration with Three Roles
- [x] Capstone: Spec-Driven Integration

### Cognitive Load Validation

- [x] B2 lessons: <=10 new concepts per lesson
- [x] C1 lessons: No artificial limits enforced

### Three Roles Validation (Layer 2 lessons)

- [x] Each L2 lesson demonstrates AI as Teacher
- [x] Each L2 lesson demonstrates AI as Student
- [x] Each L2 lesson demonstrates AI as Co-Worker (convergence)

---

## Summary Statistics

| Chapter | Lessons | Duration | Key Skill | Digital FTE Contribution |
|---------|---------|----------|-----------|--------------------------|
| 67 | 7 | 5.25 hrs | model-merging | Combined capabilities |
| 68 | 8 | 6 hrs | model-alignment | Safety guarantees |
| 69 | 7 | 5.2 hrs | model-evaluation | Quality assurance |
| 70 | 8 | 5.7 hrs | model-serving | Local deployment |
| 71 | 8 | 6 hrs | agent-integration | Agent backend |
| 72 | 9 | 7.6 hrs | llmops-fine-tuner | Complete pipeline |

**Total Chapters 67-72**: 47 lessons, ~35.75 hours

**Digital FTE Outcome**: Deployable custom model with agent integration, serving as specialized Task API assistant that can be monetized through subscription or license models.

---

**Version**: 1.0.0
**Constitution Alignment**: v7.0.0 (Agent Factory Paradigm)
**Generated**: 2026-01-01
