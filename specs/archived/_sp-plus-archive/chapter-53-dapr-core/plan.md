# Chapter 53: Dapr Core — Implementation Plan

**Generated by**: chapter-planner v2.0.0 (Reasoning-Activated)
**Source Spec**: specs/chapter-53-dapr-core/spec.md
**Expertise Skill**: .claude/skills/building-with-dapr/SKILL.md
**Created**: 2025-12-29
**Constitution**: v6.0.0 (Reasoning Mode)

---

## I. Chapter Analysis

### Chapter Type

**Technical/Code-Focused** — This chapter teaches hands-on deployment and coding with Dapr building blocks. Every lesson after L00-L02 includes both infrastructure deployment (Helm/kubectl) AND application code (async DaprClient with FastAPI).

**Recognition signals from spec**:
- Learning objectives use "apply/create/implement" verbs
- Code examples required throughout (async Python SDK patterns)
- Hands-on exercises for each building block

### Concept Density Analysis

**Core Concepts** (from spec): 12 concepts

1. Sidecar pattern and daprd injection
2. Building blocks concept (abstraction over infrastructure)
3. Component configuration (YAML CRDs)
4. State management API (save/get/delete with DaprClient)
5. Service invocation with automatic discovery
6. Pub/Sub messaging with CloudEvents
7. Input/Output bindings for external triggers
8. Jobs API for scheduled tasks
9. Secrets API
10. Configuration API
11. Dapr annotations for Kubernetes deployment
12. DaprClient async patterns (FastAPI integration)

**Complexity Assessment**: Standard-to-Complex (B1 proficiency, 12 concepts)

**Proficiency Tier**: B1 (Intermediate) — from chapter-index.md (Part 7: AI Cloud Native Development)

**Justified Lesson Count**: 11 lessons (L00-L10)

- **L00**: Layer 3 — Build skill first (Skill-First Pattern)
- **L01-L02**: Layer 1 — Manual/Conceptual foundation (sidecar + building blocks)
- **L03-L08**: Layer 2 — AI Collaboration (deploy + code each building block)
- **L09**: Layer 4 — Capstone (Dapr-enable Task API from Part 6)
- **L10**: Layer 3 — Finalize skill

**Total**: 11 lessons (~290 minutes / ~5 hours)

**Reasoning**: Chapter has 12 core concepts but follows Skill-First Pattern which front-loads skill creation (L00) and refinement (L10). Building block lessons (L03-L08) each deploy a component AND write code, justifying separate lessons despite conceptual overlap. This matches the structure of Chapter 52 (Kafka) which has 22 lessons for greater complexity.

---

## II. Success Evals (from Spec)

**Predefined Success Criteria** (evals-first requirement):

| ID | Success Criterion | Business Goal |
|----|-------------------|---------------|
| SC-001 | Students can deploy Dapr on Kubernetes in under 10 minutes | Reduce infrastructure setup friction |
| SC-002 | Students can write async FastAPI apps using 6+ Dapr building blocks | Production-ready coding patterns |
| SC-003 | Students complete capstone with Task API using Dapr for state, pubsub, invoke, secrets, and jobs | Integration demonstration |
| SC-004 | Students own a tested `dapr-deployment` skill in their skills library | Sellable Digital FTE component |
| SC-005 | 90% of code examples compile and run without modification | Quality assurance |
| SC-006 | Students can swap Redis for another backend by changing only component YAML | Understand Dapr's abstraction value |

**All lessons below map to these evals.**

---

## III. Lesson Sequence

### L00: Build Your Dapr Skill (25 min) — Layer 3

**Learning Objective**: Create a `dapr-deployment` skill BEFORE learning Dapr concepts, using Chapter 5 tools.

**Stage**: 3 (Skill Building — pre-learning)

**CEFR Proficiency**: B1

**New Concepts** (count: 2 within B1 limit):
1. Skill-First Learning Pattern application
2. Context7 documentation fetching for Dapr

**Cognitive Load Validation**: 2 concepts < 10 limit for B1

**Maps to Evals**: SC-004

**Content Elements**:
- Clone skills-lab fresh (no state assumptions from prior chapters)
- Write LEARNING-SPEC.md defining what you want to learn about Dapr
- `/fetching-library-docs dapr` to get official Dapr documentation via Context7
- `/skill-creator` to build `dapr-deployment` skill from docs (NOT from memory)
- Test skill with simple prompt: "Deploy Dapr on Kubernetes"

**Ends with**: Skill created at `.claude/skills/dapr-deployment/SKILL.md`

**Key Pattern from Expertise Skill**:
```markdown
Your skill should include:
- Dapr Helm deployment commands
- Component YAML patterns (state, pubsub, secrets)
- Async DaprClient usage patterns
- Kubernetes annotation requirements
```

**Try With AI Prompts**:
1. "I'm learning Dapr. Help me write a LEARNING-SPEC.md that covers sidecar deployment, state management, and pub/sub."
2. "Using my new dapr-deployment skill, generate Helm commands to deploy Dapr 1.14 on Docker Desktop Kubernetes."
3. "Test my skill: create a Redis state store component YAML for Dapr."

**Prerequisites**: Chapter 5 (Skills and skill-creator), Chapter 51 (Helm)

**Estimated Duration**: 25 minutes

---

### L01: The Sidecar Pattern (20 min) — Layer 1

**Learning Objective**: Understand why Dapr uses the sidecar architecture and how it separates infrastructure from application code.

**Stage**: 1 (Manual Foundation — conceptual)

**CEFR Proficiency**: B1

**New Concepts** (count: 5 within B1 limit):
1. Sidecar pattern / Ambassador pattern
2. Why separate infrastructure from application code
3. daprd sidecar process (HTTP :3500, gRPC :50001)
4. Sidecar injection via Kubernetes annotations
5. Container vs process mode (Kubernetes vs self-hosted)

**Cognitive Load Validation**: 5 concepts < 10 limit for B1

**Maps to Evals**: SC-001 (understanding foundation for deployment)

**Content Elements**:
- Visual diagram: App container + Dapr sidecar in same pod
- Analogy: "Like a translator sitting next to you who speaks all infrastructure languages"
- Annotation walkthrough: `dapr.io/enabled: "true"`, `dapr.io/app-id`, `dapr.io/app-port`
- The 2/2 Ready pattern in pod status (app container + sidecar)
- NO code yet — pure conceptual foundation

**Key Vocabulary**: sidecar, daprd, sidecar-injector, app-id, app-port

**Architecture Diagram from Expertise Skill**:
```
┌──────────────────────────────────────────────────────────────────┐
│  Pod                                                              │
│  ┌────────────────────────────────────────────────────────────┐ │
│  │  Your FastAPI Service                                       │ │
│  │  - Calls localhost:3500 (Dapr HTTP) or localhost:50001     │ │
│  └────────────────────────────────────────────────────────────┘ │
│                              │                                    │
│                              ▼                                    │
│  ┌────────────────────────────────────────────────────────────┐ │
│  │  Dapr Sidecar (daprd)                                       │ │
│  │  - HTTP API: :3500  │  gRPC API: :50001                     │ │
│  │  - Building Blocks: state, pubsub, invoke, secrets...       │ │
│  └────────────────────────────────────────────────────────────┘ │
└──────────────────────────────────────────────────────────────────┘
```

**Reflect on Your Skill**: Does your skill explain sidecar architecture and why it matters?

**Try With AI Prompts**:
1. "Explain the sidecar pattern to me like I'm familiar with Kubernetes pods but new to Dapr."
2. "What problems does the sidecar pattern solve compared to embedding infrastructure SDKs directly in my app?"
3. "Show me what Dapr annotations look like on a Kubernetes Deployment and explain each one."

**Prerequisites**: Chapter 50 (Kubernetes pods, deployments)

**Estimated Duration**: 20 minutes

---

### L02: Building Blocks and Components (20 min) — Layer 1

**Learning Objective**: Understand Dapr's abstraction model — building blocks as APIs and components as pluggable implementations.

**Stage**: 1 (Manual Foundation — conceptual)

**CEFR Proficiency**: B1

**New Concepts** (count: 5 within B1 limit):
1. Building blocks = APIs (state, pubsub, invoke, secrets, bindings, jobs, config)
2. Components = implementations (Redis, Kafka, Kubernetes secrets)
3. How swapping components changes infrastructure without code changes
4. Component YAML structure (apiVersion, kind, metadata, spec)
5. Scoping components to specific apps

**Cognitive Load Validation**: 5 concepts < 10 limit for B1

**Maps to Evals**: SC-006 (understand abstraction value)

**Content Elements**:
- Table: Building blocks covered in Ch53 vs deferred to Ch59
- Diagram: Building block API → Component → Infrastructure
- Component YAML anatomy (no deployment yet, just understanding)
- The key insight: "Same API, different backend. Change YAML, not code."
- Connection to Ch52: "You learned Kafka directly. Dapr's pub/sub can talk to Kafka OR Redis OR RabbitMQ — same code."

**Building Block Table from Expertise Skill**:

| Building Block | API Endpoint | Ch53 Scope |
|----------------|--------------|------------|
| **Service Invocation** | `/v1.0/invoke/{app-id}/method/{method}` | Yes |
| **State Management** | `/v1.0/state/{store}` | Yes |
| **Pub/Sub** | `/v1.0/publish/{pubsub}/{topic}` | Yes |
| **Bindings** | `/v1.0/bindings/{binding}` | Yes |
| **Secrets** | `/v1.0/secrets/{store}/{key}` | Yes |
| **Jobs** | Jobs API | Yes |
| **Configuration** | `/v1.0/configuration/{store}` | Yes |
| **Actors** | — | No (Ch59) |
| **Workflows** | — | No (Ch59) |

**Key Vocabulary**: building block, component, pluggable, component spec, scopes

**Reflect on Your Skill**: Does your skill distinguish building blocks from components?

**Try With AI Prompts**:
1. "What's the difference between a Dapr building block and a Dapr component? Give me a concrete example."
2. "Show me a Redis state store component YAML and explain what each field does."
3. "How would I swap from Redis pub/sub to Kafka pub/sub without changing my application code?"

**Prerequisites**: L01 (Sidecar pattern)

**Estimated Duration**: 20 minutes

---

### L03: Deploy Dapr + State Management (35 min) — Layer 2

**Learning Objective**: Deploy Dapr control plane with Helm AND use state management with async DaprClient in one hands-on lesson.

**Stage**: 2 (AI Collaboration — deploy AND code)

**CEFR Proficiency**: B1

**New Concepts** (count: 8 within B1 limit):
1. Dapr control plane components (operator, sidecar-injector, sentry, placement, scheduler)
2. Helm deployment: `helm upgrade --install dapr dapr/dapr`
3. Redis deployment for state store
4. State store component YAML
5. State API: save, get, delete, bulk operations
6. ETag for optimistic concurrency
7. Async DaprClient context manager pattern
8. FastAPI integration with lifespan

**Cognitive Load Validation**: 8 concepts < 10 limit for B1

**Maps to Evals**: SC-001 (deploy in <10 min), SC-002 (async FastAPI), SC-005 (code runs)

**Content Elements**:

**Part A: Deploy Dapr with Helm** (15 min)
```bash
# Add Dapr Helm repo
helm repo add dapr https://dapr.github.io/helm-charts/
helm repo update

# Install Dapr 1.14+ in dapr-system namespace
helm upgrade --install dapr dapr/dapr \
  --version=1.14.0 \
  --namespace dapr-system \
  --create-namespace \
  --wait

# Verify installation
kubectl get pods -n dapr-system

# Deploy Redis
helm install redis bitnami/redis --namespace default --set auth.enabled=false
```

**Part B: State Management with Async DaprClient** (20 min)

Simple Todo example (NOT full Task API — that's for capstone):
```python
from dapr.clients import DaprClient
from pydantic import BaseModel

class Todo(BaseModel):
    id: str
    title: str
    done: bool = False

async with DaprClient() as client:
    # Save state
    await client.save_state(
        store_name='statestore',
        key='todo-1',
        value=Todo(id='todo-1', title='Learn Dapr', done=False).model_dump_json()
    )

    # Get state
    state = await client.get_state(store_name='statestore', key='todo-1')
    todo = Todo.model_validate_json(state.data)

    # Delete state
    await client.delete_state(store_name='statestore', key='todo-1')
```

**State Store Component YAML from Expertise Skill**:
```yaml
apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: statestore
  namespace: default
spec:
  type: state.redis
  version: v1
  metadata:
    - name: redisHost
      value: redis-master.default.svc.cluster.local:6379
```

**Three Roles Demonstrations** (REQUIRED for Layer 2):

1. **AI as Teacher**: AI suggests ETag pattern for optimistic concurrency that student didn't know
2. **AI as Student**: Student clarifies they want simple Todo example, AI adapts from showing complex patterns
3. **AI as Co-Worker**: Iterate on FastAPI lifespan integration until Dapr health check works

**Reflect on Your Skill**: Does your skill include Helm deployment AND state patterns?

**Try With AI Prompts**:
1. "Deploy Dapr 1.14 on my Docker Desktop Kubernetes cluster. Show me Helm commands and how to verify all control plane pods are running."
2. "Create a FastAPI endpoint that saves a Todo to Dapr state store using async DaprClient. Include the state store component YAML."
3. "What's the ETag pattern for optimistic concurrency with Dapr state? When would I use it?"

**Prerequisites**: L02 (Building blocks concept), Chapter 51 (Helm)

**Estimated Duration**: 35 minutes

---

### L04: Service Invocation (25 min) — Layer 2

**Learning Objective**: Call services via Dapr with automatic discovery and mTLS using async DaprClient.

**Stage**: 2 (AI Collaboration — deploy AND code)

**CEFR Proficiency**: B1

**New Concepts** (count: 5 within B1 limit):
1. Service invocation API: `/v1.0/invoke/{app-id}/method/{method}`
2. Automatic service discovery via app-id annotation
3. mTLS between sidecars (Sentry service)
4. DaprClient.invoke_method() async pattern
5. HTTP header proxying: `dapr-app-id` header alternative

**Cognitive Load Validation**: 5 concepts < 10 limit for B1

**Maps to Evals**: SC-002 (async FastAPI patterns)

**Content Elements**:

**Hands-On Setup**: Deploy a second simple service (notification-service) with Dapr annotations.

**Service Invocation Code (Simple Todo Context)**:
```python
from dapr.clients import DaprClient

async with DaprClient() as client:
    # POST to notification-service
    response = await client.invoke_method(
        app_id='notification-service',
        method_name='notify',
        http_verb='POST',
        data='{"message": "Todo created: Learn Dapr"}'
    )
    print(f"Notification response: {response.text()}")
```

**Deployment with Dapr Annotations**:
```yaml
metadata:
  annotations:
    dapr.io/enabled: "true"
    dapr.io/app-id: "todo-api"
    dapr.io/app-port: "8000"
```

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI explains mTLS happens automatically via Sentry — student learns without configuring TLS
2. **AI as Student**: Student asks for simpler example with just Todo notification, AI adapts
3. **AI as Co-Worker**: Debug together when invoke fails due to wrong app-id

**Reflect on Your Skill**: Add service invocation patterns to your skill.

**Try With AI Prompts**:
1. "My todo-api needs to call notification-service when a todo is created. Deploy both services with Dapr and show me async service invocation."
2. "How does Dapr handle mTLS between services? Do I need to configure certificates?"
3. "What happens if I use the wrong app-id in invoke_method? Show me how to debug."

**Prerequisites**: L03 (Dapr deployed, async DaprClient patterns)

**Estimated Duration**: 25 minutes

---

### L05: Pub/Sub Messaging (30 min) — Layer 2

**Learning Objective**: Publish and subscribe to events using Dapr pub/sub with async DaprClient.

**Stage**: 2 (AI Collaboration — deploy AND code)

**CEFR Proficiency**: B1

**New Concepts** (count: 6 within B1 limit):
1. Pub/Sub API: `/v1.0/publish/{pubsub}/{topic}`
2. CloudEvents format (automatic wrapping)
3. Redis pub/sub component YAML
4. Declarative subscriptions (Subscription CRD)
5. Programmatic subscriptions (dapr-ext-fastapi)
6. DaprClient.publish_event() async pattern

**Cognitive Load Validation**: 6 concepts < 10 limit for B1

**Maps to Evals**: SC-002, SC-006 (swap Redis for Kafka with YAML only)

**Content Elements**:

**Publish Event (Simple Todo Context)**:
```python
from dapr.clients import DaprClient
import json

async with DaprClient() as client:
    await client.publish_event(
        pubsub_name='pubsub',
        topic_name='todo-events',
        data=json.dumps({
            'event_type': 'todo.created',
            'todo_id': 'todo-1',
            'title': 'Learn Dapr'
        }),
        data_content_type='application/json'
    )
```

**Subscribe with dapr-ext-fastapi**:
```python
from fastapi import FastAPI
from dapr.ext.fastapi import DaprApp

app = FastAPI()
dapr_app = DaprApp(app)

@dapr_app.subscribe(pubsub='pubsub', topic='todo-events')
async def handle_todo_event(event_data: dict):
    print(f"Received: {event_data}")
    return {"status": "SUCCESS"}
```

**Redis Pub/Sub Component from Expertise Skill**:
```yaml
apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: pubsub
spec:
  type: pubsub.redis
  version: v1
  metadata:
    - name: redisHost
      value: redis-master.default.svc.cluster.local:6379
```

**Connection to Ch52**: "Same concepts as Kafka, different broker. Swap Redis for Kafka with one YAML change."

**Kafka Pub/Sub Component (Show Swappability)**:
```yaml
apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: pubsub
spec:
  type: pubsub.kafka
  version: v1
  metadata:
    - name: brokers
      value: task-events-kafka-bootstrap.kafka.svc.cluster.local:9092
```

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI explains CloudEvents format is automatic — student learns Dapr wraps messages
2. **AI as Student**: Student wants to see both declarative and programmatic subscriptions, AI provides both
3. **AI as Co-Worker**: Iterate on subscription route until handler receives events correctly

**Reflect on Your Skill**: Add pub/sub patterns to your skill.

**Try With AI Prompts**:
1. "Add pub/sub to my Todo API: publish todo.created events using async DaprClient and create a subscription handler using dapr-ext-fastapi."
2. "Show me how to swap from Redis pub/sub to Kafka pub/sub without changing my application code."
3. "What's CloudEvents format? How does Dapr handle it automatically?"

**Prerequisites**: L04 (Service invocation), Chapter 52 (Kafka concepts for comparison)

**Estimated Duration**: 30 minutes

---

### L06: Bindings and Triggers (25 min) — Layer 2

**Learning Objective**: Connect to external systems with input/output bindings using async DaprClient.

**Stage**: 2 (AI Collaboration — deploy AND code)

**CEFR Proficiency**: B1

**New Concepts** (count: 5 within B1 limit):
1. Input bindings: trigger your app from external events (cron, webhooks, queues)
2. Output bindings: invoke external systems (HTTP, email, storage)
3. Binding component configuration with `direction` metadata
4. DaprClient.invoke_binding() async pattern
5. Difference from pub/sub: bindings for external systems, pub/sub for internal messaging

**Cognitive Load Validation**: 5 concepts < 10 limit for B1

**Maps to Evals**: SC-002

**Content Elements**:

**Cron Input Binding Component**:
```yaml
apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: cron-binding
spec:
  type: bindings.cron
  version: v1
  metadata:
    - name: schedule
      value: "*/5 * * * *"  # Every 5 minutes
```

**FastAPI Endpoint for Input Binding**:
```python
@app.post("/cron-binding")
async def handle_cron_trigger():
    print("Cron triggered! Cleaning up old todos...")
    return {"status": "OK"}
```

**Output Binding (HTTP Webhook)**:
```python
async with DaprClient() as client:
    await client.invoke_binding(
        binding_name='http-binding',
        operation='post',
        data='{"webhook": "todo.cleanup.complete"}'
    )
```

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI explains when to use bindings vs pub/sub — student learns distinction
2. **AI as Student**: Student wants simpler cron example first, AI simplifies before showing HTTP binding
3. **AI as Co-Worker**: Debug cron binding together when schedule syntax is wrong

**Reflect on Your Skill**: Add binding patterns to your skill.

**Try With AI Prompts**:
1. "Create a cron binding that triggers a cleanup endpoint every 5 minutes. Show the component YAML and FastAPI handler."
2. "Create an HTTP output binding to call an external webhook. Show async DaprClient usage."
3. "When should I use bindings vs pub/sub? Give me a clear decision framework."

**Prerequisites**: L05 (Pub/Sub for comparison)

**Estimated Duration**: 25 minutes

---

### L07: Jobs API: Scheduled Tasks (25 min) — Layer 2

**Learning Objective**: Schedule future jobs using Dapr's Jobs API with async DaprClient.

**Stage**: 2 (AI Collaboration — deploy AND code)

**CEFR Proficiency**: B1

**New Concepts** (count: 5 within B1 limit):
1. Jobs API vs Bindings: Jobs for scheduling future work, bindings for external triggers
2. Scheduler control plane service (already deployed with Dapr)
3. Creating jobs: one-time or recurring
4. Jobs stored in embedded Etcd
5. Job handler endpoint in FastAPI

**Cognitive Load Validation**: 5 concepts < 10 limit for B1

**Maps to Evals**: SC-002, SC-003 (Jobs used in capstone)

**Content Elements**:

**Schedule a Job (Simple Todo Context)**:
```python
async with DaprClient() as client:
    # Schedule a job for future execution
    await client.schedule_job(
        name='daily-cleanup',
        schedule='@daily',  # or cron expression
        data={'action': 'cleanup-old-todos'}
    )
```

**Job Handler Endpoint**:
```python
@app.post("/job/daily-cleanup")
async def handle_cleanup_job(job_data: dict):
    action = job_data.get('action')
    if action == 'cleanup-old-todos':
        # Clean up todos older than 30 days
        print("Running daily todo cleanup...")
    return {"status": "SUCCESS"}
```

**Jobs vs Bindings Comparison**:

| Aspect | Jobs API | Bindings |
|--------|----------|----------|
| **Use case** | Schedule future work | External system triggers |
| **Storage** | Dapr Scheduler (Etcd) | External system manages |
| **Control** | You schedule via API | External system triggers |
| **Examples** | "Run cleanup at midnight" | "Trigger when file arrives" |

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI explains Jobs API is built into Dapr Scheduler — no extra infrastructure
2. **AI as Student**: Student asks for simpler one-time job first, AI provides before recurring
3. **AI as Co-Worker**: Debug job scheduling together when cron expression is malformed

**Reflect on Your Skill**: Add job scheduling patterns to your skill.

**Try With AI Prompts**:
1. "Schedule a job that runs daily at midnight to archive completed todos. Use the Dapr Jobs API with async DaprClient."
2. "What's the difference between Jobs API and cron bindings? When should I use each?"
3. "Create a FastAPI handler for receiving job triggers from Dapr Scheduler."

**Prerequisites**: L06 (Bindings for comparison)

**Estimated Duration**: 25 minutes

---

### L08: Secrets and Configuration (25 min) — Layer 2

**Learning Objective**: Access secrets and configuration through Dapr APIs using async DaprClient.

**Stage**: 2 (AI Collaboration — deploy AND code)

**CEFR Proficiency**: B1

**New Concepts** (count: 5 within B1 limit):
1. Secrets API: `/v1.0/secrets/{store}/{key}`
2. Kubernetes secrets store component (built-in, no extra install)
3. DaprClient.get_secret() async pattern
4. Configuration API: `/v1.0/configuration/{store}`
5. Referencing secrets in component YAML (secretKeyRef)

**Cognitive Load Validation**: 5 concepts < 10 limit for B1

**Maps to Evals**: SC-002, SC-003 (Secrets used in capstone)

**Content Elements**:

**Create Kubernetes Secret**:
```bash
kubectl create secret generic api-credentials \
  --from-literal=api-key=my-secret-key-123
```

**Secrets Store Component**:
```yaml
apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: kubernetes-secrets
spec:
  type: secretstores.kubernetes
  version: v1
  metadata: []
```

**Get Secret with Async DaprClient**:
```python
async with DaprClient() as client:
    secret = await client.get_secret(
        store_name='kubernetes-secrets',
        key='api-credentials'
    )
    api_key = secret.secret.get('api-key')
    print(f"Got API key: {api_key[:4]}...")
```

**Reference Secrets in Component YAML**:
```yaml
apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: statestore
spec:
  type: state.redis
  metadata:
    - name: redisPassword
      secretKeyRef:
        name: redis-password
        key: password
```

**Three Roles Demonstrations**:
1. **AI as Teacher**: AI explains secretKeyRef pattern for component YAML — student learns secure configuration
2. **AI as Student**: Student wants to see Kubernetes secrets first (simpler), AI starts there before showing other secret stores
3. **AI as Co-Worker**: Debug together when secret key name doesn't match

**Reflect on Your Skill**: Add secrets/config patterns to your skill.

**Try With AI Prompts**:
1. "Configure my Todo API to get an API key from Kubernetes secrets via Dapr using async DaprClient."
2. "Show me how to reference secrets in a Dapr component YAML using secretKeyRef."
3. "What's the difference between Secrets API and Configuration API? When do I use each?"

**Prerequisites**: L07 (All building blocks context), Chapter 50 (Kubernetes secrets)

**Estimated Duration**: 25 minutes

---

### L09: Capstone: Dapr-Enabled Task API (40 min) — Layer 4

**Learning Objective**: Refactor the Task API from Part 6 to use Dapr building blocks for ALL infrastructure abstraction.

**Stage**: 4 (Spec-Driven Integration — compose skills)

**CEFR Proficiency**: B1

**Maps to Evals**: SC-003 (Integration demonstration), SC-005 (Code runs)

**Content Elements**:

**Spec-Driven Approach**: Write specification FIRST, then AI orchestrates implementation.

**CAPSTONE-SPEC.md**:
```markdown
# Task API with Dapr Integration

## Intent
Refactor the Part 6 Task API to use Dapr for all infrastructure abstraction.

## Building Blocks to Use
1. **State Management**: Replace direct Redis with Dapr state store
2. **Pub/Sub**: Publish task.created, task.completed events
3. **Service Invocation**: Call notification-service via Dapr
4. **Secrets**: Get API keys via Dapr secrets API
5. **Jobs**: Schedule daily cleanup via Dapr Jobs API

## Success Criteria
- [ ] Pod shows 2/2 containers (app + sidecar)
- [ ] Task CRUD works via Dapr state store
- [ ] task.created events published on task creation
- [ ] notification-service called via Dapr invoke
- [ ] No direct Redis/Kafka clients in application code
```

**Deployment with Dapr Annotations**:
```yaml
metadata:
  annotations:
    dapr.io/enabled: "true"
    dapr.io/app-id: "task-api"
    dapr.io/app-port: "8000"
    dapr.io/enable-api-logging: "true"
```

**Integrated Task API Pattern** (from Expertise Skill):
```python
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException
from dapr.clients import DaprClient
from dapr.ext.fastapi import DaprApp
from pydantic import BaseModel
import json
import uuid

class Task(BaseModel):
    id: str | None = None
    title: str
    status: str = "pending"

@asynccontextmanager
async def lifespan(app: FastAPI):
    yield

app = FastAPI(lifespan=lifespan)
dapr_app = DaprApp(app)

@app.post("/tasks", response_model=Task)
async def create_task(task: Task):
    task.id = str(uuid.uuid4())

    async with DaprClient() as client:
        # Save state via Dapr
        await client.save_state(
            store_name='statestore',
            key=f'task-{task.id}',
            value=task.model_dump_json()
        )

        # Publish event via Dapr
        await client.publish_event(
            pubsub_name='pubsub',
            topic_name='task-events',
            data=json.dumps({
                'event_type': 'task.created',
                'task_id': task.id,
                'title': task.title
            }),
            data_content_type='application/json'
        )

        # Invoke notification service via Dapr
        await client.invoke_method(
            app_id='notification-service',
            method_name='notify',
            data=json.dumps({'task_id': task.id}),
            http_verb='POST'
        )

    return task

@app.get("/tasks/{task_id}", response_model=Task)
async def get_task(task_id: str):
    async with DaprClient() as client:
        state = await client.get_state(
            store_name='statestore',
            key=f'task-{task_id}'
        )

        if not state.data:
            raise HTTPException(status_code=404, detail="Task not found")

        return Task.model_validate_json(state.data)

# Subscribe to events
@dapr_app.subscribe(pubsub='pubsub', topic='task-events')
async def handle_task_event(event_data: dict):
    print(f"Processing event: {event_data}")
    return {"status": "SUCCESS"}
```

**Test the Complete Flow**:
1. Create task via POST /tasks
2. Verify state saved: check statestore
3. Verify event published: check subscriber logs
4. Verify notification sent: check notification-service logs
5. Verify pod status: `kubectl get pods` shows 2/2

**Deliverable**: Working Task API using Dapr for ALL infrastructure abstraction.

**Try With AI Prompts**:
1. "Refactor my Part 6 Task API to use Dapr state management instead of direct Redis. Show the complete async DaprClient integration."
2. "Add pub/sub to my Task API: publish task.created events and create a subscriber that logs them."
3. "Deploy my Dapr-enabled Task API to Kubernetes with the correct annotations. Verify the sidecar is injected."

**Prerequisites**: All L01-L08, Part 6 Task API

**Estimated Duration**: 40 minutes

---

### L10: Finalize Your Dapr Skill (20 min) — Layer 3

**Learning Objective**: Complete and test your `dapr-deployment` skill, validating it covers all building blocks.

**Stage**: 3 (Skill Building — finalization)

**CEFR Proficiency**: B1

**Maps to Evals**: SC-004 (Own tested skill)

**Content Elements**:

**Review All "Reflect on Skill" Additions from L01-09**:
- L01: Sidecar architecture explanation
- L02: Building blocks vs components distinction
- L03: Helm deployment + state patterns
- L04: Service invocation patterns
- L05: Pub/Sub patterns
- L06: Binding patterns
- L07: Jobs API patterns
- L08: Secrets/config patterns
- L09: Complete integration example

**Test Skill Against Multiple Prompts**:
```
1. "Deploy Dapr on Kubernetes" → Verify Helm commands
2. "Add state management to my FastAPI app" → Verify async DaprClient
3. "Set up pub/sub with Dapr" → Verify component YAML + code
4. "Schedule a recurring job" → Verify Jobs API usage
5. "Configure secrets for my Dapr app" → Verify secrets patterns
```

**Add Safety Guardrails from Expertise Skill**:

**NEVER**:
- Call Dapr before sidecar is ready (use health checks)
- Hardcode component names (use configuration)
- Skip error handling for Dapr API calls
- Store sensitive data in state without encryption
- Expose Dapr HTTP/gRPC ports externally

**ALWAYS**:
- Wait for sidecar readiness: `/v1.0/healthz`
- Use secrets component for credentials
- Enable mTLS in production (default with Sentry)
- Configure appropriate retry policies
- Set resource limits on sidecar

**Add Common Errors from Expertise Skill**:

| Error | Cause | Fix |
|-------|-------|-----|
| `ERR_STATE_STORE_NOT_FOUND` | State component not configured | Apply component YAML |
| `ERR_PUBSUB_NOT_FOUND` | Pub/sub component not configured | Apply component YAML |
| `connection refused :3500` | Sidecar not ready | Add startup probe |
| `ERR_DIRECT_INVOKE` | Target app not found | Check app-id annotation |

**Final Skill Validation**:
```
Using my dapr-deployment skill, generate a complete Dapr setup for:
- A FastAPI service that saves tasks to state store
- Publishes events to pub/sub
- Calls notification service via invoke
- Schedules daily cleanup job
- Gets API keys from secrets

Show all component YAMLs and Python code.
```

**Ends with**: Production-ready `dapr-deployment` skill in your skills library.

**Try With AI Prompts**:
1. "Review my dapr-deployment skill. Does it cover all 6 building blocks from Chapter 53?"
2. "Add safety guardrails to my skill: what should it warn users about?"
3. "Test my skill: generate a complete Dapr-enabled microservice from scratch."

**Prerequisites**: L09 (Capstone complete)

**Estimated Duration**: 20 minutes

---

## IV. Pedagogical Arc

```
L00: Skill-First (25 min)
  │   Build skill BEFORE learning
  │
  ▼
L01-L02: Foundation (40 min)
  │   Sidecar + Building Blocks mental models
  │   Layer 1: Manual/Conceptual
  │
  ▼
L03-L08: Building Blocks Practice (165 min)
  │   Each: Deploy component + Write code
  │   Layer 2: AI Collaboration
  │   State → Invoke → PubSub → Bindings → Jobs → Secrets
  │
  ▼
L09: Integration (40 min)
  │   Refactor Task API with ALL building blocks
  │   Layer 4: Spec-Driven
  │
  ▼
L10: Finalize Skill (20 min)
      Complete, tested skill asset
      Layer 3: Skill Building
```

**Total Duration**: ~290 minutes (~5 hours)

---

## V. Cognitive Load Assessment Per Lesson

| Lesson | New Concepts | CEFR Limit (B1: 10) | Status |
|--------|--------------|---------------------|--------|
| L00 | 2 | 10 | WITHIN LIMIT |
| L01 | 5 | 10 | WITHIN LIMIT |
| L02 | 5 | 10 | WITHIN LIMIT |
| L03 | 8 | 10 | WITHIN LIMIT |
| L04 | 5 | 10 | WITHIN LIMIT |
| L05 | 6 | 10 | WITHIN LIMIT |
| L06 | 5 | 10 | WITHIN LIMIT |
| L07 | 5 | 10 | WITHIN LIMIT |
| L08 | 5 | 10 | WITHIN LIMIT |
| L09 | Integration (no new) | — | N/A |
| L10 | Refinement (no new) | — | N/A |

**Total new concepts**: 46 across 11 lessons (average 4.6 per lesson)

---

## VI. Content Dependencies and Ordering

### Skill Dependency Graph

```
L00 (Skill-First)
  │
  ▼
L01 (Sidecar) → L02 (Building Blocks)
                  │
                  ▼
                L03 (Dapr Deploy + State) ─────────────────┐
                  │                                         │
                  ▼                                         │
                L04 (Invoke)                                │
                  │                                         │
                  ▼                                         │
                L05 (PubSub) ─────────────────────────────┤
                  │                                         │
                  ▼                                         │
                L06 (Bindings)                              │
                  │                                         │
                  ▼                                         │
                L07 (Jobs)                                  │
                  │                                         │
                  ▼                                         │
                L08 (Secrets) ─────────────────────────────┤
                                                            │
                                                            ▼
                                                          L09 (Capstone: All together)
                                                            │
                                                            ▼
                                                          L10 (Finalize Skill)
```

### Cross-Chapter Dependencies

| Prerequisite Chapter | Skills Assumed |
|---------------------|----------------|
| **Chapter 5** | Skills creation, `/fetching-library-docs`, `/skill-creator` |
| **Chapter 49** | Docker: Container images, Dockerfile |
| **Chapter 50** | Kubernetes: Pods, Deployments, Services, Secrets, ConfigMaps |
| **Chapter 51** | Helm: Charts, values, `helm install/upgrade` |
| **Chapter 52** | Kafka concepts (what Dapr abstracts with pub/sub) |
| **Part 6** | FastAPI async patterns, Task API |

**Validation**: All prerequisite chapters are implemented per chapter-index.md.

---

## VII. Expertise Skill Integration

### Key Patterns from `.claude/skills/building-with-dapr/SKILL.md`

**Used in L01-L02 (Conceptual)**:
- Sidecar architecture diagram
- Building blocks table
- Component vs building block distinction

**Used in L03-L08 (Building Blocks)**:
- Component YAML patterns (state, pubsub, secrets, bindings)
- Async DaprClient code patterns
- Error table (ERR_STATE_STORE_NOT_FOUND, etc.)

**Used in L09 (Capstone)**:
- Complete FastAPI + Dapr integration pattern
- Kubernetes deployment with annotations

**Used in L10 (Finalize Skill)**:
- Safety guardrails (NEVER/ALWAYS lists)
- Common errors table
- References section

---

## VIII. Validation Checklist

**Chapter-Level Validation**:
- [x] Chapter type identified: Technical/Code-Focused
- [x] Concept density analysis documented: 12 core concepts
- [x] Lesson count justified: 11 lessons (Skill-First Pattern)
- [x] All evals from spec covered by lessons
- [x] All lessons map to at least one eval

**Stage Progression Validation**:
- [x] L00: Layer 3 (Skill-First, pre-learning)
- [x] L01-L02: Layer 1 (Manual/Conceptual, no code yet)
- [x] L03-L08: Layer 2 (AI Collaboration with Three Roles)
- [x] L09: Layer 4 (Spec-Driven Integration)
- [x] L10: Layer 3 (Skill finalization)
- [x] No spec-first before Layer 4

**Cognitive Load Validation**:
- [x] Each lesson's concept count <= B1 tier limit (10)
- [x] Average 4.6 new concepts per teaching lesson
- [x] Integration lessons (L09, L10) don't introduce new concepts

**Dependency Validation**:
- [x] Skill dependencies satisfied by lesson order
- [x] Cross-chapter dependencies validated (prerequisites implemented)
- [x] Part 6 Task API available for capstone

**Three Roles Validation** (Layer 2 lessons L03-L08):
- [x] Each Layer 2 lesson demonstrates AI as Teacher
- [x] Each Layer 2 lesson demonstrates AI as Student
- [x] Each Layer 2 lesson demonstrates AI as Co-Worker (convergence)

**Expertise Skill Integration**:
- [x] Decision logic from skill used in lesson structure
- [x] Code examples from skill used in lessons
- [x] Safety guardrails from skill added to L10

---

## IX. Quality Reference Alignment

This plan matches the structure and quality of **Chapter 52: Event-Driven Architecture with Kafka** at `/apps/learn-app/docs/07-AI-Cloud-Native-Development/52-event-driven-kafka/`:

| Aspect | Chapter 52 (Kafka) | Chapter 53 (Dapr) |
|--------|-------------------|-------------------|
| **Skill-First L00** | Build Kafka skill | Build Dapr skill |
| **Conceptual foundation** | L01-L03 (EDA concepts) | L01-L02 (Sidecar, building blocks) |
| **Hands-on building blocks** | L04-L08 (producers, consumers) | L03-L08 (state, invoke, pubsub, bindings, jobs, secrets) |
| **Reflect on Your Skill** | Every lesson | Every lesson |
| **3 Try With AI prompts** | Every lesson | Every lesson |
| **Capstone** | L21 (Event-driven notifications) | L09 (Dapr-enabled Task API) |
| **Finalize Skill** | L22 | L10 |
| **Total duration** | ~8+ hours (22 lessons) | ~5 hours (11 lessons) |

Dapr has fewer lessons because it abstracts multiple technologies (vs Kafka deep dive), but follows the same Skill-First Learning Pattern.

---

**Plan Version**: 1.0.0
**Ready for**: Content implementation via content-implementer subagent
