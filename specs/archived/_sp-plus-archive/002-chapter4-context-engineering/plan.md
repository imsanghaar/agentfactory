# Implementation Plan: Chapter 4 — Effective Context Engineering with General Agents

**Generated by**: chapter-planner v2.0.0 (Reasoning-Activated)
**Source Spec**: specs/002-chapter4-context-engineering/spec.md
**Research Notes**: workspace/chapter4-context-engineering-DEEP-v3.md
**Constitution**: v7.0.0 (Agent Factory Paradigm)
**Created**: 2026-01-29

---

## I. Chapter Overview

### Executive Summary

Chapter 4 introduces **Context Engineering** as the quality control discipline for Digital FTE manufacturing. This chapter bridges Chapter 3 (HOW to use tools: CLAUDE.md, Skills, Subagents, Hooks, MCP) and Chapter 5 (Seven Principles, including "Persisting State in Files") by teaching:

- **WHY** context quality determines agent value
- **WHEN** to apply different context strategies
- **HOW** to engineer context that produces sellable Digital FTE quality

### Thesis Connection

**Core Thesis**: "General Agents BUILD Custom Agents" — Context engineering IS the quality control discipline that determines whether your Digital FTE is worth $500/month or $50,000/month.

**Manufacturing Analogy**: Just as Toyota has quality control for car manufacturing (raw materials quality, assembly precision, testing protocols), context engineering is quality control for Digital FTE manufacturing (context quality, information organization, verification workflows).

### Chapter Positioning

| Chapter       | Focus                      | What Students Learn                                          |
| ------------- | -------------------------- | ------------------------------------------------------------ |
| Chapter 3     | HOW (Tools)                | Use CLAUDE.md, Skills, Subagents, Hooks, MCP                 |
| **Chapter 4** | **WHY/WHEN (Engineering)** | **Why tools work, when to use each, engineering discipline** |
| Chapter 5     | WHAT (Principles)          | Seven Principles including "Persisting State in Files"       |

### Critical Non-Repetition Constraint

**Chapter 4 MUST NOT teach**:

- How to create CLAUDE.md files (Chapter 3, Lesson 5)
- How to create Skills (Chapter 3, Lessons 7-8)
- How to use Subagents (Chapter 3, Lesson 9)
- How to configure Hooks (Chapter 3, Lesson 13)
- How to set up MCP servers (Chapter 3, Lesson 10)

**Chapter 4 MUST teach**:

- Why a 47-line CLAUDE.md outperforms a 400-line one
- When to /clear vs /compact
- How to structure for position sensitivity
- How to prevent workflow drift
- How to isolate context in multi-agent systems

---

## II. Chapter Analysis

### Concept Density Analysis

**Core Concepts** (from spec): 12 concepts

1. Attention Budget (U-shaped attention curve, 70% threshold)
2. Position Sensitivity (Lost in the Middle research)
3. Context Rot (4 types: Poisoning, Distraction, Confusion, Clash)
4. Signal vs Noise (4-question audit framework)
5. Context Zones (Green/Yellow/Orange/Red/Black)
6. Context Lifecycle (/clear vs /compact decision framework)
7. Progress File Architecture (multi-session persistence)
8. Session Architecture (Initializer + Coding agent pattern)
9. Tacit Knowledge Transfer (two-way problem)
10. Memory Injection (PreToolUse vs UserPromptSubmit)
11. Context Isolation (dirty slate vs clean context patterns)
12. Subagent Design Patterns (Stateless, Stateful, Shared)

**Complexity Assessment**: Complex (12 interconnected concepts requiring synthesis)

**Proficiency Tier**: B1 (Intermediate) — from spec

### Justified Lesson Count

Based on concept density + B1 proficiency + stage requirements:

- **Layer 1 (Manual Foundation)**: 3 lessons (Concepts 1-4: understanding WHY context matters)
- **Layer 2 (AI Collaboration)**: 4 lessons (Concepts 5-9: applying techniques with AI)
- **Layer 3 (Intelligence Design)**: 2 lessons (Concepts 10-11: creating reusable patterns)
- **Layer 4 (Capstone)**: 1 lesson (Integration of full toolkit)

**Total**: 10 lessons (justified by concept density, NOT arbitrary template)

**Reasoning**: This chapter covers 12 complex concepts with significant interdependencies. B1 proficiency allows 7-10 concepts per lesson, but these concepts require progressive scaffolding and practice. The 10-lesson structure allows each major concept to be introduced with sufficient context before building on it.

---

## III. Pedagogical Arc

The chapter follows a **Foundation → Techniques → Advanced → Integration** progression:

```
┌─────────────────────────────────────────────────────────────────────────┐
│  FOUNDATION (Lessons 1-3): Understanding WHY context matters            │
│  └── Manufacturing quality problem → Attention budget → Position sens.  │
├─────────────────────────────────────────────────────────────────────────┤
│  TECHNIQUES (Lessons 4-6): HOW to optimize context                      │
│  └── Signal vs noise → Tacit knowledge → Context lifecycle              │
├─────────────────────────────────────────────────────────────────────────┤
│  ADVANCED (Lessons 7-9): Persistence, drift prevention, isolation       │
│  └── Progress files → Memory injection → Context isolation              │
├─────────────────────────────────────────────────────────────────────────┤
│  INTEGRATION (Lesson 10): Decision frameworks + production agent        │
│  └── Full toolkit synthesis → Sellable Digital FTE                      │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## IV. Layer Distribution

| Lesson | Title                             | Layer             | Justification                                           |
| ------ | --------------------------------- | ----------------- | ------------------------------------------------------- |
| 1      | The Manufacturing Quality Problem | L1 (Manual)       | Foundation: establish mental model before AI            |
| 2      | The Attention Budget              | L1 (Manual)       | Foundation: core mechanic must be understood manually   |
| 3      | Lost in the Middle                | L1 (Manual)       | Foundation: position sensitivity research comprehension |
| 4      | Signal vs Noise                   | L2 (AI Collab)    | Technique: apply audit framework with AI assistance     |
| 5      | Tacit Knowledge Transfer          | L2 (AI Collab)    | Technique: two-way knowledge exchange with AI           |
| 6      | Context Lifecycle                 | L2 (AI Collab)    | Technique: decision-making with AI guidance             |
| 7      | Long-Horizon Progress Files       | L2 (AI Collab)    | Technique: session architecture with AI                 |
| 8      | Mid-Stream Memory Injection       | L3 (Intelligence) | Create reusable memory hook pattern                     |
| 9      | Context Isolation                 | L3 (Intelligence) | Create reusable orchestration pattern                   |
| 10     | The Context Engineering Playbook  | L4 (Capstone)     | Spec-driven production agent                            |

---

## V. Success Evals (from Spec)

**Predefined Success Criteria** (all lessons map to these):

| ID     | Eval Criterion                                              | Target | Mapped Lessons |
| ------ | ----------------------------------------------------------- | ------ | -------------- |
| SC-001 | Identify context zone from /usage + recommend action        | 80%+   | 2, 6           |
| SC-002 | Classify CLAUDE.md content as SIGNAL or NOISE               | 80%+   | 4              |
| SC-003 | Restructure CLAUDE.md using three-zone position strategy    | 75%+   | 3, 4           |
| SC-004 | Design progress file architecture for multi-session feature | 75%+   | 7              |
| SC-005 | Explain workflow drift + propose PreToolUse solution        | 70%+   | 8              |
| SC-006 | Compare dirty slate vs clean context patterns               | 70%+   | 9              |
| SC-007 | Traverse context engineering decision tree                  | 90%+   | 10             |
| SC-008 | Demonstrate improved agent quality via chapter techniques   | 80%+   | 10             |
| SC-009 | All statistics verifiable from cited sources                | 100%   | All            |
| SC-010 | No meta-commentary, framework invisible                     | 100%   | All            |

---

## VI. Lesson Breakdown

### Lesson 1: The Manufacturing Quality Problem — Why Context Determines Agent Value

**Duration**: 45 min
**Layer**: L1 (Manual Foundation)
**User Story**: US1 — Understanding Why Context Quality Determines Agent Value

**Learning Objectives**:

1. Explain why two engineers using the same model produce agents of vastly different quality—citing context quality as the differentiator
2. Map Toyota's quality control practices to Digital FTE manufacturing (raw materials = context, assembly precision = information organization, testing protocols = verification workflows)
3. Identify the 5 context components and their typical contribution to context window

**Key Concepts** (count: 5 — within B1 limit):

- Context as quality control for Digital FTE manufacturing
- Context vs prompts distinction (50-200 tokens vs 200,000+)
- Context composition (system prompt, CLAUDE.md, tools, history, tool outputs)
- Principle 5 connection ("Persisting State in Files")
- Manufacturing quality analogy

**Lab**: Agent Quality Diagnostic

- **Deliverable**: Diagnostic report identifying context-related quality gaps
- **Protocol**: Run same task fresh vs after 30 min work, compare outputs, document degradation

**Teaching Approach**: Story-driven narrative (two consulting firms, same model, different results) + Manufacturing analogy + self-assessment exercise

**Try With AI** (3 prompts):

1. Context inventory estimation (awareness)
2. Quality comparison experiment (demonstration)
3. Principle 5 bridge (CLAUDE.md audit)

**Prerequisites**: Chapter 3 completion (tools proficiency)

---

### Lesson 2: The Attention Budget — Why More Context Is Not Better

**Duration**: 50 min
**Layer**: L1 (Manual Foundation)
**User Story**: US2 — Diagnosing Context Degradation

**Learning Objectives**:

1. Explain the U-shaped attention curve (beginning and end get ~70% accuracy, middle gets ~40%)
2. Apply the 70% context utilization threshold for quality degradation
3. Classify the 4 types of context rot (Poisoning, Distraction, Confusion, Clash)

**Key Concepts** (count: 6 — within B1 limit):

- U-shaped attention curve
- Attention budget (n^2 compute, position decay, training bias)
- 70% utilization threshold
- Zone system (Green/Yellow/Orange/Red/Black)
- 4 types of context rot
- /usage command for monitoring

**Lab**: Context Degradation Experiment

- **Deliverable**: Graph of quality ratings vs context utilization %
- **Protocol**: Run /usage at intervals, rate same task quality at different utilization levels

**Teaching Approach**: Visual diagrams (U-curve, zone system) + hands-on experiment + self-discovery

**Try With AI** (3 prompts):

1. Budget awareness (/usage interpretation)
2. Rot detection (identify outdated, irrelevant, contradictory content)
3. 70% drill (compaction decision-making)

**Prerequisites**: Lesson 1 (context as quality control)

---

### Lesson 3: Lost in the Middle — Where Information Goes to Die

**Duration**: 45 min
**Layer**: L1 (Manual Foundation)
**User Story**: US2 — Diagnosing Context Degradation (position sensitivity)

**Learning Objectives**:

1. Explain position sensitivity using the Liu et al. (2023) "Lost in the Middle" research findings
2. Apply the three-zone CLAUDE.md strategy (critical at beginning, reference in middle, workflow at end)
3. Predict compliance rates based on information position (30% accuracy drop for middle vs edges)

**Key Concepts** (count: 5 — within B1 limit):

- Position sensitivity phenomenon
- Primacy effect (first items anchor attention)
- Recency effect (last items freshest in memory)
- Middle blindness
- Three-zone strategy (Zone 1: critical, Zone 2: reference, Zone 3: workflow)

**Lab**: Position Sensitivity Test

- **Deliverable**: Compliance rates by position (table proving position matters in YOUR setup)
- **Protocol**: Add test instruction to beginning/middle/end of CLAUDE.md, measure compliance across 5 file creations each

**Teaching Approach**: Research-based explanation + visual diagram + empirical experiment

**Try With AI** (3 prompts):

1. Position audit (identify current position of each CLAUDE.md section)
2. Restructure proposal (apply three-zone strategy)
3. Stress test (verify improved recall after restructuring)

**Prerequisites**: Lesson 2 (attention budget, zone system)

---

### Lesson 4: Signal vs Noise — Auditing Your Context for Quality

**Duration**: 60 min
**Layer**: L2 (AI Collaboration)
**User Story**: US3 — Optimizing CLAUDE.md Signal-to-Noise

**Learning Objectives**:

1. Apply the 4-question audit framework to classify CLAUDE.md content as SIGNAL or NOISE
2. Refactor a 300+ line CLAUDE.md to under 60 lines while improving effectiveness
3. Implement progressive disclosure via file references for noise content

**Key Concepts** (count: 6 — within B1 limit):

- Signal vs noise definition
- 4-question audit framework:
  1. Would Claude ask me about this?
  2. Could Claude figure this out from reading code?
  3. Does this change frequently?
  4. Is this a default convention?
- <60 line CLAUDE.md target (~150-200 instruction limit)
- Progressive disclosure pattern
- File references (@docs/X.md)
- HumanLayer best-practice example

**Lab**: CLAUDE.md Signal-to-Noise Audit

- **Deliverable**: Optimized <60 line CLAUDE.md
- **Protocol**: Export current, classify each section, delete/move noise, run comparison tests

**Teaching Approach**: AI collaboration to audit current CLAUDE.md using 4-question framework

**Three Roles Integration**:

- **AI as Teacher**: AI identifies noise patterns you didn't recognize
- **AI as Student**: You teach AI your domain-specific signals
- **Convergence**: Iterate on what's signal vs noise for YOUR project

**Try With AI** (3 prompts):

1. Noise identification (AI applies 4-question framework)
2. Signal extraction (collaborative refinement)
3. Progressive disclosure setup (file reference architecture)

**Prerequisites**: Lessons 1-3 (foundation), Chapter 3 Lesson 5-6 (CLAUDE.md creation)

---

### Lesson 5: The Two-Way Problem — Getting Tacit Knowledge In and Out

**Duration**: 60 min
**Layer**: L2 (AI Collaboration)
**User Story**: US4 — Managing Multi-Session Work (tacit knowledge foundation)

**Learning Objectives**:

1. Explain the two-way tacit knowledge problem (Engineers to AI, AI to Engineers)
2. Implement strategies for transferring domain expertise to AI (structured architecture docs, encoded stylistic preferences, memory systems)
3. Apply the OpenAI memory lifecycle (inject, reason, distill, consolidate)

**Key Concepts** (count: 7 — within B1 limit):

- Tacit knowledge definition (unwritten rules engineers carry)
- Two-way problem (knowledge IN and understanding OUT)
- Structured architecture documents for AI consumption
- Encoded stylistic preferences (examples over rules)
- Memory lifecycle: inject → reason → distill → consolidate
- Global vs session memory scoping
- Explanation requirements for extracting understanding

**Lab**: Tacit Knowledge Extraction

- **Deliverable**: Tacit knowledge document capturing what experienced engineers carry in their heads
- **Protocol**: Record 10-min explanation to new team member, transcribe, extract non-documented knowledge, encode as CLAUDE.md sections or Skills

**Teaching Approach**: Self-reflection exercise + AI collaboration for structuring

**Three Roles Integration**:

- **AI as Teacher**: AI structures your verbal explanation into actionable context
- **AI as Student**: You provide domain knowledge AI lacks
- **Convergence**: Iterate on tacit knowledge encoding format

**Try With AI** (3 prompts):

1. Tacit knowledge interview (AI asks questions to extract your domain expertise)
2. Encoding challenge (transform verbal explanation into structured context)
3. Verification test (AI demonstrates it has absorbed the tacit knowledge)

**Prerequisites**: Lesson 4 (signal vs noise—tacit knowledge IS signal)

---

### Lesson 6: Context Lifecycle — Knowing When to Reset vs Compress

**Duration**: 45 min
**Layer**: L2 (AI Collaboration)
**User Story**: US2 — Diagnosing Context Degradation (lifecycle management)

**Learning Objectives**:

1. Apply the /clear vs /compact decision framework based on task state and context condition
2. Use custom compaction instructions to preserve critical information
3. Implement session persistence using --continue and --resume

**Key Concepts** (count: 6 — within B1 limit):

- /clear (full reset) vs /compact (intelligent compression)
- Decision framework (/clear when: task complete, context poisoned, switching work; /compact when: same task continues, need to preserve decisions)
- Custom compaction instructions ("Focus on X, ignore Y")
- Session persistence (--continue, --resume, /resume)
- 3-day conversation viability rule
- Commit checkpoint pattern (never end session with broken code)

**Lab**: Context Zone Monitoring

- **Deliverable**: Log showing typical context growth pattern + optimal compaction timing
- **Protocol**: Monitor /usage every 10 messages, graph utilization over session, identify optimal /compact timing

**Teaching Approach**: Decision tree + hands-on monitoring + real-time decision-making with AI

**Three Roles Integration**:

- **AI as Teacher**: AI suggests when to compact based on zone
- **AI as Student**: You specify what to preserve in compaction
- **Convergence**: Develop custom compaction instructions together

**Try With AI** (3 prompts):

1. Zone awareness (AI reports current zone and recommendation)
2. Compaction rehearsal (practice /compact with custom instructions)
3. Session handoff (test --continue resumption)

**Prerequisites**: Lesson 2 (zones), Lesson 3 (position—what to preserve during compaction)

---

### Lesson 7: Long-Horizon Work — Progress Files and Session Architecture

**Duration**: 90 min (lab-heavy)
**Layer**: L2 (AI Collaboration)
**User Story**: US4 — Managing Multi-Session Work

**Learning Objectives**:

1. Design progress file architecture using the Completed/In Progress/Blocked/Decisions Made/Known Issues template
2. Implement the Initializer + Coding Agent pattern (Harrison Chase harness architecture)
3. Execute the commit checkpoint pattern at session boundaries

**Key Concepts** (count: 7 — within B1 limit):

- Progress file template (5 sections)
- Initializer Agent vs Coding Agent separation
- Feature decomposition (10-15 granular tasks)
- Commit checkpoint pattern
- Session initialization protocol (pwd, read progress, check git log, select task, run tests)
- Session exit protocol (commit working code, update progress file)
- --continue resumption

**Lab**: The Five-Session Feature

- **Deliverable**: Working feature + reusable progress file template
- **Protocol**: Define 5-hour feature, decompose into 10-15 tasks, complete across 5 sessions using progress tracking, retrospective

**Teaching Approach**: Practical multi-session workflow with AI collaboration on progress tracking

**Three Roles Integration**:

- **AI as Teacher**: AI suggests progress file structure and decomposition
- **AI as Student**: You teach AI the feature requirements
- **Convergence**: Iterate on task granularity and checkpoint timing

**Try With AI** (3 prompts):

1. Progress template creation (AI generates initial template)
2. Task decomposition (break feature into 10-15 tasks)
3. Session resumption test (verify AI picks up from progress file)

**Prerequisites**: Lessons 5-6 (tacit knowledge, lifecycle management)

---

### Lesson 8: Mid-Stream Memory — Injecting Context at Execution Time

**Duration**: 90 min (technical)
**Layer**: L3 (Intelligence Design)
**User Story**: US5 — Preventing Workflow Drift

**Learning Objectives**:

1. Explain the workflow drift problem (turn 1 memories become irrelevant by turn 20)
2. Implement PreToolUse memory injection using thinking block extraction
3. Apply deduplication with temp log + thinking hash (<500ms performance target)

**Key Concepts** (count: 8 — within B1 limit):

- Workflow drift problem
- UserPromptSubmit vs PreToolUse injection timing
- Thinking block extraction (last 1,500 chars)
- Semantic embedding of thinking
- Vector database query for similar memories
- additionalContext injection
- Deduplication with thinking hash
- <500ms performance target

**Lab**: Build Your First Memory Hook

- **Deliverable**: Working semantic memory injection hook
- **Protocol**: Set up vector DB, create memory corpus, write PreToolUse hook, add deduplication, test on multi-step task

**Teaching Approach**: Technical implementation with AI co-design on hook architecture

**Reusable Intelligence Created**: PreToolUse memory injection hook pattern (can be reused across projects)

**Try With AI** (3 prompts):

1. Drift diagnosis (identify where workflow drift would occur)
2. Hook architecture design (AI co-designs hook structure)
3. Memory corpus creation (populate initial memories)

**Prerequisites**: Lesson 7 (progress files), Chapter 3 Lesson 13 (Hooks basics)

---

### Lesson 9: Context Isolation — Why Clean Slates Beat Dirty States

**Duration**: 60 min
**Layer**: L3 (Intelligence Design)
**User Story**: US6 — Coordinating Multi-Agent Systems

**Learning Objectives**:

1. Explain the dirty slate problem (accumulated context pollution across linear pipeline)
2. Implement the clean context pattern (orchestrator with isolated subagents)
3. Apply context amnesia workarounds (Skills preload, master-clone, delegation context)

**Key Concepts** (count: 7 — within B1 limit):

- Dirty slate problem (linear pipeline accumulation)
- Clean context pattern (orchestrator + fresh context per subagent)
- Subagent design patterns (Stateless, Stateful/Handoff, Shared/Network)
- Context isolation benefits (full attention budget, no pollution, easier debugging, parallel execution)
- Context amnesia problem (subagents don't inherit parent context)
- Workarounds: Skills preload, master-clone, delegation context
- Tool access control by role

**Lab**: Dirty Slate vs Clean Context Comparison

- **Deliverable**: Quality comparison evidence (which pattern produces better results)
- **Protocol**: Design 3-step task, implement both patterns, compare quality, confusion errors, time

**Teaching Approach**: Comparative experiment + AI collaboration on orchestrator design

**Reusable Intelligence Created**: Multi-agent orchestration pattern (clean context template)

**Try With AI** (3 prompts):

1. Dirty slate audit (identify pollution in current multi-step workflow)
2. Orchestrator design (AI co-designs clean context architecture)
3. Subagent configuration (define tool access and context loading)

**Prerequisites**: Lesson 8 (memory injection), Chapter 3 Lesson 9 (Subagents basics)

---

### Lesson 10: The Context Engineering Playbook — Decision Frameworks for Quality

**Duration**: 120 min (capstone)
**Layer**: L4 (Spec-Driven Integration)
**User Story**: US7 — Applying Decision Frameworks

**Learning Objectives**:

1. Traverse the context engineering decision tree to identify appropriate technique for any context-related issue
2. Build a production-quality specialized agent demonstrating all chapter techniques
3. Validate that agent maintains quality at turn 1 and turn 50 (attention management), resumes after 24h (progress files), has no workflow drift (memory injection), and shows clean multi-agent coordination (context isolation)

**Key Concepts** (count: 8 — within B1 limit):

- Context engineering decision tree
- Context budget allocation (system prompt, CLAUDE.md, tools, history, tool outputs, reserve buffer)
- Seven token budgeting strategies
- When-to-use-what framework
- Quality assessment criteria (consistency, persistence, scalability, knowledge)
- Business value translation (technical quality → client outcomes)
- Continuous improvement mindset
- Digital FTE production workflow

**Lab**: Build Your First Production-Quality Agent

- **Deliverable**: Production-quality specialized agent with optimized context architecture, multi-session persistence, semantic memory injection, and quality verification evidence
- **Protocol**:
  1. Foundation: Audit/optimize CLAUDE.md (<60 lines, position-sensitive)
  2. Persistence: Extract tacit knowledge, create progress architecture
  3. Memory: Build semantic memory store, implement PreToolUse hook
  4. Scale: Design subagent architecture, implement context isolation
  5. Quality Gate: Run verification tests (turn 1 vs 50, 24h resume, multi-step drift, multi-agent coordination)

**Teaching Approach**: Spec-driven integration of all chapter techniques + AI orchestration

**Three Roles Integration**:

- **AI as Teacher**: AI suggests optimization opportunities
- **AI as Student**: You teach AI your specific domain requirements
- **AI as Co-Worker**: Full orchestration—you specify, AI implements

**Try With AI** (3 prompts):

1. Quality checklist assessment (consistency, persistence, scalability, knowledge)
2. Client pitch (translate technical quality to business value)
3. Improvement roadmap (prioritize next enhancements by effort vs impact)

**Prerequisites**: Lessons 1-9 (complete chapter foundation)

---

## VII. Skill Dependencies

### Within-Chapter Dependencies

```
Lesson 1 (Manufacturing Quality) → Foundation for all
    │
    ├── Lesson 2 (Attention Budget) → Lesson 3 (Position) → Lesson 4 (Signal/Noise)
    │                                       │                      │
    │                                       └──────────────────────┘
    │                                                              │
    │                                                              v
    │                                       Lesson 5 (Tacit Knowledge) → Lesson 7 (Progress Files)
    │                                                              │
    │                                       Lesson 6 (Lifecycle) ──┘
    │                                                              │
    │                                                              v
    │                                       Lesson 8 (Memory Injection)
    │                                                              │
    │                                                              v
    │                                       Lesson 9 (Context Isolation)
    │                                                              │
    └──────────────────────────────────────────────────────────────┘
                                                                   │
                                                                   v
                                                    Lesson 10 (Capstone)
```

### Cross-Chapter Dependencies

**Required from Chapter 3**:

- Lesson 5-6: CLAUDE.md creation and customization
- Lesson 7-8: Skills creation
- Lesson 9: Subagents basics
- Lesson 13: Hooks configuration

**Validates from chapter-index.md**: Chapter 3 is implemented (status: complete)

**Prepares for Chapter 5**:

- Principle 5 "Persisting State in Files" — Chapter 4 provides the WHY and HOW

---

## VIII. Implementation Sequence

### Phase 1: Foundation Lessons (Lessons 1-3)

**Order**: 1 → 2 → 3 (strict sequential)
**Estimated Time**: 4-5 hours content creation per lesson

**Quality Gates**:

- [ ] No Chapter 3 repetition (focus on WHY, not HOW)
- [ ] All statistics cited from authoritative sources
- [ ] Labs produce concrete artifacts
- [ ] No meta-commentary (framework invisible)

### Phase 2: Technique Lessons (Lessons 4-7)

**Order**: 4 → 5 → 6 → 7 (strict sequential, Three Roles integration)
**Estimated Time**: 5-6 hours content creation per lesson

**Quality Gates**:

- [ ] Each lesson demonstrates all three roles
- [ ] AI collaboration is bidirectional (not one-way instruction)
- [ ] Labs produce artifacts students can use in production

### Phase 3: Advanced Lessons (Lessons 8-9)

**Order**: 8 → 9 (strict sequential, intelligence design)
**Estimated Time**: 6-7 hours content creation per lesson

**Quality Gates**:

- [ ] Each lesson creates reusable intelligence (hook pattern, orchestration pattern)
- [ ] Technical implementations are tested and executable
- [ ] Patterns are general (not project-specific)

### Phase 4: Capstone (Lesson 10)

**Order**: Last (after all other lessons complete)
**Estimated Time**: 8-10 hours content creation

**Quality Gates**:

- [ ] Integrates all chapter techniques
- [ ] Produces sellable Digital FTE quality agent
- [ ] Decision tree is comprehensive and navigable
- [ ] Quality verification tests are specific and measurable

---

## IX. Quality Gates

### Constitutional Compliance

- [ ] **QG-001**: Principle 5 connection explicit in Lessons 1 and 10
- [ ] **QG-002**: No Chapter 3 repetition (focus on WHY/WHEN, not HOW)
- [ ] **QG-003**: All labs produce concrete artifacts
- [ ] **QG-004**: Capstone produces production-quality agent

### Factual Accuracy

- [ ] All statistics from Liu et al. (2023) "Lost in the Middle" verified
- [ ] All context rot research from Chroma verified
- [ ] All industry claims cited from The New Stack, HumanLayer verified
- [ ] All code examples tested and executable

### Pedagogical Structure

- [ ] Layer distribution follows Foundation → Techniques → Advanced → Integration
- [ ] Each Layer 2 lesson demonstrates all three roles
- [ ] Each Layer 3 lesson creates reusable intelligence
- [ ] Capstone (Layer 4) produces Digital FTE

### Anti-Convergence

- [ ] Teaching modality varies across lessons
- [ ] Examples are production-relevant (not toy apps)
- [ ] No meta-commentary or framework labels in student-facing content
- [ ] "Try With AI" sections use action prompts (not "What to notice")

---

## X. Chapter Renumbering Tasks

### Files to Rename

| Current Path                                                             | New Path                                                                 |
| ------------------------------------------------------------------------ | ------------------------------------------------------------------------ |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-seven-principles/` | `apps/learn-app/docs/01-General-Agents-Foundations/05-seven-principles/` |

### Files to Create

| Path                                                                                                           | Purpose             |
| -------------------------------------------------------------------------------------------------------------- | ------------------- |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-context-engineering/`                                    | Chapter 4 directory |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-context-engineering/README.md`                           | Chapter overview    |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-context-engineering/01-manufacturing-quality-problem.md` | Lesson 1            |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-context-engineering/02-attention-budget.md`              | Lesson 2            |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-context-engineering/03-lost-in-the-middle.md`            | Lesson 3            |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-context-engineering/04-signal-vs-noise.md`               | Lesson 4            |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-context-engineering/05-tacit-knowledge.md`               | Lesson 5            |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-context-engineering/06-context-lifecycle.md`             | Lesson 6            |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-context-engineering/07-progress-files.md`                | Lesson 7            |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-context-engineering/08-memory-injection.md`              | Lesson 8            |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-context-engineering/09-context-isolation.md`             | Lesson 9            |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-context-engineering/10-context-engineering-playbook.md`  | Lesson 10           |
| `apps/learn-app/docs/01-General-Agents-Foundations/04-context-engineering/11-chapter-quiz.md`                  | Assessment          |

### Cross-References to Update

- [ ] `apps/learn-app/docs/01-General-Agents-Foundations/README.md` (part-level index)
- [ ] `apps/learn-app/docs/01-General-Agents-Foundations/05-seven-principles/README.md` (update sidebar_position)
- [ ] Any internal links in Chapter 3 referencing "Chapter 4" or "Chapter 5"
- [ ] Spec references in `specs/` directory

---

## XI. Validation Checklist

### Chapter-Level Validation

- [x] Chapter type identified: Technical/Conceptual hybrid (engineering discipline, not programming)
- [x] Concept density analysis documented: 12 concepts across 10 lessons
- [x] Lesson count justified: 10 lessons based on concept density + B1 proficiency + stage requirements
- [x] All evals from spec covered by lessons
- [x] All lessons map to at least one eval

### Stage Progression Validation

- [x] Lessons 1-3: Layer 1 (Manual Foundation, no AI collaboration yet)
- [x] Lessons 4-7: Layer 2 (AI Collaboration with Three Roles)
- [x] Lessons 8-9: Layer 3 (Intelligence Design, reusable artifacts)
- [x] Lesson 10: Layer 4 (Spec-Driven Integration, Digital FTE production)
- [x] No spec-first before Layer 4

### Cognitive Load Validation

- [x] Each lesson's concept count within B1 limit (max 10)
- [x] Lesson 1: 5 concepts
- [x] Lesson 2: 6 concepts
- [x] Lesson 3: 5 concepts
- [x] Lesson 4: 6 concepts
- [x] Lesson 5: 7 concepts
- [x] Lesson 6: 6 concepts
- [x] Lesson 7: 7 concepts
- [x] Lesson 8: 8 concepts
- [x] Lesson 9: 7 concepts
- [x] Lesson 10: 8 concepts

### Dependency Validation

- [x] Skill dependencies satisfied by lesson order
- [x] Cross-chapter dependencies validated (Chapter 3 complete)

### Three Roles Validation (Layer 2 lessons)

- [x] Lesson 4 demonstrates AI as Teacher, AI as Student, Convergence
- [x] Lesson 5 demonstrates AI as Teacher, AI as Student, Convergence
- [x] Lesson 6 demonstrates AI as Teacher, AI as Student, Convergence
- [x] Lesson 7 demonstrates AI as Teacher, AI as Student, Convergence

---

## XII. Success Criteria Summary

**This chapter succeeds when**:

1. Students understand WHY context quality determines agent value (not just HOW to use tools)
2. Students can diagnose context-related issues using specific frameworks (attention budget, position sensitivity, rot types)
3. Students apply context engineering as a systematic discipline (not random optimization)
4. Students connect context engineering to Digital FTE manufacturing quality (thesis alignment)
5. Students are prepared for Principle 5 "Persisting State in Files" with deep understanding of WHY it works
6. Capstone produces production-quality specialized agent worth demonstrating to clients

**This chapter fails when**:

- Students learn techniques without understanding underlying mechanics
- Content repeats Chapter 3 tool usage instead of engineering discipline
- Labs produce no artifacts or non-transferable artifacts
- Thesis connection (Digital FTE manufacturing quality) is missing or weak
- Principle 5 connection is not explicit

---

**Plan Version**: 1.0.0
**Approved for Implementation**: Pending user review
**Next Step**: /sp.tasks to generate implementation checklist
