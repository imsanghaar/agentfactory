# Chapter 57: Dapr Actors & Workflows for Stateful Agents - Implementation Plan

**Generated by**: chapter-planner v2.0.0 (Reasoning-Activated)
**Source Spec**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/specs/chapter-57-dapr-actors-workflows/spec.md`
**Expertise Skill**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/.claude/skills/building-with-dapr/SKILL.md`
**Created**: 2025-12-29
**Constitution**: v6.0.0 (Reasoning Mode)

---

## I. Chapter Analysis

### Chapter Type

**Technical/Code-Focused** — This chapter requires extensive Python code implementation with `dapr-ext-fastapi` for actors and `dapr-ext-workflow` for workflows. All learning objectives use apply/create/implement verbs, and code examples are mandatory throughout.

### Concept Density Analysis

**Core Concepts** (from spec): 18 concepts across two major building blocks

**Part A - Actors (9 concepts)**:
1. Actor Model (Hewitt, 1973) - conceptual foundation
2. Virtual Actors pattern (Dapr/Orleans implementation)
3. Turn-based concurrency (single-threaded per actor)
4. Actor lifecycle (activation, deactivation, garbage collection)
5. Actor state management (_state_manager, persistence)
6. Timers (non-persistent scheduling)
7. Reminders (persistent scheduling)
8. Actor communication patterns (ActorProxy, delegation)
9. Event-driven actors (pub/sub + bindings integration)

**Part B - Workflows (6 concepts)**:
1. Durable execution (event sourcing, checkpointing)
2. Workflow determinism (replay-safe code)
3. Activities (units of work)
4. Workflow patterns (chaining, fan-out/fan-in)
5. Saga pattern (compensation)
6. Monitor pattern (continue_as_new)

**Part C - Production (3 concepts)**:
1. Actors vs Workflows decision framework
2. Multi-app workflows (cross-service orchestration)
3. Namespaced actors (multi-tenancy)

**Complexity Assessment**: Complex (18 concepts, production patterns, two building blocks)

**Proficiency Tier**: B1 (Intermediate) - from spec

**Justified Lesson Count**: 21 lessons (as specified)
- L00: Skill Extension (L3)
- L01-L08: Actors Foundation + Practice (L1, L2)
- L09-L14: Workflows Foundation + Practice (L1, L2)
- L15-L18: Production Patterns (L2)
- L19-L20: Capstone + Skill Finalization (L4, L3)

**Reasoning**: 18 core concepts across two major building blocks, B1 proficiency level, requires extensive hands-on practice. The lesson count is justified by:
- Actors require 8 lessons (9 concepts with significant code)
- Workflows require 6 lessons (6 concepts with patterns)
- Production integration requires 4 lessons (3 concepts applied to real scenarios)
- Skill-First pattern adds L00 and L20
- Capstone integrates everything

---

## II. Success Evals (from Spec)

**Predefined Success Criteria** (evals-first requirement):

1. **SC-001**: Students can explain the actor model and its benefits in under 2 minutes (L01)
2. **SC-002**: Students can implement a working ChatActor with state persistence (L03-L04)
3. **SC-003**: Students can implement timers AND reminders with correct use case selection (L05)
4. **SC-004**: Students can trace actor method calls via Zipkin/Jaeger (L08)
5. **SC-005**: Students can explain workflow determinism rules and identify violations (L10)
6. **SC-006**: Students can implement a workflow with 3+ chained activities that survives restart (L11)
7. **SC-007**: Students can implement fan-out/fan-in pattern processing 5+ items in parallel (L13)
8. **SC-008**: Students can implement saga pattern with compensation (L14)
9. **SC-009**: Students can decide when to use actors vs workflows for a given scenario (L15)
10. **SC-010**: Students can implement cross-app workflow with activities on different services (L16)
11. **SC-011**: Students can configure multi-tenant actors with namespace isolation (L17)
12. **SC-012**: Students can secure actors with state encryption and mTLS (L18)
13. **SC-013**: Capstone integrates actors and workflows on Docker Desktop Kubernetes (L19)
14. **SC-014**: Students' extended `dapr-deployment` skill generates valid actor/workflow code (L20)

**All lessons below map to these evals.**

---

## III. Pedagogical Arc

```
PART A: DAPR ACTORS (L00-L08)
│
├── L00: Extend Your Dapr Skill (L3 - Skill Extension)
│   └── SKILL-FIRST: Fetch actor/workflow docs, extend existing skill
│
├── L01: The Actor Model (L1 - Manual Foundation)
│   └── CONCEPTUAL: Hewitt 1973, Virtual Actors, turn-based concurrency
│   └── NO CODE YET - build mental model first
│
├── L02-L08: Actor Implementation (L2 - AI Collaboration)
│   └── PROGRESSIVE: HelloActor → ChatActor → State → Timers → Communication → Events → Observability
│   └── THREE ROLES throughout
│
PART B: DAPR WORKFLOWS (L09-L14)
│
├── L09-L10: Workflow Foundations (L1 - Manual Foundation)
│   └── CONCEPTUAL: Durable execution, replay, determinism
│   └── UNDERSTAND before implementing
│
├── L11-L14: Workflow Implementation (L2 - AI Collaboration)
│   └── PROGRESSIVE: Authoring → Managing → Patterns (Chaining, Fan-Out) → Patterns (Saga, Monitor)
│
PART C: PRODUCTION PATTERNS (L15-L18)
│
├── L15-L18: Advanced Integration (L2 - AI Collaboration)
│   └── INTEGRATION: Actors+Workflows, Multi-App, Namespaces, Security
│
PART D: CAPSTONE & SKILL (L19-L20)
│
├── L19: Capstone - Stateful Task Agent (L4 - Spec-Driven)
│   └── SPEC-FIRST: Write spec → Compose skills → Orchestrate
│
└── L20: Finalize Your Dapr Skill (L3 - Skill Finalization)
    └── VALIDATE: Test skill generates correct code, document improvements
```

---

## IV. Lesson Sequence

---

### L00: Extend Your Dapr Skill

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/00-extend-your-dapr-skill.md`

**Learning Objective**: Extend the existing `dapr-deployment` skill with actor and workflow patterns using official documentation

**Stage**: 3 (Skill Extension - Skill-First Pattern)

**CEFR Proficiency**: B1

**New Concepts** (count: 2):
1. Skill extension workflow (fetching new docs, updating skill)
2. Actor/workflow SDK integration points

**Cognitive Load Validation**: 2 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-014

**Key Content**:
- Clone skills-lab fresh (no state assumptions)
- Write LEARNING-SPEC.md for actors & workflows extension
- Use `/fetching-library-docs` to fetch `dapr-ext-workflow` documentation
- Extend skill with:
  - Actor interface patterns (ABC + @actormethod)
  - Actor registration with DaprActor(app)
  - WorkflowRuntime setup and registration
  - Activity definitions
  - Workflow client patterns

**Code Examples**:
- Skill extension prompt template
- Sample LEARNING-SPEC.md structure

**"Try With AI" Prompts**:
1. "Using /fetching-library-docs, fetch the dapr-ext-workflow Python SDK documentation and summarize the key classes I need to know"
   - **What you're learning**: How to ground skill knowledge in official documentation
2. "Help me extend my dapr-deployment skill to include actor state management patterns from the official Dapr actors docs"
   - **What you're learning**: Iterative skill improvement from authoritative sources
3. "Generate a test scenario for my updated skill: ask it to create a basic actor that stores greeting history"
   - **What you're learning**: Skill validation through concrete test cases

**Duration**: 25 min

---

### L01: The Actor Model

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/01-the-actor-model.md`

**Learning Objective**: Explain the Actor Model (Hewitt, 1973), Virtual Actors, and turn-based concurrency

**Stage**: 1 (Manual Foundation)

**CEFR Proficiency**: B1

**New Concepts** (count: 5):
1. Actor Model (1973) - actors, state, behavior, mailbox
2. Message-passing (no shared state, no locks)
3. Virtual Actors pattern (Orleans, on-demand activation)
4. Turn-based concurrency (single-threaded per actor)
5. Actor lifecycle (activation, deactivation, garbage collection)

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-001

**Key Content**:
- **The Actor Model Origin**: Carl Hewitt, Peter Bishop, Richard Steiger (1973)
- **Actor Components**:
  - Private state (encapsulated, never shared)
  - Behavior (logic to process messages)
  - Mailbox (queue for async messages, FIFO)
- **Why Actors for AI Agents**:
  - Each agent = one actor (ChatActor, TaskActor)
  - State isolation (no race conditions between agents)
  - Horizontal scaling (distribute actors across nodes)
- **Virtual Actors (Dapr/Orleans)**:
  - Activated on-demand when first invoked
  - Garbage-collected after idle timeout
  - State persisted automatically
  - Location-transparent (Placement service handles distribution)
- **Turn-Based Concurrency**:
  - One message processed at a time per actor
  - No locks, no mutexes, no race conditions
  - Diagram: Message queue -> Actor processing

**Diagrams Needed**:
1. Actor anatomy (state + behavior + mailbox)
2. Turn-based concurrency (queue -> single-threaded processing)
3. Virtual actor lifecycle (dormant -> activated -> processing -> idle -> deactivated)

**"Try With AI" Prompts**:
1. "Explain the Actor Model to me like I understand threads and locks but keep running into race condition bugs. Why would actors help?"
   - **What you're learning**: Connecting actor benefits to real problems you've experienced
2. "Compare traditional actors (like Akka) with Virtual Actors (like Dapr). What's the key difference in lifecycle management?"
   - **What you're learning**: Understanding Dapr's specific implementation choice
3. "My AI chat application needs to maintain separate conversation histories for 10,000 concurrent users. Explain why actors are ideal for this, using the turn-based concurrency concept."
   - **What you're learning**: Mapping actor concepts to your domain (AI agents)

**Reflect on Your Skill**: Does your skill explain actor model fundamentals? Test it with: "Using my dapr-deployment skill, explain why I'd use an actor instead of a regular FastAPI endpoint with Redis state."

**Duration**: 25 min

**Source Material**:
- `07_daca_agent_native_dev/05_agent_actors/01_hello_actors/README.md`
- `.claude/skills/building-with-dapr/references/actors.md`

---

### L02: Hello Actors - Your First Actor

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/02-hello-actors.md`

**Learning Objective**: Create, register, and invoke a basic Dapr Actor using Python and FastAPI

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 5):
1. Actor interface definition (ActorInterface + @actormethod)
2. Actor implementation (class extending Actor)
3. Actor registration with DaprActor(app)
4. Actor invocation via ActorProxy
5. Actor state store configuration (actorStateStore: "true")

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-002 (partial)

**Key Content**:
- **Installation**: `pip install dapr-ext-fastapi`
- **Actor Interface Pattern**:
  ```python
  from dapr.actor import ActorInterface, actormethod

  class HelloAgentInterface(ActorInterface):
      @actormethod(name="AddGreeting")
      async def add_greeting(self, greeting: dict) -> None: ...

      @actormethod(name="GetGreetingHistory")
      async def get_greeting_history(self) -> list[dict] | None: ...
  ```
- **Actor Implementation**:
  ```python
  from dapr.actor import Actor

  class HelloAgent(Actor, HelloAgentInterface):
      def __init__(self, ctx, actor_id):
          super().__init__(ctx, actor_id)
          self._history_key = f"history-{actor_id.id}"

      async def _on_activate(self) -> None:
          # Initialize state on activation
          ...

      async def add_greeting(self, greeting: dict) -> None:
          # Process greeting, update state
          ...
  ```
- **FastAPI Registration**:
  ```python
  from dapr.ext.fastapi import DaprActor

  app = FastAPI()
  dapr_actor = DaprActor(app)

  @app.on_event("startup")
  async def startup():
      await dapr_actor.register_actor(HelloAgent)
  ```
- **Actor Invocation**:
  ```python
  from dapr.actor import ActorProxy, ActorId

  proxy = ActorProxy.create("HelloAgent", ActorId("user-123"), HelloAgentInterface)
  await proxy.AddGreeting({"message": "Hello!"})
  ```
- **State Store Configuration**: Add `actorStateStore: "true"` to statestore.yaml

**Three Roles Demonstrations**:

1. **AI as Teacher**: Student asks "How do I define an actor that tracks greeting history?" AI explains @actormethod decorator, naming convention (Python snake_case in implementation, PascalCase in decorator name), and state manager pattern.

2. **AI as Student**: Student says "I want the actor to limit history to last 5 entries." AI adapts implementation to include `if len(history) > 5: history = history[-5:]`

3. **AI as Co-Worker**: Student and AI iterate on error handling in `_on_activate` - first version crashes on missing state, AI suggests try/except with initialization fallback, student refines to add logging.

**"Try With AI" Prompts**:
1. "Help me create a HelloAgent actor that stores greeting messages. Show me the interface, implementation, and registration code."
   - **What you're learning**: Complete actor creation workflow from interface to registration
2. "I've created my actor but getting ACTOR_TYPE_NOT_FOUND. Debug this with me - here's my registration code..."
   - **What you're learning**: Common actor registration errors and debugging
3. "Extend my HelloAgent to track timestamps with each greeting using Python's datetime. Make sure the data serializes correctly to Redis."
   - **What you're learning**: State serialization considerations for actors

**Reflect on Your Skill**: Test your skill with: "Using my dapr-deployment skill, generate a complete actor that tracks user preferences with get/set methods."

**Duration**: 30 min

**Source Material**:
- `07_daca_agent_native_dev/05_agent_actors/01_hello_actors/README.md`
- `dapr-docs-1.16/.../actors/howto-actors.md`

---

### L03: Chat Actor - Stateful Conversations

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/03-chat-actor.md`

**Learning Objective**: Build a ChatActor that maintains conversation history and integrates with Dapr pub/sub

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 4):
1. Complex actor state (conversation history as list of messages)
2. Actor methods for specific interactions (process_message, get_history)
3. Actor ID uniqueness (per-user instances)
4. Pub/sub integration from within actors (DaprClient publish)

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-002

**Key Content**:
- **ChatActor Interface**:
  ```python
  class ChatAgentInterface(ActorInterface):
      @actormethod(name="ProcessMessage")
      async def process_message(self, user_input: Message) -> Message | None: ...

      @actormethod(name="GetConversationHistory")
      async def get_conversation_history(self) -> list[dict] | None: ...
  ```
- **Complex State Management**:
  - Conversation history as list of {"role": "user/assistant", "content": "..."}
  - Limit to last N exchanges for memory efficiency
  - Per-user state isolation via actor_id
- **Pub/Sub Event Publishing**:
  ```python
  from dapr.clients import DaprClient

  async def _publish_conversation_event(self, user_input, response):
      with DaprClient() as client:
          client.publish_event(
              pubsub_name="pubsub",
              topic_name="conversation-events",
              data=json.dumps({...})
          )
  ```
- **Request/Response Pattern**: FastAPI endpoints invoke actor, return response
- **Event-Driven Pattern**: Actor publishes events for downstream processing

**Code Examples**:
- Complete ChatAgent implementation
- FastAPI endpoints for chat interaction
- Subscription endpoint for conversation events

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains the pattern of using DaprClient within actor methods for pub/sub, including the context manager pattern and proper error handling.

2. **AI as Student**: Student asks "Make the actor use a Pydantic model instead of raw dicts." AI adapts to use `Message(role: str, content: str)` model with validation.

3. **AI as Co-Worker**: Together they design the event payload structure - AI suggests CloudEvents metadata, student adds actor_id and history_key for correlation, converge on schema.

**"Try With AI" Prompts**:
1. "Help me build a ChatActor that maintains conversation history. I want it to store both user messages and assistant responses, limited to the last 10 exchanges."
   - **What you're learning**: Complex state management patterns for actors
2. "My ChatActor should publish a ConversationUpdated event whenever a message is processed. Show me how to use DaprClient inside the actor."
   - **What you're learning**: Integrating pub/sub with actor state changes
3. "I have users alice and bob chatting simultaneously. Explain how actor IDs ensure their conversations stay separate, and show me how to verify this with curl commands."
   - **What you're learning**: Actor ID isolation and testing strategies

**Reflect on Your Skill**: Does your skill understand ChatActor patterns? Test: "Generate a ChatActor for my customer support use case that stores customer context."

**Duration**: 35 min

**Source Material**:
- `07_daca_agent_native_dev/05_agent_actors/02_chat_actor/README.md`

---

### L04: Actor State Management

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/04-actor-state-management.md`

**Learning Objective**: Master actor state persistence with _state_manager, lifecycle hooks, and turn-based concurrency guarantees

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 5):
1. StateManager API (get_state, set_state, try_get_state)
2. Lifecycle hooks (_on_activate, _on_deactivate)
3. State persistence across deactivation/reactivation
4. Turn-based concurrency guarantees for state safety
5. State key naming patterns

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-002

**Key Content**:
- **StateManager Methods**:
  ```python
  # Get state (raises if not found)
  state = await self._state_manager.get_state("key")

  # Try get (returns tuple: (found, value))
  found, state = await self._state_manager.try_get_state("key")

  # Set state
  await self._state_manager.set_state("key", value)

  # Remove state
  await self._state_manager.remove_state("key")
  ```
- **Lifecycle Hooks**:
  ```python
  async def _on_activate(self) -> None:
      """Called when actor is activated (first message or after GC)."""
      found, state = await self._state_manager.try_get_state("data")
      if not found:
          await self._state_manager.set_state("data", default_value)

  async def _on_deactivate(self) -> None:
      """Called before actor is garbage-collected."""
      # Cleanup resources, final state save
  ```
- **State Persistence Demo**:
  1. Create actor, set state
  2. Wait for idle timeout (actor deactivates)
  3. Invoke actor again (reactivates)
  4. Verify state persists
- **Turn-Based Concurrency**:
  - Multiple concurrent requests to same actor -> queued
  - Only one method executes at a time
  - No race conditions on state

**Diagram**: State persistence across actor lifecycle (active -> idle -> deactivated -> reactivated -> state recovered)

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains the difference between `get_state` (throws on missing) vs `try_get_state` (returns tuple), recommending try_get_state for initialization patterns.

2. **AI as Student**: Student asks "I want state stored under a predictable key per actor." AI adapts to use `f"data-{self.id.id}"` pattern.

3. **AI as Co-Worker**: Together debug a scenario where state appears to be lost - discover actor was restarted before state was flushed, add explicit save in _on_deactivate.

**"Try With AI" Prompts**:
1. "Show me how actor state persists across deactivation. Walk me through what happens when my TaskActor goes idle, gets garbage-collected, and then receives a new request."
   - **What you're learning**: Virtual actor lifecycle and automatic state recovery
2. "Explain turn-based concurrency with a concrete scenario: 3 requests arrive simultaneously for the same actor. What happens and why is this safe?"
   - **What you're learning**: How actors eliminate race conditions without locks
3. "Help me implement a _on_activate hook that initializes default state only if no state exists, and a _on_deactivate that logs final state for debugging."
   - **What you're learning**: Lifecycle hook patterns for robust actors

**Reflect on Your Skill**: Test: "Using my skill, explain when I should use try_get_state vs get_state in an actor."

**Duration**: 30 min

**Source Material**:
- `07_daca_agent_native_dev/05_agent_actors/02_chat_actor/README.md`
- `.claude/skills/building-with-dapr/references/actors.md`

---

### L05: Timers and Reminders

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/05-timers-reminders.md`

**Learning Objective**: Implement actor timers for lightweight scheduling and reminders for persistent, durable scheduling

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 4):
1. Actor timers (in-memory, non-persistent)
2. Actor reminders (persisted, survive restarts)
3. Timer/reminder callbacks
4. Use case decision criteria

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-003

**Key Content**:
- **Timers vs Reminders Decision Table**:

| Feature | Timer | Reminder |
|---------|-------|----------|
| Persistence | Lost on deactivation | Survives restarts |
| Storage | In-memory only | State store |
| Use case | Lightweight, short-lived | Durable, long-lived |
| Resource cost | Low | Higher |
| Example | Timeout for response | Deadline notification |

- **Timer Implementation**:
  ```python
  async def start_heartbeat_timer(self):
      await self.register_timer(
          timer_name="heartbeat",
          callback="on_heartbeat",
          state=b'timer_state',
          due_time=timedelta(seconds=10),
          period=timedelta(seconds=30)
      )

  async def on_heartbeat(self, state: bytes) -> None:
      print(f"Heartbeat for {self.id}")
  ```
- **Reminder Implementation**:
  ```python
  async def set_deadline_reminder(self, deadline_seconds: int):
      await self.register_reminder(
          reminder_name="deadline",
          state=b'{"task_id": "123"}',
          due_time=timedelta(seconds=deadline_seconds),
          period=timedelta(seconds=0)  # One-time
      )

  async def receive_reminder(self, name: str, state: bytes,
                             due_time: timedelta, period: timedelta) -> None:
      if name == "deadline":
          await self.update_status("overdue")
  ```
- **Demonstration**: Set reminder, kill pod, restart, verify reminder fires

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains the Scheduler service's role in managing reminders, how they're persisted, and why timers are lost on deactivation.

2. **AI as Student**: Student says "I need a reminder that fires daily." AI adapts to show period-based recurring reminder with `period=timedelta(hours=24)`.

3. **AI as Co-Worker**: Together implement a task deadline system - AI suggests reminder for deadline, student adds grace period logic, converge on reminder + status update pattern.

**"Try With AI" Prompts**:
1. "Help me decide: I need to send a notification 24 hours after a task is created. Should I use a timer or reminder? Explain why."
   - **What you're learning**: Timer vs reminder decision criteria
2. "Implement a TaskActor with a deadline_reminder that marks the task as overdue. Show me how to test that the reminder survives pod restart."
   - **What you're learning**: Reminder durability and testing strategies
3. "Create a timer that sends a heartbeat every 30 seconds for monitoring, but stops when the actor deactivates. Explain why this is appropriate for heartbeats."
   - **What you're learning**: Timer use cases and lifecycle behavior

**Reflect on Your Skill**: Test: "When should I use a timer vs reminder for scheduling work in a Dapr actor?"

**Duration**: 30 min

**Source Material**:
- `07_daca_agent_native_dev/05_agent_actors/04_advanced_actor_config/01_actor_timers/`
- `07_daca_agent_native_dev/05_agent_actors/04_advanced_actor_config/02_actor_reminders/`
- `dapr-docs-1.16/.../actors/actors-timers-reminders.md`

---

### L06: Actor Communication Patterns

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/06-actor-communication.md`

**Learning Objective**: Implement actor-to-actor communication via ActorProxy for coordination patterns

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 4):
1. ActorProxy for invoking other actors
2. Parent-child actor pattern
3. Peer-to-peer actor pattern
4. Task delegation scenario

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-002 (advanced)

**Key Content**:
- **ActorProxy Invocation**:
  ```python
  from dapr.actor import ActorProxy, ActorId

  # From within an actor, call another actor
  async def delegate_to_worker(self, task_data: dict):
      worker_proxy = ActorProxy.create(
          "WorkerActor",
          ActorId(f"worker-{task_data['id']}"),
          WorkerActorInterface
      )
      result = await worker_proxy.ProcessTask(task_data)
      return result
  ```
- **Parent-Child Pattern**:
  - ManagerActor creates/manages WorkerActors
  - Parent tracks child actor IDs
  - Parent aggregates child results
- **Peer-to-Peer Pattern**:
  - Actors communicate as equals
  - No hierarchy, just collaboration
  - Example: ChatActor forwards to NotificationActor
- **Task Delegation Scenario**:
  ```
  TaskManagerActor
       │
       ├── TaskActor("task-1")
       ├── TaskActor("task-2")
       └── TaskActor("task-3")
  ```

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains that ActorProxy calls are async and go through Dapr sidecar, with automatic routing via Placement service.

2. **AI as Student**: Student asks "What if the target actor doesn't exist?" AI explains virtual actor semantics - it's created on first call.

3. **AI as Co-Worker**: Together implement a TaskManagerActor that delegates to TaskActors, with proper error handling for failed delegations.

**"Try With AI" Prompts**:
1. "Design a parent-child actor pattern where a ManagerActor creates and tracks multiple WorkerActors. Show me how the manager delegates tasks and collects results."
   - **What you're learning**: Hierarchical actor coordination patterns
2. "My ChatActor needs to notify a NotificationActor after processing a message. Show me the ActorProxy call and explain how Dapr routes this."
   - **What you're learning**: Actor-to-actor communication mechanics
3. "What happens if I call an actor that hasn't been created yet? Explain virtual actor semantics and how this affects my delegation pattern."
   - **What you're learning**: On-demand activation behavior

**Reflect on Your Skill**: Test: "Generate code for two actors that communicate - a TaskActor that delegates to a WorkerActor."

**Duration**: 30 min

**Source Material**:
- `07_daca_agent_native_dev/05_agent_actors/03_actors_communication/`

---

### L07: Event-Driven Actors

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/07-event-driven-actors.md`

**Learning Objective**: Integrate actors with Dapr pub/sub topics and bindings for event-driven patterns

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 4):
1. Actor subscription to pub/sub topics
2. Actor invocation from bindings
3. Event-driven actor patterns
4. Combining actors with external triggers

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-002 (integration)

**Key Content**:
- **Actor + Pub/Sub Pattern**:
  - Actor publishes events (DaprClient.publish_event)
  - FastAPI endpoint subscribes to topic
  - Subscription handler invokes actor
  ```python
  @dapr_app.subscribe(pubsub='pubsub', topic='task-events')
  async def handle_task_event(event_data: dict):
      actor_id = event_data.get("task_id")
      proxy = ActorProxy.create("TaskActor", ActorId(actor_id), TaskActorInterface)
      await proxy.ProcessEvent(event_data)
  ```
- **Actor + Bindings Pattern**:
  - Input binding triggers FastAPI endpoint
  - Endpoint invokes appropriate actor
  - Actor processes external system event
- **Use Cases**:
  - Webhook triggers actor processing
  - Cron job activates actor (Scheduler integration)
  - External queue message invokes actor

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains the difference between actors publishing events (outbound) and actors being triggered by events (inbound via subscription handler).

2. **AI as Student**: Student asks "Can an actor subscribe directly to a topic?" AI clarifies that subscriptions are at the app level, then route to actors.

3. **AI as Co-Worker**: Together design a webhook-to-actor flow - binding receives webhook, handler parses payload, invokes correct actor based on webhook type.

**"Try With AI" Prompts**:
1. "Show me how to connect a Dapr pub/sub subscription to actor invocation. When a task-event arrives, it should be processed by the corresponding TaskActor."
   - **What you're learning**: Event-driven actor activation patterns
2. "I want to trigger my SchedulerActor from a cron binding. Walk me through the binding configuration and the FastAPI handler that invokes the actor."
   - **What you're learning**: Combining bindings with actors
3. "Design an event-driven architecture where multiple event types (task.created, task.updated, task.completed) route to different actor methods. Show me the routing logic."
   - **What you're learning**: Event routing to actor methods

**Reflect on Your Skill**: Test: "Generate code for event-driven actor invocation from a pub/sub topic."

**Duration**: 35 min

**Source Material**:
- `07_daca_agent_native_dev/05_agent_actors/06_event_driven_actors/`

---

### L08: Actors Observability

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/08-actors-observability.md`

**Learning Objective**: Configure tracing, metrics, and debugging for actor systems

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 4):
1. Actor tracing with Zipkin/Jaeger
2. Actor metrics (activation count, method duration)
3. Dapr Dashboard for actor inspection
4. Debugging strategies for actor systems

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-004

**Key Content**:
- **Tracing Configuration**:
  ```yaml
  # config/tracing.yaml
  apiVersion: dapr.io/v1alpha1
  kind: Configuration
  metadata:
    name: daprConfig
  spec:
    tracing:
      samplingRate: "1"
      zipkin:
        endpointAddress: http://zipkin:9411/api/v2/spans
  ```
- **Viewing Traces**:
  - Open Zipkin/Jaeger UI
  - Find traces by actor type and method
  - Follow distributed trace through actor calls
- **Actor Metrics**:
  - `dapr_actor_active_count`: Current active actors by type
  - `dapr_actor_pending_calls`: Calls waiting in queue
  - `dapr_actor_operation_duration`: Method execution time
- **Dapr Dashboard**:
  - View registered actor types
  - See active instance counts
  - Inspect actor state (via Redis CLI)
- **Debugging Strategies**:
  - Enable `dapr.io/enable-api-logging: "true"`
  - Check sidecar logs: `kubectl logs <pod> -c daprd`
  - Verify actor registration: GET `/dapr/config`

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains how distributed tracing propagates context through actor calls, enabling end-to-end visibility.

2. **AI as Student**: Student asks "How do I find slow actor methods?" AI adapts to show duration metric queries and trace filtering.

3. **AI as Co-Worker**: Together troubleshoot an actor that isn't receiving calls - check registration, verify app-id, inspect sidecar logs.

**"Try With AI" Prompts**:
1. "Help me configure Zipkin tracing for my actor system and show me how to find traces for a specific TaskActor method call."
   - **What you're learning**: Distributed tracing setup and usage
2. "My actor seems to be taking too long. Show me how to use Dapr metrics to identify the slow method and diagnose the issue."
   - **What you're learning**: Performance debugging with metrics
3. "Walk me through debugging: my actor isn't receiving any calls. What should I check in the Dapr Dashboard, sidecar logs, and actor configuration?"
   - **What you're learning**: Systematic actor debugging approach

**Reflect on Your Skill**: Test: "How do I set up observability for actors in Kubernetes?"

**Duration**: 25 min

**Source Material**:
- `07_daca_agent_native_dev/05_agent_actors/05_actors_observability/`

---

### L09: Dapr Workflows Overview

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/09-workflows-overview.md`

**Learning Objective**: Understand durable workflow execution, event sourcing, and when to use workflows vs actors

**Stage**: 1 (Manual Foundation)

**CEFR Proficiency**: B1

**New Concepts** (count: 5):
1. Durable execution (survives failures)
2. Event sourcing (replay-based execution)
3. Workflow vs Actor decision criteria
4. Workflow engine architecture
5. Checkpointing and recovery

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-005 (partial), SC-009 (partial)

**Key Content**:
- **Why Workflows?**:
  - Long-running processes (hours, days)
  - Multi-step orchestration
  - Automatic retry and recovery
  - Human-in-the-loop patterns
- **Durable Execution**:
  - Workflow state persisted at each step
  - Crash recovery from last checkpoint
  - No lost work on failure
- **Event Sourcing Model**:
  - Workflow history stored as events
  - Replay reconstructs state
  - Enables "time travel" debugging
- **Actors vs Workflows Decision**:

| Use Case | Actors | Workflows |
|----------|--------|-----------|
| Stateful entity with identity | Yes | No |
| Long-running orchestration | No | Yes |
| Turn-based concurrency | Yes | No |
| Multi-step business process | No | Yes |
| Timers/Reminders on entity | Yes | No |
| Compensation/Rollback | No | Yes |
| Parallel task execution | No | Yes |
| Chat sessions | Yes | No |
| Order processing | No | Yes |

**Diagram**: Workflow execution with checkpointing (start -> activity -> checkpoint -> activity -> checkpoint -> complete)

**"Try With AI" Prompts**:
1. "Explain durable execution to me. What exactly is being persisted, and how does the workflow recover after a crash?"
   - **What you're learning**: Checkpoint and recovery mechanics
2. "I'm building an AI agent system. Some agents need conversation state (actors), others need multi-step task processing (workflows). Help me decide which to use for each component."
   - **What you're learning**: Practical decision framework
3. "What is event sourcing in the context of workflows? How does 'replaying history' reconstruct workflow state?"
   - **What you're learning**: Execution model fundamentals

**Reflect on Your Skill**: Test: "When should I use a workflow instead of an actor for my AI agent?"

**Duration**: 25 min

**Source Material**:
- `07_daca_agent_native_dev/06_dapr_workflows/01_hello_workflow/readme.md`
- `.claude/skills/building-with-dapr/references/workflows.md`

---

### L10: Workflow Architecture

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/10-workflow-architecture.md`

**Learning Objective**: Understand workflow engine internals, replay-based execution, and determinism requirements

**Stage**: 1 (Manual Foundation)

**CEFR Proficiency**: B1

**New Concepts** (count: 4):
1. Workflow engine (Durable Task Framework)
2. Replay-based execution model
3. Determinism rules
4. Activity isolation

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-005

**Key Content**:
- **Workflow Engine**:
  - Built on Durable Task Framework
  - Uses Dapr actor backend for state
  - Workflow = orchestrator, Activity = worker
- **Replay Mechanism**:
  1. Workflow starts, calls activity
  2. Engine persists "activity called" event
  3. Activity executes, returns result
  4. Engine persists "activity completed" event
  5. On replay: engine skips completed activities, returns cached results
- **Determinism Rules** (CRITICAL):
  ```python
  # DON'T use in workflow code:
  import random
  datetime.now()  # Use ctx.current_utc_datetime
  httpx.get(...)  # Use activity
  os.environ["X"]  # Pass as input

  # DO use:
  now = ctx.current_utc_datetime
  result = yield ctx.call_activity(make_api_call, input=url)
  ```
- **Why Determinism Matters**:
  - Replay must produce same sequence
  - Non-deterministic code causes replay failure
  - Activities can be non-deterministic (not replayed, cached)

**Diagram**: Replay process (history replay -> skip completed -> resume from checkpoint)

**"Try With AI" Prompts**:
1. "Explain the replay mechanism step by step. What happens when my workflow calls two activities, crashes, and then restarts?"
   - **What you're learning**: How replay reconstructs workflow state
2. "Why can't I use datetime.now() in my workflow? Show me what goes wrong and the correct alternative."
   - **What you're learning**: Determinism violations and fixes
3. "What's the difference between workflow code and activity code in terms of determinism requirements? Why can activities call external APIs directly?"
   - **What you're learning**: Workflow vs activity execution model

**Reflect on Your Skill**: Test: "What are the determinism rules for Dapr workflows? Give me a DO and DON'T list."

**Duration**: 25 min

**Source Material**:
- `07_daca_agent_native_dev/06_dapr_workflows/02_architecture_theory/readme.md`
- `dapr-docs-1.16/.../workflow/workflow-architecture.md`

---

### L11: Authoring Workflows

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/11-authoring-workflows.md`

**Learning Objective**: Implement workflow functions, activities, WorkflowRuntime setup, and data passing

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 5):
1. @wfr.workflow decorator
2. @wfr.activity decorator
3. WorkflowRuntime and client
4. ctx.call_activity with input/output
5. yield keyword for durable execution

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-006

**Key Content**:
- **Installation**: `pip install dapr-ext-workflow`
- **Activity Definition**:
  ```python
  @wfr.activity(name="validate_task")
  def validate_task(ctx: WorkflowActivityContext, task: dict) -> dict:
      # Activities CAN be non-deterministic
      return {"valid": True, "validated_at": datetime.now().isoformat()}
  ```
- **Workflow Definition**:
  ```python
  @wfr.workflow(name="task_processing")
  def task_processing_workflow(ctx: DaprWorkflowContext, task: dict):
      # Step 1: Validate
      validation = yield ctx.call_activity(validate_task, input=task)
      if not validation["valid"]:
          return {"status": "rejected"}

      # Step 2: Assign
      assignment = yield ctx.call_activity(assign_task, input=task)

      # Step 3: Complete
      return {"status": "completed", "assigned_to": assignment["assignee"]}
  ```
- **Runtime Setup**:
  ```python
  from dapr.ext.workflow import WorkflowRuntime, DaprWorkflowClient

  wfr = WorkflowRuntime()
  wfr.register_workflow(task_processing_workflow)
  wfr.register_activity(validate_task)
  wfr.register_activity(assign_task)

  # FastAPI lifespan
  @asynccontextmanager
  async def lifespan(app: FastAPI):
      wfr.start()
      yield
      wfr.shutdown()
  ```
- **Starting Workflows**:
  ```python
  client = DaprWorkflowClient()
  instance_id = client.schedule_new_workflow(
      workflow=task_processing_workflow,
      input={"task_id": "123", "title": "Review PR"}
  )
  ```

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains the yield keyword's role - it's not just "wait", it's the durability point where state is persisted.

2. **AI as Student**: Student asks "Can I add retry logic to activities?" AI adapts to show `retry_policy` parameter with backoff.

3. **AI as Co-Worker**: Together implement a 3-activity workflow with proper error handling, refining the activity interface based on what data needs to pass between steps.

**"Try With AI" Prompts**:
1. "Help me create my first workflow with 3 chained activities: validate_task, assign_task, send_notification. Show me the complete code including runtime setup."
   - **What you're learning**: Full workflow implementation pattern
2. "Explain the yield keyword in workflows. What exactly happens when I write `result = yield ctx.call_activity(...)`?"
   - **What you're learning**: How durability is achieved
3. "Add retry policy to my assign_task activity with 3 attempts and exponential backoff. Show me how retry works across workflow replays."
   - **What you're learning**: Activity retry configuration

**Reflect on Your Skill**: Test: "Generate a complete workflow with activities for task processing."

**Duration**: 35 min

**Source Material**:
- `07_daca_agent_native_dev/06_dapr_workflows/03_author_workflows/readme.md`
- `dapr-docs-1.16/.../workflow/howto-author-workflow.md`

---

### L12: Managing Workflows

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/12-managing-workflows.md`

**Learning Objective**: Start, query, raise events to, and terminate workflows via API and CLI

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 5):
1. schedule_new_workflow (start)
2. get_workflow_state (query)
3. wait_for_external_event (pause for input)
4. raise_workflow_event (send event)
5. terminate_workflow / purge_workflow (cleanup)

**Cognitive Load Validation**: 5 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-006 (management)

**Key Content**:
- **Start Workflow**:
  ```python
  client = DaprWorkflowClient()
  instance_id = client.schedule_new_workflow(
      workflow=approval_workflow,
      input={"order_id": "order-123", "amount": 1500}
  )
  ```
- **Query Status**:
  ```python
  state = client.get_workflow_state(instance_id, fetch_payloads=True)
  print(f"Status: {state.runtime_status}")  # RUNNING, COMPLETED, FAILED
  print(f"Output: {state.serialized_output}")
  ```
- **Wait for External Event**:
  ```python
  @wfr.workflow
  def approval_workflow(ctx, order: dict):
      if order["amount"] > 1000:
          yield ctx.call_activity(request_approval, input=order)
          approval = ctx.wait_for_external_event("approval_decision")
          timeout = ctx.create_timer(timedelta(days=3))
          winner = yield wf.when_any([approval, timeout])
          # ...
  ```
- **Raise Event**:
  ```python
  client.raise_workflow_event(
      instance_id=instance_id,
      event_name="approval_decision",
      data={"approved": True, "approver": "manager@company.com"}
  )
  ```
- **Terminate and Purge**:
  ```python
  client.terminate_workflow(instance_id)
  client.purge_workflow(instance_id)
  ```
- **CLI Commands**:
  ```bash
  dapr workflow run task_processing --app-id task-service --input '{"task_id": "123"}'
  dapr workflow get <instance-id> --app-id task-service
  dapr workflow raise-event <instance-id>/approval_decision --input '{"approved": true}'
  dapr workflow terminate <instance-id> --app-id task-service
  ```

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains the difference between terminate (stops but preserves history) and purge (removes all traces).

2. **AI as Student**: Student asks "What if the event arrives before the workflow is ready to receive it?" AI explains event buffering.

3. **AI as Co-Worker**: Together implement an approval workflow with external event and timeout, testing the various management operations.

**"Try With AI" Prompts**:
1. "Show me how to implement a workflow that waits for human approval. Include the external event handling and a 3-day timeout."
   - **What you're learning**: Human-in-the-loop pattern
2. "I started a workflow but need to cancel it. What's the difference between terminate and purge? Which should I use?"
   - **What you're learning**: Workflow lifecycle management
3. "Create a FastAPI endpoint that lets me query workflow status and raise events. I want to build a dashboard for workflow monitoring."
   - **What you're learning**: Building workflow management APIs

**Reflect on Your Skill**: Test: "How do I implement human approval in a Dapr workflow?"

**Duration**: 30 min

**Source Material**:
- `07_daca_agent_native_dev/06_dapr_workflows/04_manage_workflows/readme.md`
- `dapr-docs-1.16/.../workflow/howto-manage-workflow.md`

---

### L13: Workflow Patterns - Chaining & Fan-Out

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/13-patterns-chaining-fanout.md`

**Learning Objective**: Implement task chaining and fan-out/fan-in patterns for parallel processing

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 3):
1. Task chaining pattern
2. Fan-out (parallel scheduling)
3. Fan-in (when_all aggregation)

**Cognitive Load Validation**: 3 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-007

**Key Content**:
- **Task Chaining**:
  ```python
  @wfr.workflow
  def chained_workflow(ctx, data: dict):
      result1 = yield ctx.call_activity(step1, input=data)
      result2 = yield ctx.call_activity(step2, input=result1)
      result3 = yield ctx.call_activity(step3, input=result2)
      return result3
  ```
- **Fan-Out/Fan-In**:
  ```python
  @wfr.workflow
  def fanout_workflow(ctx, items: list):
      # Fan-out: Schedule all tasks in parallel
      parallel_tasks = [
          ctx.call_activity(process_item, input=item)
          for item in items
      ]

      # Fan-in: Wait for all to complete
      results = yield wf.when_all(parallel_tasks)

      # Aggregate results
      return {"total": sum(results), "count": len(results)}
  ```
- **Partial Completion (when_any)**:
  ```python
  # Wait for first to complete
  first_result = yield wf.when_any(parallel_tasks)
  ```
- **Real-World Example**: Process 10 AI agent tasks in parallel, aggregate insights

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains how parallel tasks are scheduled but durability is still maintained - each completion is an event in history.

2. **AI as Student**: Student asks "What if I have 1000 items? Will that overwhelm the system?" AI suggests batching pattern.

3. **AI as Co-Worker**: Together implement a fan-out workflow that processes 5+ items, with proper error handling for partial failures.

**"Try With AI" Prompts**:
1. "Show me a fan-out/fan-in workflow that processes 5 task items in parallel and aggregates the results. Include error handling if one fails."
   - **What you're learning**: Parallel execution with aggregation
2. "I need to process 100 items but want to batch them in groups of 10. Show me how to combine batching with fan-out."
   - **What you're learning**: Scaling parallel patterns
3. "What's the difference between when_all and when_any? Show me a scenario where I'd use each."
   - **What you're learning**: Parallel completion strategies

**Reflect on Your Skill**: Test: "Generate a fan-out/fan-in workflow for parallel processing."

**Duration**: 35 min

**Source Material**:
- `07_daca_agent_native_dev/06_dapr_workflows/05_patterns/01_task_chaining/`
- `07_daca_agent_native_dev/06_dapr_workflows/05_patterns/02_fan_in_out/`
- `.claude/skills/building-with-dapr/references/workflows.md`

---

### L14: Workflow Patterns - Saga & Monitor

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/14-patterns-saga-monitor.md`

**Learning Objective**: Implement saga pattern with compensation and monitor pattern with continue_as_new

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 3):
1. Saga pattern (compensating transactions)
2. Monitor pattern (eternal polling)
3. continue_as_new (history management)

**Cognitive Load Validation**: 3 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-008

**Key Content**:
- **Saga Pattern**:
  ```python
  @wfr.workflow
  def order_saga(ctx, order: dict):
      compensations = []

      try:
          yield ctx.call_activity(reserve_inventory, input=order)
          compensations.append(("release_inventory", order))

          yield ctx.call_activity(charge_payment, input=order)
          compensations.append(("refund_payment", order))

          yield ctx.call_activity(ship_order, input=order)
          return {"status": "completed"}

      except Exception as e:
          # Compensate in reverse order
          for comp_name, comp_data in reversed(compensations):
              yield ctx.call_activity(comp_name, input=comp_data)
          return {"status": "rolled_back", "error": str(e)}
  ```
- **Monitor Pattern**:
  ```python
  @wfr.workflow
  def health_monitor(ctx, state: dict):
      status = yield ctx.call_activity(check_health, input=state["target"])

      if status == "unhealthy" and state.get("was_healthy", True):
          yield ctx.call_activity(send_alert, input=state["target"])

      # Sleep for interval
      yield ctx.create_timer(timedelta(minutes=5))

      # Restart with new state (keeps history small)
      ctx.continue_as_new({
          "target": state["target"],
          "was_healthy": status == "healthy",
          "check_count": state.get("check_count", 0) + 1
      })
  ```
- **Why continue_as_new**:
  - History grows with each event
  - Long-running workflows accumulate large history
  - continue_as_new resets history while preserving state

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains saga compensation order (reverse of execution) and why this matters for consistency.

2. **AI as Student**: Student asks "What if the compensation itself fails?" AI discusses compensation retries and fallback strategies.

3. **AI as Co-Worker**: Together implement a task processing saga with proper compensation, testing failure at each step.

**"Try With AI" Prompts**:
1. "Implement a saga for task processing: create_task -> assign_task -> notify_assignee. If notification fails, roll back the assignment and creation."
   - **What you're learning**: Compensation pattern for consistency
2. "Create a monitor workflow that checks service health every 5 minutes and alerts on failures. Use continue_as_new to prevent history growth."
   - **What you're learning**: Eternal workflows with history management
3. "Explain why the saga compensation order is reversed. What would happen if we compensated in forward order?"
   - **What you're learning**: Consistency semantics

**Reflect on Your Skill**: Test: "Generate a saga workflow with compensation for a multi-step process."

**Duration**: 35 min

**Source Material**:
- `07_daca_agent_native_dev/06_dapr_workflows/05_patterns/04_monitor/`
- `.claude/skills/building-with-dapr/references/workflows.md`

---

### L15: Combining Actors with Workflows

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/15-actors-workflows-together.md`

**Learning Objective**: Design hybrid systems using actors for entity state and workflows for orchestration

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 3):
1. Decision framework (actors vs workflows)
2. Hybrid pattern (workflow orchestrating actors)
3. Actors as workflow activity backing

**Cognitive Load Validation**: 3 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-009

**Key Content**:
- **Decision Framework**:
  - **Use Actors when**: Entity needs identity, turn-based access, timers/reminders on entity
  - **Use Workflows when**: Multi-step process, parallel execution, compensation needed
  - **Use Both when**: Process orchestrates stateful entities
- **Hybrid Pattern**:
  ```python
  # Activity that calls an actor
  @wfr.activity
  def update_task_actor(ctx, task_data: dict) -> dict:
      proxy = ActorProxy.create("TaskActor", ActorId(task_data["id"]), TaskActorInterface)
      return await proxy.UpdateStatus(task_data["status"])

  # Workflow orchestrating actor calls
  @wfr.workflow
  def task_processing(ctx, task: dict):
      yield ctx.call_activity(update_task_actor, input={"id": task["id"], "status": "in_progress"})
      # ... more steps ...
      yield ctx.call_activity(update_task_actor, input={"id": task["id"], "status": "completed"})
  ```
- **Real-World Pattern**:
  - TaskActor: Holds task state, reminders for deadlines
  - TaskProcessingWorkflow: Orchestrates task through stages
  - Workflow calls actor for state updates

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains that actors maintain entity state while workflows orchestrate processes - they're complementary, not competing.

2. **AI as Student**: Student asks "Can a workflow start an actor?" AI clarifies that actors are virtual (always exist), workflows invoke actor methods.

3. **AI as Co-Worker**: Together design a task management system with TaskActor (state) and TaskWorkflow (orchestration), deciding what lives where.

**"Try With AI" Prompts**:
1. "I'm building a task management system. Help me decide what should be an actor (TaskActor) vs what should be a workflow (TaskProcessingWorkflow)."
   - **What you're learning**: Practical decision framework
2. "Show me how a workflow activity can call an actor. I want my TaskProcessingWorkflow to update the TaskActor's state at each step."
   - **What you're learning**: Hybrid integration pattern
3. "Design a complete system for order processing: OrderActor for order state, OrderWorkflow for the fulfillment process. Show me how they interact."
   - **What you're learning**: Real-world hybrid architecture

**Reflect on Your Skill**: Test: "When should I use actors vs workflows? Give me a decision tree."

**Duration**: 30 min

---

### L16: Multi-App Workflows

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/16-multi-app-workflows.md`

**Learning Objective**: Implement cross-app activity calls and child workflows for distributed orchestration

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 4):
1. Cross-app activity calls (app_id parameter)
2. Cross-app child workflows
3. Multi-app restrictions (namespace, state store)
4. Error handling for unavailable apps

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-010

**Key Content**:
- **Cross-App Activity**:
  ```python
  @wfr.workflow
  def orchestrator_workflow(ctx, data: dict):
      # Call activity on different app
      result = yield ctx.call_activity(
          'process_data',
          input=data,
          app_id='data-processor-service'  # Target app
      )
      return result
  ```
- **Cross-App Child Workflow**:
  ```python
  @wfr.workflow
  def parent_workflow(ctx, order: dict):
      # Start child workflow on different app
      result = yield ctx.call_child_workflow(
          workflow='payment_workflow',
          input=order,
          app_id='payment-service'
      )
      return result
  ```
- **Restrictions**:
  - All apps must be in same namespace
  - All apps must use same workflow state store
  - Target app must have activity/workflow registered
- **Error Handling**:
  - If target app unavailable: retry with policy
  - If activity/workflow not found: error returned

**Use Cases**:
- ML pipeline: CPU orchestrator calls GPU worker
- Multi-team: Each team owns their activities
- Cross-language: Python orchestrator, Go workers

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains that the `app_id` parameter routes to a different Dapr sidecar, enabling cross-service orchestration.

2. **AI as Student**: Student asks "What happens if the target app is down?" AI explains retry policy behavior.

3. **AI as Co-Worker**: Together implement a multi-app workflow with proper error handling and validation.

**"Try With AI" Prompts**:
1. "Show me how to call an activity on a different service. My orchestrator-service needs to call process_data activity on data-processor-service."
   - **What you're learning**: Cross-app activity invocation
2. "What are the restrictions for multi-app workflows? Can apps be in different namespaces or use different state stores?"
   - **What you're learning**: Multi-app deployment constraints
3. "Implement a parent workflow on app1 that calls a child workflow on app2. Include error handling for when app2 is unavailable."
   - **What you're learning**: Cross-app child workflows with resilience

**Reflect on Your Skill**: Test: "How do I call an activity on a different Dapr app from my workflow?"

**Duration**: 30 min

**Source Material**:
- `dapr-docs-1.16/.../workflow/workflow-multi-app.md`

---

### L17: Namespaced Actors

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/17-namespaced-actors.md`

**Learning Objective**: Configure actors for multi-tenant deployment with namespace isolation

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 4):
1. Actor namespacing for multi-tenancy
2. Separate state stores per namespace
3. Placement service namespace behavior
4. Namespace isolation guarantees

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-011

**Key Content**:
- **Why Namespaced Actors**:
  - Multi-tenant SaaS: Each customer in separate namespace
  - Environment isolation: dev, staging, prod
  - Same actor types, isolated state
- **State Store Configuration**:
  ```yaml
  # Namespace: tenant-a (using Redis DB 1)
  apiVersion: dapr.io/v1alpha1
  kind: Component
  metadata:
    name: statestore
    namespace: tenant-a
  spec:
    type: state.redis
    version: v1
    metadata:
      - name: redisHost
        value: redis:6379
      - name: actorStateStore
        value: "true"
      - name: redisDB
        value: "1"  # Tenant A uses DB 1

  # Namespace: tenant-b (using Redis DB 2)
  # ... same but redisDB: "2"
  ```
- **Kubernetes Setup**:
  ```bash
  kubectl create namespace tenant-a
  kubectl create namespace tenant-b
  kubectl apply -f statestore-a.yaml -n tenant-a
  kubectl apply -f statestore-b.yaml -n tenant-b
  ```
- **Placement Service Behavior**:
  - Actors in namespace-a don't receive placement info for namespace-b
  - Complete isolation at placement level

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains that namespace isolation requires SEPARATE state stores - same Redis instance can be used with different DB numbers.

2. **AI as Student**: Student asks "Can tenant-a call actors in tenant-b?" AI clarifies: no cross-namespace actor calls (isolation enforced).

3. **AI as Co-Worker**: Together configure two namespaces with isolated state stores, deploy same actor type to both.

**"Try With AI" Prompts**:
1. "I'm building a multi-tenant SaaS. Show me how to deploy the same TaskActor to different customer namespaces with isolated state."
   - **What you're learning**: Multi-tenant actor deployment
2. "Configure Redis state store for two namespaces: tenant-a (Redis DB 1) and tenant-b (Redis DB 2). Explain why separate databases are required."
   - **What you're learning**: State store isolation patterns
3. "What happens if tenant-a tries to invoke an actor in tenant-b? Explain the isolation guarantees."
   - **What you're learning**: Namespace security boundaries

**Reflect on Your Skill**: Test: "How do I deploy actors for multi-tenant isolation?"

**Duration**: 25 min

**Source Material**:
- `dapr-docs-1.16/.../actors/namespaced-actors.md`

---

### L18: Actor Security Essentials

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/18-actor-security.md`

**Learning Objective**: Secure actors with state encryption, mTLS, and audit logging

**Stage**: 2 (AI Collaboration)

**CEFR Proficiency**: B1

**New Concepts** (count: 4):
1. Actor state encryption at rest
2. mTLS for actor communication
3. Audit logging for actor methods
4. Actor threat model

**Cognitive Load Validation**: 4 concepts <= 10 limit -> WITHIN LIMIT

**Maps to Evals**: SC-012

**Key Content**:
- **Threat Model**:
  - State store access: Unencrypted state in Redis
  - Network interception: Actor-to-actor calls
  - Audit trail: Who called what method when
- **State Encryption**:
  - Dapr doesn't encrypt state by default
  - Use component-level encryption or encrypted Redis
  - Alternative: Encrypt/decrypt in actor code
- **mTLS (Automatic with Sentry)**:
  - Dapr Sentry issues certificates
  - All sidecar-to-sidecar traffic encrypted
  - Verify: `kubectl get pods -n dapr-system` shows dapr-sentry
- **Audit Logging**:
  ```python
  async def update_status(self, status: str) -> None:
      logging.info(f"AUDIT: Actor {self.id} status update to {status}")
      # ... implementation
  ```
  - Consider structured logging for SIEM integration
  - Include: actor_id, method, timestamp, caller (if available)

**Three Roles Demonstrations**:

1. **AI as Teacher**: AI explains the actor threat model - where sensitive data exists and how each security measure addresses it.

2. **AI as Student**: Student asks "Is mTLS automatic?" AI clarifies: yes with Dapr Sentry, verify it's running.

3. **AI as Co-Worker**: Together implement audit logging with structured format suitable for security monitoring.

**"Try With AI" Prompts**:
1. "Explain the threat model for actor systems. Where is sensitive data exposed and how do I protect each point?"
   - **What you're learning**: Security-first thinking for actors
2. "Show me how to verify mTLS is enabled for my actor deployment. What should I check in the Dapr control plane?"
   - **What you're learning**: Security verification
3. "Implement structured audit logging for my TaskActor. I want to track all method calls with enough detail for security review."
   - **What you're learning**: Audit trail implementation

**Reflect on Your Skill**: Test: "What security measures should I implement for production actors?"

**Duration**: 30 min

---

### L19: Capstone - Stateful Task Agent

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/19-capstone-stateful-task-agent.md`

**Learning Objective**: Build a complete TaskActor + TaskProcessingWorkflow system running on Docker Desktop Kubernetes

**Stage**: 4 (Spec-Driven Integration)

**CEFR Proficiency**: B1

**Maps to Evals**: SC-013

**Key Content**:

**SPEC-FIRST Approach**:
1. Write specification before code
2. Compose accumulated skills (actors, workflows, observability)
3. AI orchestrates implementation
4. Validate against spec

**System Components**:
- **TaskActor**: Stateful task entity with:
  - State: title, status, assignee, deadline
  - Methods: get_task, update_status, assign, set_deadline_reminder
  - Reminder: deadline_reminder that marks task overdue
- **TaskProcessingWorkflow**: Durable orchestration with:
  - Activities: validate_task, assign_task, notify_assignee
  - Patterns: Error handling, retries, compensation

**Project Structure**:
```
capstone/
├── task_actor_service/
│   ├── main.py          # TaskActor implementation
│   ├── Dockerfile
│   └── requirements.txt
├── task_workflow_service/
│   ├── main.py          # TaskProcessingWorkflow
│   ├── Dockerfile
│   └── requirements.txt
├── k8s/
│   ├── task-actor-deployment.yaml
│   ├── task-workflow-deployment.yaml
│   └── components/
│       ├── statestore.yaml
│       └── pubsub.yaml
└── spec.md              # System specification
```

**Capstone Specification Template**:
```markdown
# TaskAgent System Specification

## Intent
Build a stateful task management system using Dapr actors for entity state
and workflows for task processing orchestration.

## Components
1. TaskActor: Manages individual task state with deadline reminders
2. TaskProcessingWorkflow: Orchestrates task lifecycle (validate -> assign -> complete)

## Success Criteria
- [ ] TaskActor persists state across deactivation
- [ ] Deadline reminder fires and marks task overdue
- [ ] Workflow survives pod restart and resumes
- [ ] System runs on Docker Desktop Kubernetes
```

**Duration**: 45 min

---

### L20: Finalize Your Dapr Skill

**Output File**: `/Users/mjs/Documents/code/panaversity-official/tutorsgpt/p7-c/apps/learn-app/docs/07-AI-Cloud-Native-Development/59-dapr-actors-workflows/20-finalize-dapr-skill.md`

**Learning Objective**: Validate skill generates correct actor/workflow code and document improvements

**Stage**: 3 (Skill Finalization)

**CEFR Proficiency**: B1

**Maps to Evals**: SC-014

**Key Content**:
- **Skill Validation**:
  1. Test actor code generation
  2. Test workflow code generation
  3. Test combined patterns
- **Validation Prompts**:
  ```
  Using my dapr-deployment skill, generate a TaskActor with state management
  and deadline reminder.
  ```
  ```
  Using my dapr-deployment skill, generate a TaskProcessingWorkflow with
  3 chained activities and retry logic.
  ```
- **Document Improvements**:
  - What patterns were added?
  - What code templates work best?
  - What gaps remain?
- **Skill Portfolio Update**:
  - Add actor patterns to skill
  - Add workflow patterns to skill
  - Document what the skill now knows

**Duration**: 20 min

---

## V. Skill Dependencies

**Skill Dependency Graph**:
```
Actor Model (L01) -> First Actor (L02) -> Chat Actor (L03) -> State (L04)
                                                                   |
State (L04) -> Timers/Reminders (L05) -> Communication (L06) -> Events (L07) -> Observability (L08)
                                                                                      |
Workflow Concepts (L09) -> Architecture (L10) -> Authoring (L11) -> Managing (L12)
                                                                          |
Managing (L12) -> Chaining/Fan-Out (L13) -> Saga/Monitor (L14)
                                                    |
                            Actors+Workflows (L15) -> Multi-App (L16) -> Namespaces (L17) -> Security (L18)
                                                                                                   |
                                                                              Capstone (L19) -> Finalize (L20)
```

**Cross-Chapter Dependencies**:
- **Chapter 53 (Dapr Core)**: Students must complete Ch53 first
  - Provides: Dapr fundamentals, state management, pub/sub, `dapr-deployment` skill
  - Validation: Check `chapter-index.md` status

---

## VI. Assessment Plan

### Formative Assessments (During Lessons)

| Lesson | Assessment Type | Description |
|--------|----------------|-------------|
| L01 | Conceptual Quiz | Explain actor model in 2 minutes |
| L02 | Hands-on | Create and invoke HelloAgent |
| L03-L04 | Hands-on | Build ChatActor with persistence |
| L05 | Decision Exercise | Timer vs Reminder scenarios |
| L08 | Debugging | Trace actor call in Zipkin |
| L10 | Code Review | Identify determinism violations |
| L11 | Hands-on | 3-activity workflow that survives restart |
| L13 | Hands-on | Fan-out processing 5+ items |
| L14 | Hands-on | Saga with compensation |
| L15 | Design Exercise | Actor vs workflow decision tree |

### Summative Assessment (End of Chapter)

**L19 Capstone**: Complete TaskActor + TaskProcessingWorkflow system
- Runs on Docker Desktop Kubernetes
- Actor state persists
- Workflow survives restart
- Deadline reminder fires

**L20 Skill Validation**: Extended skill generates correct code

---

## VII. Source Material Mapping

| Lesson | Primary Source | Secondary Sources |
|--------|---------------|-------------------|
| L01 | actors.md reference | 01_hello_actors README |
| L02 | 01_hello_actors | actors-overview.md |
| L03-L04 | 02_chat_actor | actors.md reference |
| L05 | 04_advanced_actor_config | actors-timers-reminders.md |
| L06 | 03_actors_communication | - |
| L07 | 06_event_driven_actors | - |
| L08 | 05_actors_observability | - |
| L09-L10 | workflows.md reference | 01_hello_workflow |
| L11 | 03_author_workflows | howto-author-workflow.md |
| L12 | 04_manage_workflows | howto-manage-workflow.md |
| L13-L14 | 05_patterns/* | workflow-patterns.md |
| L15 | workflows.md reference | - |
| L16 | workflow-multi-app.md | - |
| L17 | namespaced-actors.md | - |
| L18 | Building-with-dapr skill | - |
| L19 | 06_ai_pizza_shop | All prior |
| L20 | - | All prior |

---

## VIII. Validation Checklist

**Chapter-Level Validation**:
- [x] Chapter type identified (Technical)
- [x] Concept density analysis documented (18 concepts)
- [x] Lesson count justified (21 lessons for 2 building blocks)
- [x] All evals from spec covered by lessons
- [x] All lessons map to at least one eval

**Stage Progression Validation**:
- [x] L00: Skill Extension (L3)
- [x] L01: Manual Foundation (L1) - Actor Model
- [x] L02-L08: AI Collaboration (L2) - Actor Practice
- [x] L09-L10: Manual Foundation (L1) - Workflow Concepts
- [x] L11-L18: AI Collaboration (L2) - Workflow + Production
- [x] L19: Spec-Driven Integration (L4) - Capstone
- [x] L20: Skill Finalization (L3)

**Cognitive Load Validation**:
- [x] All lessons: <= 5 concepts (under B1 limit of 10)
- [x] B1 proficiency tier maintained throughout

**Dependency Validation**:
- [x] Actor concepts before actor implementation
- [x] Workflow concepts before workflow implementation
- [x] Both building blocks before production patterns
- [x] All lessons before capstone

**Three Roles Validation** (L2 lessons):
- [x] Each L2 lesson includes AI as Teacher scenario
- [x] Each L2 lesson includes AI as Student scenario
- [x] Each L2 lesson includes AI as Co-Worker scenario

---

## IX. Implementation Notes

### Quality Reference

Compare all lessons against Ch53 L01 (`01-sidecar-pattern.md`) for:
- Full YAML frontmatter with skills, learning objectives, cognitive load
- Compelling narrative opening
- Tables comparing concepts
- 3 "Try With AI" prompts with "What you're learning" explanations
- "Reflect on Your Skill" section at end of each L2 lesson
- Safety notes where appropriate

### Code Example Standards

- All code uses Python 3.11+ type hints
- All actors use ABC interfaces with @actormethod
- All workflows use dataclasses for inputs/outputs
- All examples tested on Docker Desktop Kubernetes

### Diagram Requirements

- L01: Actor anatomy, turn-based concurrency, virtual actor lifecycle
- L04: State persistence across lifecycle
- L09: Workflow checkpointing
- L10: Replay process
- L15: Hybrid actor/workflow architecture

---

**Plan Version**: 1.0.0
**Generated**: 2025-12-29
**Ready for**: Content implementation with subagent orchestration
